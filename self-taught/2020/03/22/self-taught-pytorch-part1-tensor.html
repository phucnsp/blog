<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Pytorch part 1 - basic tensor and Pytorch tensor | Phuc Ng. Su</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Pytorch part 1 - basic tensor and Pytorch tensor" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="in progress" />
<meta property="og:description" content="in progress" />
<link rel="canonical" href="https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html" />
<meta property="og:url" content="https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html" />
<meta property="og:site_name" content="Phuc Ng. Su" />
<meta property="og:image" content="https://phucnsp.github.io/blog/images/pytorch_ava.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-22T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"in progress","@type":"BlogPosting","headline":"Pytorch part 1 - basic tensor and Pytorch tensor","dateModified":"2020-03-22T00:00:00-05:00","datePublished":"2020-03-22T00:00:00-05:00","image":"https://phucnsp.github.io/blog/images/pytorch_ava.png","url":"https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://phucnsp.github.io/blog/feed.xml" title="Phuc Ng. Su" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Pytorch part 1 - basic tensor and Pytorch tensor | Phuc Ng. Su</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Pytorch part 1 - basic tensor and Pytorch tensor" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="in progress" />
<meta property="og:description" content="in progress" />
<link rel="canonical" href="https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html" />
<meta property="og:url" content="https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html" />
<meta property="og:site_name" content="Phuc Ng. Su" />
<meta property="og:image" content="https://phucnsp.github.io/blog/images/pytorch_ava.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-22T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"in progress","@type":"BlogPosting","headline":"Pytorch part 1 - basic tensor and Pytorch tensor","dateModified":"2020-03-22T00:00:00-05:00","datePublished":"2020-03-22T00:00:00-05:00","image":"https://phucnsp.github.io/blog/images/pytorch_ava.png","url":"https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://phucnsp.github.io/blog/feed.xml" title="Phuc Ng. Su" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Phuc Ng. Su</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Pytorch part 1 - basic tensor and Pytorch tensor</h1><p class="page-description">in progress</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-22T00:00:00-05:00" itemprop="datePublished">
        Mar 22, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      29 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#self-taught">self-taught</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/phucnsp/blog/tree/master/_notebooks/2020-03-22-self-taught-pytorch-part1-tensor.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/phucnsp/blog/master?filepath=_notebooks%2F2020-03-22-self-taught-pytorch-part1-tensor.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/phucnsp/blog/blob/master/_notebooks/2020-03-22-self-taught-pytorch-part1-tensor.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Neural-network-programming---deep-learning-with-pytorch---deepilzard">Neural network programming - deep learning with pytorch - deepilzard </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Part-1:-Pytorch-and-Tensors">Part 1: Pytorch and Tensors </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Section-1:-Introducing-Pytorch">Section 1: Introducing Pytorch </a></li>
<li class="toc-entry toc-h4"><a href="#Section-2:-Introducing-Tensors">Section 2: Introducing Tensors </a></li>
<li class="toc-entry toc-h4"><a href="#Section-3:-Pytorch-Tensors">Section 3: Pytorch Tensors </a></li>
<li class="toc-entry toc-h4"><a href="#Section-4:-Tensor-Operations">Section 4: Tensor Operations </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Part-2:-Neural-Networks-and-Deep-learning-with-Pytorch">Part 2: Neural Networks and Deep learning with Pytorch </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Section-1:-Data-and-Data-processing">Section 1: Data and Data processing </a></li>
<li class="toc-entry toc-h4"><a href="#Section-2:-Neural-Net-and-Pytorch-design">Section 2: Neural Net and Pytorch design </a></li>
<li class="toc-entry toc-h4"><a href="#Section-3:-Training-NN">Section 3: Training NN </a></li>
<li class="toc-entry toc-h4"><a href="#Section-4:-Analyze-the-model's-results">Section 4: Analyze the model&#39;s results </a>
<ul>
<li class="toc-entry toc-h5"><a href="#Analyse-classification-result-using-a-Confusion-Matrix">Analyse classification result using a Confusion Matrix </a></li>
<li class="toc-entry toc-h5"><a href="#Analyse-training-loop-by-using-TensorBoard-with-PyTorch">Analyse training loop by using TensorBoard with PyTorch </a></li>
<li class="toc-entry toc-h5"><a href="#Hyperparameter-Experimenting---Training-Neural-Networks">Hyperparameter Experimenting - Training Neural Networks </a></li>
<li class="toc-entry toc-h5"><a href="#Speeding-up-the-training-process-by-increasing-num_workers">Speeding up the training process by increasing num_workers </a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Stack-vs-Concat">Stack vs Concat </a></li>
<li class="toc-entry toc-h2"><a href="#Disabling-PyTorch-Gradient-Tracking">Disabling PyTorch Gradient Tracking </a></li>
<li class="toc-entry toc-h2"><a href="#Effective-Pytorch">Effective Pytorch </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-22-self-taught-pytorch-part1-tensor.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some good sources:</p>
<ul>
<li>deeplizard : <a href="https://deeplizard.com/learn/video/v5cngxo4mIg">https://deeplizard.com/learn/video/v5cngxo4mIg</a>
</li>
<li>effective pytorch - vahidk <a href="https://github.com/vahidk/EffectivePyTorch?fbclid=IwAR1MhsjnjccWy6dIVtibFOCZbWhLtAj5pSTobnkUDxw_gHgfEswnVzqrKQ0#torchscript">https://github.com/vahidk/EffectivePyTorch?fbclid=IwAR1MhsjnjccWy6dIVtibFOCZbWhLtAj5pSTobnkUDxw_gHgfEswnVzqrKQ0#torchscript</a>  </li>
<li>recommend walk with pytorch: <a href="https://forums.fast.ai/t/getting-comfortable-with-pytorch-projects/28371">https://forums.fast.ai/t/getting-comfortable-with-pytorch-projects/28371</a>
</li>
<li>official tutorial: <a href="https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a>
</li>
<li>DL(with Pytorch): <a href="https://github.com/Atcold/pytorch-Deep-Learning">https://github.com/Atcold/pytorch-Deep-Learning</a>
</li>
<li>Pytorch project template: <a href="https://github.com/moemen95/PyTorch-Project-Template">https://github.com/moemen95/PyTorch-Project-Template</a>
</li>
<li>nlp turorial with pytorch : <a href="https://github.com/graykode/nlp-tutorial">https://github.com/graykode/nlp-tutorial</a>
</li>
<li>UDACITY course <a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">https://www.udacity.com/course/deep-learning-pytorch--ud188</a>
</li>
<li>awesome pytorch list: <a href="https://github.com/bharathgs/Awesome-pytorch-list">https://github.com/bharathgs/Awesome-pytorch-list</a>
</li>
<li>deep learning with pytorch <a href="https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf">https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf</a>
</li>
<li>pytorch zero to all: <a href="https://github.com/hunkim/PyTorchZeroToAll">https://github.com/hunkim/PyTorchZeroToAll</a>
</li>
<li>others:<ul>
<li><a href="https://medium.com/pytorch/get-started-with-pytorch-cloud-tpus-and-colab-a24757b8f7fc">https://medium.com/pytorch/get-started-with-pytorch-cloud-tpus-and-colab-a24757b8f7fc</a></li>
<li>grokking book</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-network-programming---deep-learning-with-pytorch---deepilzard">
<a class="anchor" href="#Neural-network-programming---deep-learning-with-pytorch---deepilzard" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural network programming - deep learning with pytorch - deepilzard<a class="anchor-link" href="#Neural-network-programming---deep-learning-with-pytorch---deepilzard"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Part-1:-Pytorch-and-Tensors">
<a class="anchor" href="#Part-1:-Pytorch-and-Tensors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Part 1: Pytorch and Tensors<a class="anchor-link" href="#Part-1:-Pytorch-and-Tensors"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-1:-Introducing-Pytorch">
<a class="anchor" href="#Section-1:-Introducing-Pytorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 1: Introducing Pytorch<a class="anchor-link" href="#Section-1:-Introducing-Pytorch"> </a>
</h4>
<ul>
<li>PyTorch Explained - Python Deep Learning Neural Network API</li>
<li>PyTorch Install - Quick and Easy</li>
<li>CUDA Explained - Why Deep Learning Uses GPUs</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-2:-Introducing-Tensors">
<a class="anchor" href="#Section-2:-Introducing-Tensors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 2: Introducing Tensors<a class="anchor-link" href="#Section-2:-Introducing-Tensors"> </a>
</h4>
<ul>
<li>Tensors Explained - Data Structures of Deep Learning</li>
<li>Rank, Axes, and Shape Explained - Tensors for Deep Learning</li>
<li>CNN Tensor Shape Explained - CNNs and Feature Maps</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-3:-Pytorch-Tensors">
<a class="anchor" href="#Section-3:-Pytorch-Tensors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 3: Pytorch Tensors<a class="anchor-link" href="#Section-3:-Pytorch-Tensors"> </a>
</h4>
<ul>
<li>PyTorch Tensors Explained - Neural Network Programming</li>
<li>Creating PyTorch Tensors for Deep Learning - Best Options</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-4:-Tensor-Operations">
<a class="anchor" href="#Section-4:-Tensor-Operations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 4: Tensor Operations<a class="anchor-link" href="#Section-4:-Tensor-Operations"> </a>
</h4>
<ul>
<li>Flatten, Reshape, and Squeeze Explained - Tensors for Deep Learning</li>
<li>CNN Flatten Operation Visualized - Tensor Batch Processing</li>
<li>Tensors for Deep Learning - Broadcasting and Element-wise Operations</li>
<li>ArgMax and Reduction Ops - Tensors for Deep Learning</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Part-2:-Neural-Networks-and-Deep-learning-with-Pytorch">
<a class="anchor" href="#Part-2:-Neural-Networks-and-Deep-learning-with-Pytorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Part 2: Neural Networks and Deep learning with Pytorch<a class="anchor-link" href="#Part-2:-Neural-Networks-and-Deep-learning-with-Pytorch"> </a>
</h3>
<ul>
<li>Prepare the data</li>
<li>Build the model</li>
<li>Train the model</li>
<li>Analyze the model's results</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-1:-Data-and-Data-processing">
<a class="anchor" href="#Section-1:-Data-and-Data-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 1: Data and Data processing<a class="anchor-link" href="#Section-1:-Data-and-Data-processing"> </a>
</h4>
<ul>
<li>Importance of Data in Deep Learning - Fashion MNIST for AI</li>
<li>Extract, Transform, Load (ETL) - Deep Learning Data Preparation</li>
<li>PyTorch Datasets and DataLoaders - Training Set Exploration</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="c1">#from plotcm import plot_confusion_matrix</span>

<span class="kn">import</span> <span class="nn">pdb</span>

<span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_set</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span>
    <span class="p">,</span><span class="n">train</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">,</span><span class="n">download</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">,</span><span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">])</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xs</span><span class="p">,</span><span class="n">ys</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dl</span><span class="p">))</span>
<span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([4, 1, 28, 28]), torch.Size([4]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_set</span><span class="o">.</span><span class="n">train_labels</span><span class="p">,</span> <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets
  warnings.warn("train_labels has been renamed targets")
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([9, 0, 0,  ..., 3, 0, 5]), tensor([9, 0, 0,  ..., 3, 0, 5]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_set</span><span class="o">.</span><span class="n">classes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['T-shirt/top',
 'Trouser',
 'Pullover',
 'Dress',
 'Coat',
 'Sandal',
 'Shirt',
 'Sneaker',
 'Bag',
 'Ankle boot']</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x1a2a0ee790&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="c1"># plt.imshow(np.transpose(grid, (1,2,0)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x1a2a383e90&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-2:-Neural-Net-and-Pytorch-design">
<a class="anchor" href="#Section-2:-Neural-Net-and-Pytorch-design" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 2: Neural Net and Pytorch design<a class="anchor-link" href="#Section-2:-Neural-Net-and-Pytorch-design"> </a>
</h4>
<ul>
<li>Build PyTorch CNN - Object Oriented Neural Net-</li>
<li>CNN Layers - Deep Neural Network Archite-</li>
<li>CNN Weights - Learnable Parameters in Neural Net-</li>
<li>Callable Neural Networks - Linear Layers in -</li>
<li>CNN Forward Method - Deep Learning Implement-</li>
<li>Forward Propagation Explained - Pass Image to PyTorch Neural Network</li>
<li>Neural Network Batch Processing - Pass Image Batch to PyTorch CNN</li>
<li>CNN Output Size Formula - Bonus Neural Network Debugging Session</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">12</span><span class="o">*</span><span class="mi">4</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># (1) input layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> 
        
        <span class="c1"># (2) hidden conv layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># out shape - bs x 6 x 12 x 12</span>
        
        <span class="c1"># (3) hidden conv layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># out shape - bs x 12 x 4 x 4</span>
        
        <span class="c1"># (4) hidden linear layer</span>
<span class="c1">#         import pdb; pdb.set_trace()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># x.reshape(-1, 12*4*4)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># (5) hidden linear layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># (6) output layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#         x = F.softmax(x, dim=1)</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Network(
  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=192, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=60, bias=True)
  (out): Linear(in_features=60, out_features=10, bias=True)
)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([4, 10])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.0071,  0.0308,  0.1355,  0.1304, -0.1290,  0.0521,  0.0140, -0.0722,  0.0914, -0.0045],
        [-0.0082,  0.0273,  0.1325,  0.1348, -0.1298,  0.0527,  0.0120, -0.0763,  0.0880, -0.0087],
        [-0.0101,  0.0328,  0.1360,  0.1372, -0.1294,  0.0470,  0.0095, -0.0750,  0.0896, -0.0034],
        [-0.0076,  0.0324,  0.1334,  0.1366, -0.1288,  0.0475,  0.0084, -0.0755,  0.0876, -0.0043]],
       grad_fn=&lt;AddmmBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  """Entry point for launching an IPython kernel.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.1184, 0.1070, 0.0941, 0.0892, 0.0883, 0.1071, 0.0939, 0.0983, 0.1142, 0.0895],
        [0.1184, 0.1071, 0.0940, 0.0894, 0.0889, 0.1064, 0.0931, 0.0982, 0.1145, 0.0901],
        [0.1180, 0.1080, 0.0937, 0.0892, 0.0888, 0.1061, 0.0936, 0.0980, 0.1144, 0.0902],
        [0.1183, 0.1069, 0.0939, 0.0892, 0.0880, 0.1064, 0.0939, 0.0986, 0.1145, 0.0902]], grad_fn=&lt;SoftmaxBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  """Entry point for launching an IPython kernel.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-3:-Training-NN">
<a class="anchor" href="#Section-3:-Training-NN" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 3: Training NN<a class="anchor-link" href="#Section-3:-Training-NN"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are now ready to begin the training process. The training process is an iterative process which including following steps:</p>
<ol>
<li>
<p><strong>Get batch from the training set</strong>.</p>
<ul>
<li>Since we have 60,000 samples in our training set, we will have 60,000 / 100 = 600 iterations. Something to notice, batch_size will directly impact to the number of times the weights updated. In our case, the weights will be updated 600 times by the end of each loop. So far, there is no rule-of-thump for selecting the value of batch size so we still need to do trial and error to figure out the best value.</li>
</ul>
</li>
<li>
<p><strong>Pass batch to network.</strong></p>
</li>
<li>
<p><strong>Calculate the loss (difference between the predicted values and the true values).</strong></p>
<ul>
<li>To be notice, the function <code>cross_entropy</code> has a parameter called <code>reduction</code> which has 3 option - <code>none, mean, sum</code>. By default, this variable is set to <code>mean</code> which will average the loss value by batch_size. <code>None</code> and <code>sum</code> means there is no reduction applied and the output will be summed, respectively.</li>
</ul>
</li>
<li>
<p><strong>Calculate the gradient of the loss function w.r.t the network's weights.</strong></p>
<ul>
<li>Before calculate the gradient, we need to zero out these gradients, by calling <code>optimizer.zero_grad()</code>, because after we call the loss.backward() method, the gradients will be calculated and added to the grad attributes of our network's parameters.  </li>
<li>Calculating the gradients is very easy using PyTorch. Since PyTorch has created a computation graph under the hood. As our tensor flowed forward through our network, all of the computations where added to the graph. The computation graph is then used by PyTorch to calculate the gradients of the loss function with respect to the network's weights.</li>
</ul>
</li>
<li>
<p><strong>Update the weights using the gradients to reduce the loss.</strong></p>
<ul>
<li>The gradients calculated from step 4 are used by the optimizer to update the respective weights. </li>
</ul>
</li>
<li>
<p><strong>Repeat steps 1-5 until one epoch is completed.</strong></p>
</li>
<li><strong>Repeat steps 1-6 for as many epochs required to reach the minimum loss.</strong></li>
</ol>
<p>To create our optimizer, we use the <code>torch.optim</code> package that has many optimization algorithm implementations that we can use, for example: Adam. The model's parameters and learning rate are passed to the optimizer. <code>lr</code> tells optimizer how far to step in the direction of minimizing loss fct while <code>Parameters</code> provide Adam the ability to access gradients.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> 
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> 
<span class="n">accuracy</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">preds</span><span class="p">,</span> <span class="n">lbs</span><span class="p">:</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">lbs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_acc</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>                    
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span>                <span class="c1"># 1. Get batch from the training set.</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>                 <span class="c1"># 2. Pass batch to network.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># 3. Calculate the loss</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>            
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>                       <span class="c1"># 4. Calculate the gradient</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                      <span class="c1"># 5. Update the weights</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total_acc</span>  <span class="o">+=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    
    <span class="n">nr_iters_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch:       </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="n">nr_iters_per_epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_acc : </span><span class="si">{</span><span class="n">total_acc</span><span class="o">/</span><span class="n">nr_iters_per_epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  after removing the cwd from sys.path.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch:       0 
avg_loss: 0.6262958686550458 
avg_acc : 76.13
epoch:       1 
avg_loss: 0.4225387443850438 
avg_acc : 84.28333333333333
epoch:       2 
avg_loss: 0.37975253333648046 
avg_acc : 85.75166666666667
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Section-4:-Analyze-the-model's-results">
<a class="anchor" href="#Section-4:-Analyze-the-model's-results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Section 4: Analyze the model's results<a class="anchor-link" href="#Section-4:-Analyze-the-model's-results"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Analyse-classification-result-using-a-Confusion-Matrix">
<a class="anchor" href="#Analyse-classification-result-using-a-Confusion-Matrix" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analyse classification result using a Confusion Matrix<a class="anchor-link" href="#Analyse-classification-result-using-a-Confusion-Matrix"> </a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The confusion matrix will show us which categories the model is predicting correctly and which categories the model is predicting incorrectly. For the incorrect predictions, this will show us which categories are confusing the model.</p>
<p>Now, if we compare the two tensors element-wise and count the number of predicted labels vs the target labels, the values inside the two tensors act as coordinates for our matrix. Let's stack these two tensors along the second dimension so we can have 60,000 ordered pairs.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(60000, 60000)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get predictions for the entire training set</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_all_preds</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
    <span class="n">all_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">lbs</span> <span class="o">=</span> <span class="n">batch</span>
        
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">all_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">all_preds</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">all_preds</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">prediction_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="n">train_preds</span> <span class="o">=</span> <span class="n">get_all_preds</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prediction_loader</span><span class="p">)</span>
    
<span class="n">stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
<span class="p">(</span>
    <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span>
    <span class="n">train_preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">stacked</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([60000, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># method 1: manually calculate confusion matrix</span>
<span class="n">cmt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">stacked</span><span class="p">:</span>
    <span class="n">tl</span><span class="p">,</span> <span class="n">pl</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">cmt</span><span class="p">[</span><span class="n">tl</span><span class="p">,</span><span class="n">pl</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">cmt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[5523,    1,   46,   59,   15,    2,  306,    0,   48,    0],
        [  36, 5829,    3,   77,   15,    0,   32,    0,    8,    0],
        [ 144,    6, 3704,   51, 1359,    3,  603,    0,  129,    1],
        [ 554,   26,    2, 5077,  189,    0,  135,    0,   15,    2],
        [  49,    3,   99,  161, 5298,    1,  316,    0,   72,    1],
        [  13,    0,    0,    0,    0, 5671,    0,  178,   81,   57],
        [1443,   10,  244,   75,  693,    0, 3414,    0,  121,    0],
        [   1,    0,    0,    0,    0,   38,    0, 5823,   19,  119],
        [  45,    0,    4,    8,   17,    1,   34,    4, 5884,    3],
        [   0,    0,    0,    0,    0,   23,    0,  261,    6, 5710]])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># method 2: use sklearn </span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">train_preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">cm</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[5523,    1,   46,   59,   15,    2,  306,    0,   48,    0],
       [  36, 5829,    3,   77,   15,    0,   32,    0,    8,    0],
       [ 144,    6, 3704,   51, 1359,    3,  603,    0,  129,    1],
       [ 554,   26,    2, 5077,  189,    0,  135,    0,   15,    2],
       [  49,    3,   99,  161, 5298,    1,  316,    0,   72,    1],
       [  13,    0,    0,    0,    0, 5671,    0,  178,   81,   57],
       [1443,   10,  244,   75,  693,    0, 3414,    0,  121,    0],
       [   1,    0,    0,    0,    0,   38,    0, 5823,   19,  119],
       [  45,    0,    4,    8,   17,    1,   34,    4, 5884,    3],
       [   0,    0,    0,    0,    0,   23,    0,  261,    6, 5710]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To nicely plot the confusion matrix, we can use below util function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'Confusion matrix'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float'</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Normalized confusion matrix"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Confusion matrix, without normalization'</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">'nearest'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>

    <span class="n">fmt</span> <span class="o">=</span> <span class="s1">'.2f'</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s1">'d'</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"white"</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s2">"black"</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'True label'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predicted label'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">names</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s1">'T-shirt/top'</span><span class="p">,</span>
    <span class="s1">'Trouser'</span><span class="p">,</span>
    <span class="s1">'Pullover'</span><span class="p">,</span>
    <span class="s1">'Dress'</span><span class="p">,</span>
    <span class="s1">'Coat'</span><span class="p">,</span>
    <span class="s1">'Sandal'</span><span class="p">,</span>
    <span class="s1">'Shirt'</span><span class="p">,</span>
    <span class="s1">'Sneaker'</span><span class="p">,</span>
    <span class="s1">'Bag'</span><span class="p">,</span>
    <span class="s1">'Ankle boot'</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion matrix, without normalization
[[5523    1   46   59   15    2  306    0   48    0]
 [  36 5829    3   77   15    0   32    0    8    0]
 [ 144    6 3704   51 1359    3  603    0  129    1]
 [ 554   26    2 5077  189    0  135    0   15    2]
 [  49    3   99  161 5298    1  316    0   72    1]
 [  13    0    0    0    0 5671    0  178   81   57]
 [1443   10  244   75  693    0 3414    0  121    0]
 [   1    0    0    0    0   38    0 5823   19  119]
 [  45    0    4    8   17    1   34    4 5884    3]
 [   0    0    0    0    0   23    0  261    6 5710]]
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAArkAAALICAYAAAB7IOjQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3gUZdfH8e9JAgGJ9J6A9C69NxEVEJCidJRexN57wfa8KjYUFRTbYwNRkY4gCALSpYhYqEpvAtIJ4X7/2CUGSCdkdvf5fa5rr+zeU/bMTnb35MyZiTnnEBEREREJJWFeByAiIiIiktGU5IqIiIhIyFGSKyIiIiIhR0muiIiIiIQcJbkiIiIiEnIivA5ARERERNImPOdlzp065nUYuGN7vnXOtfI6jsQoyRUREREJMu7UMSLLd/E6DI6vfDO/1zEkRe0KIiIiIhJylOSKiIiISMhRu4KIiIhI0DEw1SqTo1dHREREREKOKrkiIiIiwcYAM6+jCGiq5IqIiIhIyFGSKyIiIiIhR+0KIiIiIsFIJ54lS6+OiIiIiIQcJbkiIiIiEnLUriAiIiISjHR1hWSpkisiIiIiIUeVXBEREZGgo/94lhK9OiIiIiIScpTkioiIiEjIUbuCiIiISDDSiWfJUiVXREREREKOklwRERERCTlqVxAREREJNoaurpACvToiIiIiEnKU5IqIiIhIyFG7goiIiEjQMV1dIQWq5IqIiIhIyFElV0RERCQY6cSzZOnVEREREZGQoyRXREREREKO2hVEREREgpFOPEuWKrkiIiIiEnKU5IqIiIhIyFG7goiIiEjQMV1dIQV6dUREREQk5KiSKyIiIhJsDJ14lgJVckVEREQk5CjJFREREZGQo3YFERERkWCkE8+SpVdHREREREKOklwRERERCTlqVxAREREJOrpObkr06oiIiIhIyFElV0RERCQYhek6uclRJVdEREREQo6SXBEREREJOWpXEBEREQk2hk48S4FeHREREREJOUpyRURERCTkqF1BREREJBiZrq6QHFVyRURERCTkKMkVERERkZCjdgURERGRoKN/65sSvToiIiIiEnJUyRUREREJRjrxLFmq5IqIiIhIyFGSKyIiIiIhR+0KIiIiIsFIJ54lS6+OiIiIiIQcJbkiIiIiEnLUriAiIiISbMx0dYUUqJIrIiIiIiFHlVwRERGRYKQTz5KlV0dEREREQo6SXBEREREJOWpXEBEREQlGOvEsWarkioiIiEjIUZIrIiIiIiFH7QoiIiIiQcd0dYUU6NURERERkZCjJFdEREREQo7aFURERESCka6ukCxVckVEREQk5KiSKyIiIhJsDJ14lgK9OiIiIiIScpTkioiIiEjIUbuCiIiISNDRdXJToldHREREREKOklwRCSlmlt3MJpnZQTMbdwHr6WlmMzIyNq+YWRMz+93rOEREMpOSXBHxhJn1MLNlZnbYzHaY2TQza5wBq+4EFALyOec6p3clzrlPnXMtMiCei8rMnJmVSW4e59w851z5zIpJRDKJmfe3AKYkV0QynZndA7wG/AdfQloceAtonwGrvwz4wzl3KgPWFfTMTOdeiMj/JCW5IpKpzCwX8DRwq3Pua+fcEedcrHNuknPufv88kWb2mplt999eM7NI/7RmZrbVzO41s93+KnBf/7SngCeArv4KcX8zG2pmnyR4/hL+6meE/3EfM9toZofMbJOZ9UwwPj/Bcg3NbKm/DWKpmTVMMG2OmT1jZgv865lhZvmT2P4z8T+QIP4OZtbazP4ws7/N7JEE89c1s4VmdsA/7wgzy+qf9oN/tlX+7e2aYP0PmtlO4IMzY/5lSvufo6b/cVEz22tmzS5ox4pI5rMw728BLLCjE5FQ1ADIBoxPZp5HgfpAdaAaUBd4LMH0wkAuIBroD7xpZnmcc0/iqw6Pdc5FOefeSy4QM8sBvA5c65y7FGgIrExkvrzAFP+8+YBXgClmli/BbD2AvkBBICtwXzJPXRjfaxCNLyl/F7gRqAU0AZ4ws1L+eeOAu4H8+F67q4BbAJxzTf3zVPNv79gE68+Lr6o9KOETO+c2AA8Cn5rZJcAHwIfOuTnJxCsiEnSU5IpIZssH7E2hnaAn8LRzbrdzbg/wFHBTgumx/umxzrmpwGEgvT2np4EqZpbdObfDOfdLIvO0AdY55z52zp1yzn0O/AZcl2CeD5xzfzjnjgFf4EvQkxILPOeciwXG4EtghzvnDvmf/xegKoBzbrlzbpH/eTcDo4ArUrFNTzrnTvjjOYtz7l1gHbAYKILvjwoRkZCiJFdEMts+IH8KvaJFgT8TPP7TPxa/jnOS5KNAVFoDcc4dAboCNwM7zGyKmVVIRTxnYopO8HhnGuLZ55yL898/k4TuSjD92JnlzaycmU02s51m9g++SnWirRAJ7HHOHU9hnneBKsAbzrkTKcwrIoHI65POdOKZiMhZFgLHgQ7JzLMd36H2M4r7x9LjCHBJgseFE050zn3rnLsGX0XzN3zJX0rxnIlpWzpjSou38cVV1jmXE3gE33+tT45LbqKZReE78e89YKi/HUNEJKQoyRWRTOWcO4ivD/VN/wlXl5hZFjO71sxe9M/2OfCYmRXwn8D1BPBJUutMwUqgqZkV95/09vCZCWZWyMza+XtzT+Bre4hLZB1TgXL+y55FmFlXoBIwOZ0xpcWlwD/AYX+Vecg503cBpc5bKnnDgeXOuQH4eo1HXnCUIiIBRkmuiGQ659wrwD34TibbA2wBbgO+8c/yLLAMWA38DPzkH0vPc80ExvrXtZyzE9Mw4F58ldq/8fW63pLIOvYBbf3z7gMeANo65/amJ6Y0ug/fSW2H8FWZx54zfSjwkf/qC11SWpmZtQda4WvRAN9+qHnmqhIiEiTMvL+yQoBfXcGcS/aoloiIiIgEmLA8JVxks8dSnvEiO/7NwOXOudpex5EYXSRcREREJBgF+IlfXgvsOrOIiIiISDooyRURERGRkKN2BREREZEgZGpXSJaS3AxgWXI4y5bb6zAyRI1yRbwOIcPolMrApI/kwBQXYichh4fQl38o7ZnQ2Svw00/L9zrnCngdhyRNSW4GsGy5iax1c8ozBoEF3z3udQgZ5vTpUPpqCB1hYaH0NRc6jpxI7r8sB58ckaHz9RZKn2Wh9P7PnsXO/S+IEmBC51NARERE5H+EoXaFlOjEMxEREREJOUpyRURERCTkqF1BREREJNgYoXUm30WgSq6IiIiIhBxVckVERESCjunEsxSokisiIiIiIUdJroiIiIiEHCW5IiIiIkHIzDy/pTLOzWb2s5mtNLNl/rG8ZjbTzNb5f+bxj5uZvW5m681stZnVTLCe3v7515lZ75SeV0muiIiIiFxsVzrnqjvnavsfPwTMcs6VBWb5HwNcC5T13wYBb4MvKQaeBOoBdYEnzyTGSVGSKyIiIiKZrT3wkf/+R0CHBOP/dT6LgNxmVgRoCcx0zv3tnNsPzARaJfcEurqCiIiISBAKkKsr5D/TguD3jnPunXPmccAMM3PAKP/0Qs65HQDOuR1mVtA/bzSwJcGyW/1jSY0nSUmuiIiIiKTX3gQtCElp5Jzb7k9kZ5rZb8nMm1jm7pIZT5LaFURERESCkNcnnaW2kuyc2+7/uRsYj6+ndpe/DQH/z93+2bcCxRIsHgNsT2Y8SUpyRUREROSiMLMcZnbpmftAC2ANMBE4c4WE3sAE//2JQC//VRbqAwf9bQ3fAi3MLI//hLMW/rEkqV1BRERERC6WQsB4f9U3AvjMOTfdzJYCX5hZf+AvoLN//qlAa2A9cBToC+Cc+9vMngGW+ud72jn3d3JPrCRXREREJNgYiXepBhjn3EagWiLj+4CrEhl3wK1JrOt94P3UPrfaFTz225jbWfr+YBaNHsj8Uf0BeLRPUzaMu5NFoweyaPRAWtYrA0DzWiVZMGoAS98fzIJRA7iiRon49Ux4sTuLRw9i+Qc38/o9rQkLC8zf/MED+lG8aEFqVa/idSjpFhcXR4O6Nbmhw3UAOOcY+sSjVKtcnppVK/HWiNc9jjD1KpYrSZ2aValfpwaNG9QBYPXqVVzZtCF1alalU8d2/PPPPx5HmbLEfq+efXoopS6Lpl6t6tSrVZ3p06Z6GGH6bNmyhZZXX0n1yytSs1plRrw+3OuQUnT8+HGuuaIBV9SvSaPa1Xj+2acA+HPzJlo0a0idahXp36sHJ0+ejF/mm6/G0bBWVRrVrsagvjd5FXqazPh2OlUrl6dyhTIMe/F5r8NJl3M/y76fPYuG9WpRv04Nrr6yCRvWr/c4wrQLhf0iGUeV3ADQ6u7/su/gsbPG3vhyMa+NXXTW2L6Dx+j0yBh27DtMpZIFmPRiD0p39n3p3Tj0Kw4d9X1pfP5UJ25oVolxs3/JnA1Ig5t69+HmW25jQL9eXoeSbm++MZzyFSpyyJ/8ffzfD9m6dSsrfv6VsLAwdu/encIaAsu0GbPJnz9//ONbbx7If54fRpOmV/DRh+/z2ivDeGLoMx5GmLKkfq9uv/Nu7r7nPo+iunARERE8/+LL1KhZk0OHDtGwXi2uuvoaKlaq5HVoSYqMjGT8lJlERUURGxtLm2uu4OoWLXn7jeHcfOudXN+5K/fecQuffPQ+/QbezIb16xj+8gtM/W4uufPkYU8QvH/i4uK4645bmTJtJtExMTSuX4e2bdsF9H5JzLmfZXfdfgtjv/yGChUr8s7It3jh+ed4Z/QHHkeZeqGyXyTjqJIbRFat38mOfYcBWLtpD5FZI8iaJRwgPsGNCA8jS5ZwfNX+wNO4SVPy5s3rdRjptm3rVqZPm0qfvv3jx0a/M5KHH3mcsDDf26lgwYJJLR4U1v3xO42bNAXgqquuYcL4rz2OKGXB/nuVlCJFilCjpu8/Wl566aVUqFCR7du3eRxV8syMqKgoAGJjY4mNjcXMmDf3e9p1vAGAbj1vYtrkiQB8/OF79Bs0hNx5fP+4qEAQvH+WLllC6dJlKFmqFFmzZqVz125MnjQh5QUDSGKfZWbGoUO+hPfgPwcpUqSIV+GlSyjsl7QwvL+yQoBcpzdJSnI95pxj0rCeLBg1gH5ta8SP39yxDkveG8TIB64jd1S285breEVFVq3fycnYuPixiS/24K9v7uHw0ZN8PffXTIn/f80D993Nc//3QnxCC7Bp4wa++nIsjRvUocN1rVm/bp2HEaaNYbRr05JG9Wvz/mjftbsrVa7ClEm+BOTrr8axdeuW5FYR0Ea+NYI6NaoyeEA/9u/f73U4F+TPzZtZuXIFderW8zqUFMXFxdGsQS0qlixKs+ZXU6JkaXLlzk1EhO/gYdHoGHZs9135Z8P6dWxYv47WVzel5ZWNmDUz2ZOlA8L27duIifn3SkbR0TFs2xbYf3ycK7HPsjdHvsv17dtQtlQxxnz6Cffe/1Ayawg8obBfJGNd1CTXzPKZ2Ur/baeZbUvwOGsKyzYzs8lJTBttZokefzCzu8zsknPGHjaznmbWIanlvNL8tg9pOGg0HR78jMEd6tCoanHenbCcSj1GUG/AO+zcd5jnb7nmrGUqlijAs4Oac9vLZ/cYtnvgM0re8CqRWcJplqBfVzLGtCmTKVCgADVq1jpr/MSJE0RGZmP+wqX07T+AIYP7J7GGwDNrznx+XLyc8ROnMmrkW8yf9wNvj3qPUSPfolH92hw+fIisWZN9qwasgYOHsPb3DSxevpLCRYrw0P33eh1Suh0+fJjuXW5g2MuvkTNnTq/DSVF4eDhzFi5n9e+b+WnZUv74/fzrvp8pAJ06dYqN69czYdos3vngE+66dTAHDxzI5IjTJrEjZYFe0Uooqc+yEa+/xtcTprBu4xZu7NWHhx64x6MI0yfY90t6eF3FDfTX96Imuc65fc656s656sBI4NUzj51zJ1NaPpn1DnDOrT133MzCgbuAS86Z1AKYge//IgdUknum/WDPgaNMnP8bdSoWZff+I5w+7XAO3p/yE7UrFo2fP7rApYx9pjMD/m8Cm7afX5k6cTKOyT/+wXWNy2faNvyvWLhwAVOmTKJiuZL0vqk7c+fMpl+fm4iOjqGD/zBsu/YdWfPzao8jTb0iRX2/WwULFqRd+w4sW7qE8hUqMGnqtyxYtIzOXbpTslRpj6NMn0KFChEeHk5YWBj9+g9k2bIlXoeULrGxsXTvcgNdu/ekQ8frvQ4nTXLlzk2jJlewbOliDh44wKlTpwDYvm0rhYv4fveKFo3m2rbXkSVLFi4rUZIyZcuxYUNgHw2Jjo456wjHtm1bKVq0aDJLBJbEPsuub9+Wn1evij9S0KlzVxYvXOhxpGkT7PtFMl5AtCuY2RUJKrwrzlw0GIgysy/N7Dcz+9T8fzKY2Rwzq+2/f9jMnjazxcCjQFHgezP73j89J5AVKAu0A4b5n6e0mVU3s0VmttrMxvsvLnxm/a+Z2Y9mtsbM6l6M7b4kWxaismeNv3917VL8smkPhfNGxc/TvnEF1m7aA0CuqEi+/r/uPPHubBau2Ro/T47sWeKXCQ83WtUrw+9/7b0YIf9Pe/rZ/2Pdxi38+scmPvr4c65o1pz3P/yYtu3aM2fObADm/TCXMmXLeRxp6hw5coRDhw7F35/13UwqVa4Sf+Lc6dOneeH55+g/cLCXYabbjh074u9P+GY8lSoH3xU9nHPcPLA/5StU5M67g6OqtnfPnvhK7LFjx/jh+1mUK1+Bxk2bMXH8VwCM+fRjrm3jO6O/9XXtmf/DHAD27d3LhvXrKFGilCexp1btOnVYv34dmzdt4uTJk4wbO4Y2bdt5HVaqJfZZ9sVX3/DPPwdZ98cfAMyeNZPyFSp6HGnaBPt+kYwXKFdXuA+41Tm3wMyigOP+8RpAZXz/tm0B0AiYf86yOYA1zrknAMysH3Clc+5Mlnc1MMs596OZTQQmO+e+9M+7GrjdOTfXzJ4GnsRXCQbI4ZxraGZN8V2T7axvSDMbBAwCIDJXuja6YJ4cjH2mC+A7YWzsrDXMXLKB9x5pT9UyhXHO8efOg9z+8hTA16dbOjoPD/VqwkO9mgBw3X2fYmZ8+Z+uZM0STnhYGHNXbOLdicvTFdPF1uvG7sybO4e9e/dSukQMjz/xFH36Bc/h/cTce/9D9Ot9IyNef42oqCjeHPmu1yGlyu5du+jWxVcZjDt1ii7dutOiZSvefGM474x8C4B2HTrSq3dfL8NMlcR+r36YO4fVq1ZiZlxWogRvvDXK6zDT7McFC/js04+pUuVy6tWqDsBTz/6HVte29jiypO3atYPbBvUjLi6O06cd7a/vRMtr21C+QkUG9unJ/z3zJJdXrU7P3v0AaH51C76fNZOGtaoSHh7G0GefJ2++fB5vRfIiIiJ4dfgIrmvTkri4OHr36UelypW9DuuCREREMOLtd+jRrRNhYWHkyZOHt0e953VYaRKK+yUlgd4u4DXLrLPwzWwocNg591Ii0x4COgKfAl8757aaWTPgUefcNf553gYWOOc+MbM5wH3OuWVmdgqIdM7F+efbDNQ+k+Sa2TvAB865hWb2If4k18xyAT8754r75ysNjHPO1fSv/2nn3Gz/tL+Aqs65RBvFwi6NdpG1bs6AV8l7+7973OsQMszp04F5hYn/dYF6Def/dUdOnPI6hAyVIzJQajgXLpQ+y0Lp/Z89iy13ztX26vkj8pVyOVs/69XTx9v/SU9PX4fkeNKuYGa3JmhPKOqcex4YAGQHFplZBf+sJxIsFkfilefjZxLcJNQF0tOMd+6nSuh8yoiIiIiEOE/+1HXOvQm8eeaxmZV2zv0M/GxmDYAKQHpPrz0EXArsNbPKwG8JkuAz03DOHTSz/WbWxDk3D7gJmJtgPV3x9fY2Bg465w6mMx4RERGRDKd2heQFyvGcu8zsSnzV2rXANKBBOtf1DjDNzHYAU4DpCaaNAd41szuATkBvYKT/kmMbgYTNh/vN7EcgJ9AvnbGIiIiIiAcyLcl1zg1NZtrtiQzP8d/OzHNbgvvNEtyPSriQc+4N4A0AM5sJ9EowbQHnX0KsfhJhfeWcezipmEVEREQkcAVKJfeiOHPSmoiIiEhIMf9NkhTSSW56JawUi4iIiEjwUZIrIiIiEoR04lnyAuI/nomIiIiIZCQluSIiIiISctSuICIiIhJkDFO7QgpUyRURERGRkKMkV0RERERCjtoVRERERIKQ2hWSp0quiIiIiIQcVXJFREREgpEKuclSJVdEREREQo6SXBEREREJOWpXEBEREQk2phPPUqJKroiIiIiEHCW5IiIiIhJy1K4gIiIiEoTUrpA8VXJFREREJOQoyRURERGRkKN2hQxQvVwRFsx8zOswMkSeend6HUKG2b94uNchZJi4087rECTEXZI13OsQJAlhYTokLYlTu0LyVMkVERERkZCjSq6IiIhIkDFMldwUqJIrIiIiIiFHSa6IiIiIhBy1K4iIiIgEI3UrJEuVXBEREREJOUpyRURERCTkqF1BREREJNiYrpObElVyRURERCTkqJIrIiIiEoRUyU2eKrkiIiIiEnKU5IqIiIhIyFG7goiIiEgQUrtC8lTJFREREZGQoyRXREREREKO2hVEREREgpG6FZKlSq6IiIiIhBxVckVERESCkE48S54quQHo+PHjNGlYj3q1qlOrWhWeeepJAJxzPPn4o1StVJ4al1firRGvexzp2X6b9ARLxz7Ios/uZ/7H9wJQtVw0cz+8O36sduXiAHS7thZLxjzIkjEP8v37d3F52aLx67m1+xUsG/sQy794iNu6X+HJtqTG8ePHadygLnVrVqNmtcrx+ylY/PH77zSoUyP+ViR/Lt58/TV69ewWP1apXEka1KnhdagpGjygH8WLFqRW9SrxY88+PZRSl0VTr1Z16tWqzvRpUz2MMP1mfDudqpXLU7lCGYa9+LzX4aRJUp9lfXvdSLXKFahd/XIGD+xHbGysx5GmXTDvl3O9/tqr1KxWmVrVq9Drxu4cP37c65DSLZT2i1w4VXIDUGRkJNNmzCIqKorY2FiuataElq2u5bfffmXb1q2sXPMrYWFh7N692+tQz9Nq8Aj2HTgS//i5O9vx3DvTmfHjr7RsVInn7mhHy8Ej2LxtHy0Gvs6BQ8do0bAibz7Wlaa9X6VS6SL07dCAJr1f5mRsHBPfuJlp89eyYcseD7cqcZGRkUyfOTt+PzW/ojEtWl5Lvfr1vQ4tVcqVL8/CpSsAiIuLo2zJGK5r35Fb77grfp6HH7iXnLlyeRViqt3Uuw8333IbA/r1Omv89jvv5u577vMoqgsXFxfHXXfcypRpM4mOiaFx/Tq0bduOipUqeR1aqiT1Wda1ew/e/+hjAPrc1JMP3h/NoMFDPI429YJ9vyS0bds23nrzdVasXkv27Nnp2b0L48aO4abefbwOLc1Cab9IxlAlNwCZGVFRUQDExsb6qhxmvDtqJA8/+jhhYb7dVrBgQS/DTBXnHDlzZAMgV1Q2duz9B4BFqzdz4NAxAJb8vJnogrkBqFCyEEvWbObY8Vji4k4z76f1tL/ycm+CT8G5++lUbGzQHjqaM3sWpUqVpvhll8WPOef4+qtxdO7S3cPIUqdxk6bkzZvX6zAy3NIlSyhdugwlS5Uia9asdO7ajcmTJngdVqol9VnW6trWmBlmRu06ddi2davHkaZNsO+Xc506dYpjx475fh49SpGiRVNeKACF2n5JyZn3kNe3QKYkN0DFxcVRr3YNLosuxFVXXU3duvXYtHEDX44bS6P6dWh/XWvWr1vndZhncQ4mvTmEBZ/cR7+ODQC4/6Xx/Oeu9qybMpT/u6s9T7wx6bzl+nSoz7c//grAL+t30LhGafLmuoTs2bLQqlElYgrlydTtSIu4uDjq1apO8aIFaX71NdStV8/rkNLly3Fj6NSl21ljC+bPo2DBQpQpW9ajqC7cyLdGUKdGVQYP6Mf+/fu9DifNtm/fRkxMsfjH0dExbNu2zcOI0i6xz7IzYmNj+ezTT2jRspWHEaZdKOyXM6Kjo7nr7vsoV6o4JYsVIWfOXFx9TQuvw0qXUNovkjECLsk1s3xmttJ/22lm2xI8zup1fJklPDycxctWsG7TFpYtW8ova9Zw4sQJsmXLxoJFS+nbbwA3D+rvdZhnad7vNRr2fIkOt49kcJcmNKpRmkGdG/HAy+Mp22YoD7wynrefOLsq2LR2GXq3r89jr08E4PfNu3j5o1lMfusWJr5xM6v/2M6puNNebE6qhIeHs3j5StZv3sqypUv4Zc0ar0NKs5MnTzJl8iQ63tD5rPFxYz+n8zmJbzAZOHgIa3/fwOLlKylcpAgP3X+v1yGlmXPuvLFAr5ycK7HPsjPuvP0WGjdpQqPGTTyMMO1CYb+csX//fiZPmsCv6zax8a/tHDl6hM8//cTrsNIllPaLZIyAS3Kdc/ucc9Wdc9WBkcCrZx47504CmE+mxW5mnvUu586dmyZNr2DmjOlER8fQoeMNALTv0JE1P6/2KqxEnWlF2LP/MBO/X02dKsXp2bYu38xeBcBXM1dSu/K/h8OrlCnK2493p/M9o/n74NH48Y8mLKJhz5e4ZuAb7P/nKOsDsB/3XLlz56bpFc2YMWO616Gk2Yzp06hevSaFChWKHzt16hQTJ4znhs5dPYzswhQqVIjw8HDCwsLo138gy5Yt8TqkNIuOjmHr1i3xj7dt20rRID2UnPCzDOC5Z55i7569vDDsFY8jS7tQ2i+zZ31HiRIlKVCgAFmyZKFDh+tZtPBHr8NKl1DaL6nldatCoP8REXBJblLMrIyZrTGzkcBPQBEzu9HMfvaP/8c/X4SZHUiwXDczG53g/hozW2Vm3yeY/xUzW2Jmq81sgH/8ajP7zszGACsyc1v37NnDgQO+TTh27Bjfz55FufIVuK5de+bMmQ3AvB/mUqZsucwMK1mXZMtK1CWR8fevrl+BX9bvYMeegzSpVQaAZnXKxSesxQrnYcxL/ej/+Mes/+vsJLZAnqj4edo3r8oX05dn4pak3rn7afas7yhfvoLHUaXduC/G0Lnr2RXb72d9R7nyFYiOifEoqgu3Y8eO+PsTvhlPpcpVkpk7MNWuU4f169exedMmTp48ybixY2jTtp3XYaVaUmrUhsMAACAASURBVJ9lH7w/mu9mzuCjTz6LP8cgmAT7fkmoWLHiLFmyiKNHj+Kc4/vZsyhfoaLXYaVLKO0XyRjBdnWFSkBf59zNZhYDPAvUBg4C35lZWyC5UtqTQDPn3C4zy+0fGwTsds7VNbNIYJGZzfBPqw9Ucs79de6KzGyQf1mKFS+eEdsWb+eOHQzs34fTcXGcPn2a6zt1pnWbtjRs1Ji+vW9kxPDXyBEVxVsj383Q570QBfNdytiXfO0TEeFhjJ2+nJkLf+PWZ8cy7L7riQgP48TJWG57dgwADw9sSd5cOXjtId8h8lNxp2l808sAfD6sH3lz5SD2VBx3Pf9l/AlqgWbnjh0M7NebuLg4TrvT3NCpC63btPU6rDQ5evQo38+ayetvjjxr/MtxY4OqVaHXjd2ZN3cOe/fupXSJGB5/4il+mDuH1atWYmZcVqIEb7w1yusw0ywiIoJXh4/gujYtiYuLo3efflSqXNnrsFItqc+yS7Nnofhll9GsSUPAd2Tqkcee8DbYNAj2/ZJQ3Xr16Hh9JxrUrUlERATVqtWg/8BBXoeVLqG0XyRjWGI9LIHCzIYCh51zL5lZGWCac66sf9oNQBvnXD//48FAaeARYK9zLrd/vBtwtXNugL+iWwwYB3ztnPvbzL4BKgJnMqlcwAB8/yzvQefcNSnFWbNWbbdg0dIM224v5a1/V8ozBYn9i4d7HUKGiTsduO/TtAoPC+zDW/+rAvm7ID0C/TCqBL/sWWy5c662V88fWaisK9r9Na+ePt7m4W09fR2SE2yV3CMJ7if1CXb6nGnZEtwfCNQD2gKrzKyqf95bnHOzEq7EzK4+5/lEREREJEgEXzPUvxYBV/qvxhABdAPmOudOA/vNrKz/5LSOCZYp5ZxbBDwO7AeigW+BW86cXGZm5c0se6ZuiYiIiEhaWQDcAliwVXLjOee2mtkTwBx8L/Mk59wU/+QH8fXm/gWsBSL946+aWUn//DOcc2vM7FegOLDSf3hrN9A+0zZERERERDJcQCe5zrmhCe6vB6qfM/1j4ONElhsLjE1k/LzTLJ1zccBD/ltC3/lvIiIiIhJkAjrJFREREZHE6QTL5AVzT66IiIiISKKU5IqIiIhIyFG7goiIiEiwMbUrpESVXBEREREJOarkioiIiAQZA1TITZ4quSIiIiIScpTkioiIiEjIUbuCiIiISNAxnXiWAlVyRURERCTkKMkVERERkZCjdgURERGRIKRuheSpkisiIiIiIUdJroiIiIiEHLUriIiIiAQhXV0hearkioiIiEjIUSVXREREJNiYTjxLiSq5IiIiIhJylOSKiIiISMhRu0IGORXnvA4hQ+xfPNzrEDLMtW/+6HUIGWbKkAZeh5BhVv910OsQMkzV4rm8DiHD7D100usQMlSBnJFeh5BhTsWd9jqEDBMRrtpaRjEgLEz9CsnRb5uIiIiIhBwluSIiIiISctSuICIiIhKEdHWF5KmSKyIiIiIhR5VcERERkSCk/3iWPFVyRURERCTkKMkVERERkZCjdgURERGRYKN/65siVXJFREREJOQoyRURERGRkKN2BREREZEgY+jqCilRJVdEREREQo4quSIiIiJBx1TJTYEquSIiIiIScpTkioiIiEjIUbuCiIiISBBSt0LyVMkVERERkZCjJFdEREREQo6S3AByy+D+lCpemHq1qp437fVXXyZn9nD27d171vjyZUvJnSML33z9ZWaFecEOHDhA966dqFalAtUvr8iihQu9DuksWcKNt7pezuge1fjgxur0qV8MgOGdqvBuj2q826Ma4/rX5pm25eOXuf2KknzSuwaje1ajbIEcZ63vkqzhfNG/Fnc0K5mp25EaFcuVpE7NqtSvU4PGDeoA8PVX46hdvQpR2cL5afkyjyM82zMP3kqrOmXo3qpB/NjIV56lZ+uG3Ni2Mbf37sieXTsAWL5oHs2rFefGto25sW1jRr/xQvwyYz54m+6tGtCtVX0+/+CtTN+O1Dp+/DiNG9Slbs1q1KxWmWeeetLrkFLl4MEDDO7TnSvrVaV5/WosX7qIA/v/psf1rWlapzI9rm/NgQP7AZgxdRItmtSm1RV1adO8IUsWLfA4+tSZ8e10qlYuT+UKZRj24vNeh5OiIYP6U7JYYerW/Pf75dGHH6Bm1UrUr12d7l2u58CBAwCcPHmSmwf2o16tajSoU4N5c+d4FHXaDB7Qj+JFC1KrehWvQ8k0Zub5LZApyQ0gPW/qzdcTpp43vnXLFmbPnkmxYsXPGo+Li+PJxx7mqmtaZFaIGeK+u++kRYtWrFrzG0uWr6JCxYpeh3SW2DjHPV//woDPVjHgs1XUvSw3FQtHceeXaxj42SoGfraKtTsPMW/93wDUK5Gb6NzZuPGjFbw8awN3Ny911vr61S/G6m3/eLEpqTJtxmwWLV3B/IVLAahUqQqfjf2Kxk2aehzZ+dre0IPXPjj7D7obB97Bp1N/5JPJ82l8ZUvee+PF+GnV6zTgk8nz+WTyfAbc/iAAG35fy4Sx/+WD8bP4ZPJ8Fsz+lr82bcjU7UityMhIps+czZKfVrF42UpmfDudxYsWeR1WioY+fC/NrrqG7xevZvoPSylTrgJvDn+JRk2v5Ielv9Co6ZW89dpLADRqeiXf/rCU6XOX8NIbo3jwziEeR5+yuLg47rrjViZMmsaK1WsZN+Zzfl271uuwktXzpt6Mn3j290vz5lez5KfVLFq2kjJly/HyMF+y/uH7owFYvHwVE6d8yyMP3c/p06czPea0uql3HyZMnu51GBJAlOQGkEaNm5Inb97zxh9+4B6eee6F8/5iGvnWCNp1uJ4CBQpmVogX7J9//mH+/B/o068/AFmzZiV37tweR3W+47G+D/SIMCM8zMD9Oy17ljBqxORi/kZfktuoVF5m/LoHgF93HiZHZAR5L8kCQLmCOchzSVaW/nkgczfgAlSoWJFy5cunPKMHatRtRM7cec4ai7o0Z/z9Y8eOplhZ2LzhD6rUqE227JcQERFBjbqNmDtj8kWJ90KZGVFRUQDExsZyKjY24Csnh/75hyUL59Ptxr6A7z2eK1duZk6dRKduNwLQqduNzJg6EYAcUVHx23T06JGA3z6ApUuWULp0GUqWKkXWrFnp3LUbkydN8DqsZDVu0pQ8ec7+frnqmhZERPjOP69Ttx7bt24F4Ldf19LsyuYAFChYkFy5cgfcUZ3ENG7SlLyJfIfK/y4luQFu6uSJFCkazeVVq501vn3bNiZP/Ib+Awd7FFn6bNq4kfz5CzCof1/q167BkEEDOHLkiNdhnSfM4N0e1Rg/sA7L/zrIr7sOx09rUjofP205yNGTcQDkj8rK7sMn4qfvPXyC/FFZMWBIkxKMnL85k6NPPcNo16YljerX5v3R73gdTrq9/dIzXNeoMt9OGMegux6JH/95xRJ6tmnEXX07sfGPXwEoVa4iK5b8yMH9f3P82FF+nDuTXTu2ehV6iuLi4qhXqzrFixak+dXXULdePa9DStZff24ib74C3HvbQK5tVo8H7ryZo0eOsHfPbgoVLgJAocJF2Lt3T/wy0ydP4Mp6VenTrSPD3hjlVeiptn37NmJiisU/jo6OYdu2bR5GdOE+/ugDrmnZCoAql1dlyuSJnDp1is2bNrFyxXK2bd3icYRyHvNdXcHrWyALqCTXzOLMbKWZrTGzcWZ2SQrzf2hmnfz355hZ7cyJNHMcPXqUYS/8H48+8dR50x66/26eevb/CA8P9yCy9Dt16hQrV/zEwMFDWLRsBZfkyMFLAdjPdtrBwM9W0fm9ZVQoFEWJfP/+KjYvn5/Zf/z7BW0k/i5vX7UwizfvZ8/hkxc93vSaNWc+Py5ezviJUxk18i3mz/vB65DSZch9jzNpwS+0bN+ZcR/7kvXylasx4Yef+XTKAjr3GsT9N/cEoGSZ8vQafCe39+7AnX1voGyFKoRHBO7VFMPDw1m8fCXrN29l2dIl/LJmjdchJevUqVOsWb2Cm/oOYtqcxWS/JAdvDR+W7DKt2rbn+8WrGf3xF7z0n/M/7wKNc+68sWCoQCdl2PP/ISIigq7dfe+RXn36ER0dQ9OGdXnw/rupV79BQL9HRJISUEkucMw5V905VwU4CdzsdUBnmFmmZ5ObNm7gzz830ahuDaqUL8W2bVtp0qA2u3buZMVPy+nXqwdVypdiwvivuOeu25g88ZvMDjHNomNiiI6Jia9GdbyhEytX/ORxVEk7cjKOldsOUvcyX0tFzmwRVCgUxcJN++Pn2XP4BAWjIuMf54+KZO/hk1QucikdqhXh8741GdKkBC0qFGBgo+LnPYeXihQtCkDBggVp174Dy5Yu8TiiC9OyXSe+nz4J8LUxXJLDd6i/0ZUtiDsVy4G/9wHQrksv/jvxB0aNmUbO3HkoVqK0ZzGnVu7cuWl6RTNmzAjsnsMiRaMpUjSaGrXrAtC6XUfWrF5J/gIF2bXTd1Lgrp07yJ+/wHnL1mvYhL82b+TvfXvPmxZIoqNj2Jqgsrlt21aK+t9LwebTjz9i2rQpvPfhJ/GJekREBM8Pe4Ufl/zE2C+/4cDBg5QpU9bjSOVchk48S0mgJbkJzQPKmFkJM4svXZjZfWY2NLkFzay7mf3srwi/4B8bYmYvJpinj5m94b9/o5kt8VeRR51JaM3ssJk9bWaLgQaJPtlFVLnK5Wz8aydrft/Imt83Eh0dw7yFyyhUuDA//7Yhfrx9xxt45bURtG3XIbNDTLPChQsTE1OMP37/HYA5s2dRoWIlj6M6W67sEeTI6vubJmt4GLWK5eav/ccAuKJsPhZt2k9s3L+VnB837qdFRd8XdsXCURw5cYq/j8by3Lfr6Pb+crp/8BNvz9vMjN/28O6CvzJ/g5Jw5MgRDh06FH9/1nczqVQ5+M5KTnjS2LzvpnFZad+X8b49u+Irbr+sWs7p045c/p7Ev/2Hyndu38KcbyfR4rpOmRx16uzZsyf+jPdjx44xe9Z3lC9fweOoklewUGGKRMewYd0fACz44XvKlq/INde25csxnwDw5ZhPuKb1dQBs3rghfj/9vGoFJ0/GkidvPm+CT6Xadeqwfv06Nm/axMmTJxk3dgxt2rbzOqw0mzljOq++PIyxX37DJZf8e7Tq6NGj8W1ks7+bSUR4RMB9ToukRkAefzCzCOBaIM0lCzMrCrwA1AL2AzPMrAPwJbAQeMA/a1fgOTOr6L/fyDkXa2ZvAT2B/wI5gDXOuScSeZ5BwCDgvKsepFffXj2YP28u+/bupULp4jzy+JP06tM/Q9YdSF557Q369urJyZMnKVGqFO+M/sDrkM6SL0dWHrqmDGFhRhjGnHV7WeSv3DYvl5/Plp3de7do837qlcjNJ71rcuJUHC/MXO9F2Gm2e9cuunW5HoC4U6fo0q07LVq2YuKE8dx79x3s3bOH6zu0pWrV6kycEhjVw8fu7M9Pi+dzYP8+2jaqxKA7H2LBnJn8tXE9YWFG4ehiPPjMqwDMnjaBrz57n/DwcCKzZefZ4e/FVx0eurUXBw/8TUREBPcPfYmcuQLv5EeAnTt2MLBfb+Li4jjtTnNDpy60btPW67BS9PTzr3LH4D7Exp6k+GUleWnEO7jTpxnSrydjP/2QotHFGPnBZwBMnTSer8Z+SpYsWciWLTtvvvdxwFeHIiIieHX4CK5r05K4uDh69+lHpcqVvQ4rWX1v6sE8//dL+dLFeeSxJ3ll2AucOHGC9m1aAr6Tz4aPeJs9u3fT4bprCQsLo2jRaN59/yOPo0+dXjd2Z97cOezdu5fSJWJ4/Imn4k9yFu/5C4jLgG3OubZmVhIYA+QFfgJucs6dNLNIfDlYLWAf0NU5t9m/joeB/kAccIdz7ttknzOx3iKvmFkc8LP/4TzgXqAoMNnfwoCZ3QdEOeeGmtmH/mlfmtkc4D4gGrjBOdfLP39/oLJz7h4zmwE8AawDlgKlgVuBR4Dd/ufNDnzuX/8pINI5F5dc3DVr1XZzFwT3Yd4zskQEcnE/ba5980evQ8gwU4Zk+oGEi2bN1sC9nFpaVS2ey+sQMsyef06kPFMQKZAzMuWZgsSpuMC/fFdqRYSHzndM9iy23Dnn2blAOaLLu4pDRnr19PGWP948Va+Dmd0D1AZy+pPcL4CvnXNjzGwksMo597aZ3QJUdc7dbGbdgI7Oua5mVgn4HKiLLzf8DiiXXI4WaL9tZ3pyqzvnbnfOnQROcXac2VJYR3IlgLFAF+AGYLzzZfgGfJTgecs754b65z+eUoIrIiIiIkkzsxigDTDa/9iA5viOsgN8BJzpuWzvf4x/+lX++dsDY5xzJ5xzm4D1+BLeJAVakpuYXUBBM8vnL2GndKxuMXCFmeX3l8a7A3P9077G9yJ2x5fwAswCOplZQQAzy2tml2X0RoiIiIiEoPxmtizBbVAi87yGr130zGGJfMAB59wp/+Ot+I7E4/+5BcA//aB//vjxRJZJVED25Cbk75N9Gl/yugn4LYX5d/h7Nr7HV6Wd6pyb4J+238zWApWcc0v8Y2vN7DF8vbthQCy+FoY/L9pGiYiIiFygAOlf35tcu4KZtQV2O+eWm1mzM8OJzOpSmJbcMokKqCTXOReVxPjrwOuJjPdJcL9ZgvufAZ8lsa7zKsHOubH8W9lNMR4RERERSZVGQDsza42v5TQnvspubjOL8FdrY4Dt/vm3AsWArf4LEeQC/k4wfkbCZRIVDO0KIiIiInIOr//bWWoKyc65h51zMc65EkA3YLZzrie+I+5nrt/YGzjzv7En+h/jnz7bfw7VRKCbmUX6r8xQFkj2rP+AquSKiIiIyP+EB4ExZvYssAJ4zz/+HvCxma3HV8HtBuCc+8V/RYa1+C5KcGtKFwdQkisiIiIiF51zbg4wx39/I4lcHcE5dxzonMTyzwHPpfb5lOSKiIiIBBsLmBPPApZ6ckVEREQk5CjJFREREZGQo3YFERERkSBjpO7qBv/LVMkVERERkZCjJFdEREREQo7aFURERESCjunqCilQJVdEREREQo4quSIiIiJBSIXc5KmSKyIiIiIhR0muiIiIiIQctSuIiIiIBCGdeJY8VXJFREREJOQoyRURERGRkKN2BREREZFgY7q6QkpUyRURERGRkKNKbgaIO+3451is12FkiLxRWb0OIcNMu7Wh1yFkmHzdP/A6hAyz/b+9vA5BEpEnRxavQ5AkRISrHiXnM3TiWUr0zhERERGRkKMkV0RERERCjtoVRERERIKQ2hWSp0quiIiIiIQcJbkiIiIiEnLUriAiIiIShNStkDxVckVEREQk5KiSKyIiIhKEdOJZ8lTJFREREZGQoyRXREREREKO2hVEREREgo3pxLOUqJIrIiIiIiFHSa6IiIiIhBy1K4iIiIgEGcN0dYUUqJIrIiIiIiFHSa6IiIiIhBy1K4iIiIgEIXUrJE+VXBEREREJOUpyA0j9auW4qlEtWjStS+vmDQF4+flnqFW5FC2a1qVF07rMmjn9rGW2bf2LcsXyMfKNV70IOUVbt2yh1TXNqXF5JWpVq8KbbwyPn/b2m29QrXIFalWrwqMPPeBhlOmzZcsWWl59JdUvr0jNapUZ8frwlBfywNo3O7Hk5Q4sHNaOec9fB0CeqKxMerwFq16/gUmPtyB3jqwA3NWuCguHtWPhsHYsfbkD/4ztTZ6orJQtmjN+fOGwduz4qCe3tq7k5WZx6+ABlLmsCA1qV4sfW71qJVdf0ZDG9WrRrFE9li9dAsCB/fvp2fUGGtatQfMm9Vn7yxqvwk6zGd9Op2rl8lSuUIZhLz7vdTgpGjKoPyWLFaZuzarxY88MfYL6tavTsG5N2rdpyY7t2wGYN3cO0QXz0LBuTRrWrcnzzz3jVdhpFmz7JaHBA/pRvGhBalWvEj/27NNDKXVZNPVqVaderepMnzbVwwjTJ1g+kzNSmJnnt0BmzjmvYwh61WrUclNn/3jB66lfrRxTZ/9I3nz548defv4ZcuSI4ubb7050mYG9uhEWFkaNWnWSnCct8kZlveB1JLRjxw527txBjRo1OXToEI3q1Wbsl+PZvXsXLz7/H76eMJnIyEh2795NwYIFM/S5L/ZZpzt27GDnjh3UqOnbtob1avHFl99QsVLGJ3/5un+Q7mXXvtmJJg9NYt+hE/Fjz95Ym/2HT/DyNz9zb4fLyZ0jksc/XXbWctfWKsbtbSvT+qmz/7AKCzPWj+rCFQ9PZsveI2mOZ/t/e6VvQ86xYP4P5MgRxZCBfVm4bBUAHa9rxS233ck1La9lxvSpDH/1JaZ8O5vHH3mAHDmieOjRJ/jj99+47+7bmTh15gXHEJkl/ILXkZy4uDgur1SOKdNmEh0TQ+P6dfjok88vyu/YqbjTGbKe+fN+ICoqikH9+7Dkp9UA/PPPP+TMmRPw/XH7269rGT7ibebNncPw117my/GTMuS5E4oIv3g1nMzcLxfD/Hm+986Afr1YvtL3B9+zTw8lR1QUd99zn8fRpV9mfiYDZM9iy51ztS/KylMhZ/GKrt4D6f9uyCjf3d7A09chOarkBrHpUyZSvERJylWo6HUoSSpSpAg1atQE4NJLL6V8hYps376Nd0eN5N77HyQyMhIgwxPczFCkSBFq1Px32yr4ty0YtKlTnE/nrAfg0znraVu3+HnzdGlcki/mbzxv/MoqRdi481C6EtyM1KhxU/LkzXvWmJlx6NAhwJdYFSlSFIDff/2VK65sDkC58hX4688/2b1rV+YGnA5LlyyhdOkylCxViqxZs9K5azcmT5rgdVjJatykKXnynL1fziS4AEeOHAn6yx4F435JqHGTpuQ9570TCoL5M1kuDiW5AcTM6HFDW669sgGffDg6fvzD0W9zdePa3HvbIA4c2A/A0SNHeGv4y9zzwKNehZtmf27ezKpVK6hTtx7r1v3BgvnzaNqoPi2uasayZUu9Du+C/Ll5MytX+rYt0Dhg4mMtmf/CdfS9uhwABXNlY+eBYwDsPHCMAjmznbVM9qzhXF09hgmLN5+3vk6NSjJuwaaLHXa6/N+Lr/DEIw9SuWwJHn/4AZ54+jkAqlxelUkTxgOwfOkStvz1J9u3bfUy1FTZvn0bMTHF4h9HR8ewbVtwfmk/9cRjVCh9GV+M+YxHn3gqfnzJ4kU0qFOD69u15te1v3gYYeqF0n5JaORbI6hToyqDB/Rj//79XodzQQL5MzkjmXl/C2RBneSaWZyZrTSzX8xslZndY2ZBu03jp33P9DmL+PiLCXz03igW/TiPXv0GseCnX5nxwxIKFi7MM489CPjaGAYOuZ0cUVEeR506hw8fpnvXTrz40qvkzJmTuFOnOHBgP3PnL+S551/kph5dCdbWmcOHD9O9yw0Me/m1sypWgeKqx6bQ6MGJdHxuJoNbVqRRxUIpLtO6dnEW/baL/YdPnjWeJSKM1rWLM35hYCa57707iudefJlf1m3mPy++zO1DBgJw130PcmD/ARrXq8WokW9StVoNwiMC/+Iyib0ngrUK+uTTz/Lbhj/p0q0H77z9JgDVatRk7R+bWLh0BYNvuY3una/3OMrUCaX9csbAwUNY+/sGFi9fSeEiRXjo/nu9DindAv0zWTJP0CaEfsecc9Wdc5WBa4DWwJPnzmRmgf9tBhT2H1rNX6Agrdq0Y+XyZRQoWIjw8HDCwsLo0asfK3/y9U2uWL6E54Y+Qv1q5Xhv5AjeePVFPnj3bS/DT1JsbCw9unaiW/cedOjo+xIrGhND+w7XY2bUqVOXsLAw9u7d63GkaRcbG0v3LjfQtXvP+G0LNDv3+yq2e/45zsQlf1K7TAF2HzxO4dzZASicOzt7/jl+1jJJVWtbVI9h1aZ97D54/LxpgWDMp/+lXfuOAHS4vhM/+Y8Q5MyZk7feeY/5i5czavSH7N27h8tKlPQy1FSJjo5h69Yt8Y+3bdtK0aJFPYzownXp2p0J33wN+PZLlP8P9ZatWhMbGxsUnwOhuF8KFfr3u6Zf/4EsW7bE65DSJRg+kyXzBHuSG885txsYBNxmPn3MbJyZTQJmAJjZ/Wa21MxWm9lT/rEcZjbFXwleY2Zd/ePPm9la/7wvXez4jx45wmF/L+HRI0f44ftZlK9YmV07d8TPM33yRMpXrAzA11Nns2jVHyxa9Qf9b76N2+9+gL4Dh1zsMNPMOceQQQMoX6ECd9x1T/z4de3aM+f72QCs++MPTp48Sf78+ZNaTUByznHzwP6Ur1CRO+++J+UFPHBJZARR2SLi719VLZq1W/Yzddlf9GxWBoCezcowZelf8cvkvCQLjSsVZnKCsTM6Ny7JuET6dANF4SJFmT9vLgA/zJlNqdJlAThw4AAnT/qq0v/94D0aNm4SFBWe2nXqsH79OjZv2sTJkycZN3YMbdq28zqsNFu/fl38/alTJlGufHkAdu3cGV8VXbZ0CadPnyZfvnyexJgWobJfEtqx49/vmgnfjKdS5SrJzB2YguEzOSP52gXM81sgC4oKZ2o55zb62xXOnMXUAKjqnPvbzFoAZYG6gAETzawpUADY7pxrA2D/z959h0dVbX0c/64khCpNivTeOwECUkRUEJGmIkURBMR27Q27vopyxauCgOi1wEUFREV6E+lKbwIqoKIQUAhVOpns948MkUAyBEg4M+Pv8zzzZGafMmvnZGb2rKyzj1keM8sPdAQqO+ecmeU9/bnMrC9Jg2qKnVKbdb527fqTPt07A+BLSKDDTZ258uqW3H/X7az/fi1mRomSpRjwxpALfq6L6btvF/HpJ6OoXr0GsfXqAPDiS/3p0bMXd93Rm3q1a5AlOpr/fjAi6F8sp/t20Sl9i6kNwIsvv8K1ra/zOLK/FcqTjTGPXQVAZKTx2cJfmLU6jhWb4xn1cHNua1GRbfEHufWNOcnbtGtQitlr4jh8LCHFvrJHR9KiZlHuf+/CZxLJCL173MLC+fPYvTuequVL0e+Zo1Nt5AAAIABJREFU5xk0dDj9Hn2YBF8C2bJmZdCQpP9ubPzpB+7qczuRkZFUqlyFIe/81+Po0ycqKoo3Bw2hbZtW+Hw+evTsRdVq1bwOK6Dbu3djwYJ57I6Pp1K5kjz1zPPMnDGNTRs3EhERQYmSJRn0dtJx+Wr8F7z/3nCioqLIlj07H436NCTeB0LxuJzqtlu7smDeXOLj4ylXujjPPvci8+fNZe2a1ZgZpUqX5u1h73od5jkLhfdkubhCegoxMzvonMt1Wts+oBLQGrjCOXe7v/114CZgn3/VXMCrwAJgBvAZMNk5t8Bf3rACWA5M8benLE48RUZNIRYMMnoKMS+Fwodlel3IFGLBJqOmEAsGmT2F2MWUUVOIBYvMnEJMBLyfQixPqSru8n4jvHr6ZNPvaagpxC4GMysL+ICd/qZT5zgy4FV/DW9t51x559wHzrmNQAzwPfCqmT3nnEsgKeP7BdABSDlRqIiIiIgEtbApVzCzgsBwYIi/xOD0VWYAL5nZJ865g2ZWDDhB0u9gj3PuYzM7CPQ0s1xADufcVDNbDGy+iF0RERERkQsU6oPc7Ga2GsgCJACjgDdSW9E5N9PMqgDf+QfAB4FbgfLAQDNLJGnQezdwCTDBzLKRlAG+8EuJiYiIiGSgcCrLywwhPch1zqVZEOecGwGMOK1tEHD6xax/JinLe7oGFxieiIiIiHgkrGpyRUREREQgxDO5IiIiIv9UqlYITJlcEREREQk7yuSKiIiIhBgDDKVyA1EmV0RERETCjga5IiIiIhJ2VK4gIiIiEoIiVK0QkDK5IiIiIhJ2NMgVERERkbCjcgURERGRUGOmy/qehTK5IiIiIhJ2NMgVERERkbCjcgURERGREKRqhcCUyRURERGRsKNMroiIiEiIMSBCqdyAlMkVERERkbCjQa6IiIiIhB2VK4iIiIiEIFUrBKZMroiIiIiEHWVyM0BkhJEvZ7TXYWSIcLp6SoIv0esQMsyOUT28DiHDFL5hiNchZJi9E+/3OoQMcywhfF4vAFGR4ZPD8SU6r0PIMJER4fMZI8FPg1wRERGREBROianMED5fdUVERERE/JTJFREREQkxZjrx7GyUyRURERGRsKNBroiIiIiEHZUriIiIiIQgXdY3MGVyRURERCTsaJArIiIiImFH5QoiIiIiIUjFCoEpkysiIiIiYUeDXBEREREJOypXEBEREQlBuqxvYMrkioiIiEjYUSZXREREJMQYEKFEbkDK5IqIiIhI2NEgV0RERETCjsoVREREREKNmU48OwtlckVEREQk7GiQG8R8Ph+NGtTlxg5tAZg75xsuj42hXp0a3NG7JwkJCd4GeB6OHj1Kk0YNaFC3FnVrVeOlF5/3OqRzMmzIYBrUrUn9OjUY+vYgAL5fu4YWVzQmNqYWnW5ox4EDBzyOMm333tmbciUvo2FMzRTt7w4bQkzNKsTWrcGzTz0BwJ7du7m+1VUULZCbRx+8z4twz/DjRz1ZNqwbi9/uysJBnQF4pVdjVr97K0uHdmPsM23IkzMagCxREbz70NUsG9aNJUO60rRGseT93HxFRZYN68bSod2Y8H/tuTR3Nk/6czZ39ulFyaKFiKld3etQ0u3o0aNcc0UjrmhYl8b1ajHg5RcBeH/4UOrXrEyBXFnYHR+fYpuF8+fRvFEMjevVom2rFl6Efc5mzphOzWqVqFa5PANfG+B1OOdk408/0ah+neRbkQJ5GDr4LZ7u9xh1alQhNqYWXTrdwL59+7wO9ZyE4utFMpcGuUFs6NuDqFS5CgCJiYn07dOTkaNGs3zV95QsWZJPRo30OMJzlzVrVqbP+oalK9ewZPlqZs6YzpLFi70OK102rF/HiA/fZ+7CxXy3bBXTp05h8+ZN/OvuvvzfS6+wZMUa2rbrwKA3Xvc61DR1696DLyZMTdE2f94cpkyeyLfLVrNk5ffc/+AjAGTNlo2nn3uRl159zYtQ03Rtvy9peN9omjwwFoDZq7YSc/cnNLj3UzbF7eWxm+sB0OvapA+6+vd8yvVPf8WAPk0xg8gIY+Cdzbi235c0uPdT1m2J5662tTzrTyDde/RkwuTpXodxTrJmzcr4KbOYt3glc79bzjdfz2D50sU0aHQ5X0yaTomSpVKsv3/fPh5/6D4+/mw8i5av4cNRYzyKPP18Ph8P3n8vEyZNY9XaDYwbM5ofNmzwOqx0q1ipEt8tW8V3y1axcPFysufIQdv2HWlx1TUsW/U9S1asoUKFCvzntVe9DvWchOLr5UKZeX8LZhrkBqm4bduYPm0qPW/vDcDu3bvJGp2VChUrAtDiqmv4avyXXoZ4XsyMXLlyAXDixAkSTpwImZqin378gfoNYsmRIwdRUVE0adqMSRO+YtPGn2jctBmQdFwmfBW8x6Vxk2bky58/RdsH7w3noUcfJ2vWrAAULFQIgJw5c9KocROyZQvOLOdJs1f9ji/RAbD0xz8oViDp76tyyfzMWb0VgF37j7D/0DFiKhTG/HVsObNlAeCSHNHs2H3Qm+DPoknTZuQ/7XgFu9Nf4yf8r/GatepQslTpM9b/4rPRXN+uA8VLlAT+/vsLZsuWLqVcufKUKVuW6OhoOnXuwuRJE7wO67zM/WY2ZcuWo2SpUlx1TUuiopJO1akf25C4uDiPozs3ofh6kcylQW6QevzRh+j/6r+JiEg6RAUKFOBEwglWrlgOwPgvP2fbtq1ehnjefD4fsTG1KVm0EC2uvoYGsbFeh5QuVapVZ9HCBezevZvDhw8zY8Y04rZtpUq16kyZPBFIOi5xIXZcft68ie8WLaRF00Zcd82VrFi+zOuQ0uScY9LLHVg0qAu9rq12xvLbWlZjxvLfAPj+l120bViWyAijVOHc1ClfiOIFc5HgS+SBIXNYNuwWfvm4N1VK5mfEzNDJwoUCn89H80YxVClTlOYtriamftqv8Z83b2Lfvr20u/YqWjRpwNhPR13ESM/P9u1xFC9eIvlxsWLFQ25AeNLn48Zw081dzmgfNeIjWra61oOI5Fyc/NLu5S2YheUg18wuM7MxZvazmW0ws6lmVvEc95HXzO7JrBgDmTZlMgULFqRO3ZhT42HkqNE88djDNGscyyWXXJL8jTvUREZGsmTFajZv2cbyZUtZv26d1yGlS+XKVXjokcdo36YVHdteR40aNYmKimLYu+/z3+HDaNqoPgf/+oss0dFeh3pOEhIS2Ld3L7Pnf8tLr/ybnrd2wTnndVipavHo51x+/xg6PDeBO6+vSePqRZOXPd65Hj5fImPm/ATAyJkbiIs/yKJBXRjYtxmLf9hBgs8RFRnBHW1q0PBfoyl76wes+zU+ucRBMkZkZCRzv1vB2p+2sHL5Mn5Yn/ZrPCEhgTWrVzL6i4mM+2oqr//7FTZv2ngRoz13qb0+gv3DPjXHjx9nyuRJdLyxU4r21wb0JzIqis5db/EoMpGMEZqjpAAs6Z1mPDDSOdfF31YbKAycyztnXuAeYFiGB3kW3323iClTJjFjxjSOHj3KXwcO0Ktndz4cMYpZ38wH4OtZM9m8adPFDi1D5c2bl2ZXNGfmzOlUqx4aJwr0uL03PfwlJC88+zTFihenUqXKTJgyA4BNmzYyY/rUQLsIOkWLFaNth46YGTH1GxAREcHu+HgKFCzodWhn2LHnEJBUfjDxu1+oX7Ewi9Zt55arKnNdgzK0fmp88rq+RMfj/12Q/HjO653YHLePWmULAPDrH/sB+HzBJh7tpEFuZsiTNy+Nm17B7K9nUqVa6q/xosWKk//SAuTMmZOcOXNyeeMmrP9+LeUrnFNe4qIqVqx4iv+kxcVto2jRogG2CE4zp0+jdu26FC5cOLntk1EjmT51CpOnfx2SA3eRU4VjJvdK4IRzbvjJBufcamChmQ00s3Vm9r2ZdQYws1xmNtvMVvrb2/s3GwCUM7PVZjbwYnbg/15+lU2/bOWHjb8yctRormjegg9HjGLnzp0AHDt2jDdef43ed9x5McPKELt27Uo+Y/fIkSN8M/trKlWq7HFU6bfLfwy2/v47EyeM56abuyS3JSYmMvDV/vTq09fLEM9Zm7btmT93DgCbN23kxPHjXFqggMdRnSlH1ihyZc+SfP/qOiVZ/9serokpxSOd6nHTi5M5cuzvGUeyZ40iR9ak7/Et6pQgITGRH7fuYfvuQ1QumZ8CubMDcFWdkvy0dc/F71CYit+1i/2nvMbnz5lNhYqV0ly/dZu2LP52IQkJCRw+fJgVy5ZRMcjfE+rVr8/mzZvY8uuvHD9+nHFjx9Dm+nZeh3XOxn02hk6d/y5VmDVjOm+8/hpjv5hAjhw5PIxM0uPkZX29vgWzsMvkAtWBFam03wDUBmoBBYBlZjYf2AV0dM4dMLMCwGIzmwj0A6o752qn9iRm1hfoC1CiZMmM70Uq3npjINOnTiExMZE+fe+i+ZWhMdXOqf7YsYM7evXA5/OR6BK58aabua7N9V6HlW63dOnEnj27yZIlC2+89Tb58uVj2JDBvDc8KeHfrkNHuve43eMo09brtm4sXDCP3fHxVClXkieffZ7uPXpx7529aRhTkyzR0bzz/kfJGZwalcpy4K8DnDh+nCmTJjB+8nQqV6nqSeyF8uVg7DNtAIiKjGDs3J+YteI31r1/G1mzRDK5fwcAlv70B/cPmUPBPNmZ9HIHEhMd23cfpPfrM4GkbPArny5h1ms3csKXyO87/6LvG7M86dPZ3HZrVxbMm0t8fDzlShfn2edepGev3l6HFdCff+7gX317Jb3GEx3tb7iJVq3b8N6wt3n7rf+w888/aNawLle3upZBQ9+jYuUqtLimFc1i6xIREcGtPW9PM+sbLKKionhz0BDatmmFz+ejR89eVK12Zo14MDt8+DBzZs9i8NDkfBCPPHgfx44fo911LQGo3yA2xfJgF4qvF8lcFqy1d+fLzO4HyjjnHjqt/U3ge+fch/7Ho4BxwDTgTaAZkAhUAsoA2YDJzrmzvtvWjannFn4XvCfrnIuIYP9adg4SfIleh5BhEsPoZVr4hiFeh5Bh9k683+sQMsyhY6E373YgObOGTw7HF0ZvAJFh9BmTPYutcM55VutUoGw1d33/0V49fbKR3Wp5+nsIJM13ATPLHWhD51ywzni/Hrgplfa0Xlm3AAWBGOfcCTPbQtIAV0RERCRoqW46sEA1ueuBdf6f6097HMynw38DZDWzO042mFl9YC/Q2cwizawgSZnbpUAeYKd/gHslcHKm8r+ASy5u6CIiIiKSEdLM5DrnSqS1LJg555yZdQTeMrN+wFFgC/AgkAtYAzjgcefcH2b2CTDJzJYDq4Ef/fvZbWaLzGwdMM0595gH3RERERFJlfK4gaWraMnMugBlnXOvmFlxoLBzLrWTu4KCc247cHMqix7z305dNx5olMZ+umV8dCIiIiKS2c46hZiZDSFpWq7u/qbDQOicbikiIiIi/zjpyeRe7pyra2arAJxze8wstC7pJCIiIhJGzCBCJ54FlJ6LQZwwswiS6lgxs0tJmmpLRERERCQopWeQOxT4AihoZi8CC4F/Z2pUIiIiIiIX4KzlCs65/5nZCuBqf1Mn51wwTyEmIiIiEvZUrRBYei8JEwmcIKlkIT3ZXxERERERz6RndoWngdFAUaA48KmZPZnZgYmIiIiInK/0ZHJvJemSt4cBzKw/sAJ4NTMDExEREZG06bK+gaWn9OA3Ug6Go4BfMiccEREREZELl2Ym18zeJKkG9zCw3sxm+B+3JGmGBRERERHxiBK5gQUqVzg5g8J6YMop7YszLxwRERERCRdmlg2YD2Qladz5uXPueTMrA4wB8gMrge7OueNmlhX4HxAD7AY6O+e2+Pf1JNAb8AH3O+dmBHruNAe5zrkPLrRjIiIiIvKPdgxo4Zw7aGZZgIVmNg14GHjTOTfGzIaTNHh9x/9zr3OuvJl1IenaDJ3NrCrQBahG0mQIX5tZReecL60nTs/sCuXMbIyZrTWzjSdvF9pjERERETk/hhFh3t/OxiU56H+YxX9zQAvgc3/7SKCD/357/2P8y6+ypDPs2gNjnHPHnHO/ApuBBoGeOz0nno0APgIMaA18RlJ6WURERET+2QqY2fJTbn1PX8HMIs1sNbATmAX8DOxzziX4V9kGFPPfLwZsBfAv3w9cemp7KtukKj1TiOVwzs0ws9edcz8Dz5jZgnRsJyIiIiLhLd45Vy/QCv6SgtpmlhcYD1RJbTX/z9TSwy5Ae5rSM8g95k8T/2xmdwFxQKF0bCciIiIimcFCb3YF59w+M5sLNATymlmUP1tbHNjuX20bUALYZmZRQB5gzyntJ526TarSU67wEJALuB9oDNwB9Epvh0RERETkn8nMCvozuJhZduBq4AdgDnCTf7UewAT//Yn+x/iXf+Occ/72LmaW1T8zQwVgaaDnPmsm1zm3xH/3L6B7ejslIiIiIpknRK54VgQYaWaRJCVXP3POTTazDcAYM3sZWAWcnNXrA2CUmW0mKYPbBcA5t97MPgM2AAnAvYFmVoDAF4MYT4BaB+fcDentnYiIiIj88zjn1gJ1Umn/hVRmR3DOHQU6pbGv/kD/9D53oEzukPTu5J/OgIiIkPg29Y8SFZmeahy52PZOvN/rEDJMvmZPeh1Chtk7/1WvQ8hQxxMSvQ4hw0SG0edLYmLA84REMlSgi0HMvpiBiIiIiEj6KZUTmH4/IiIiIhJ2NMgVERERkbCTnnlyATCzrM65Y5kZjIiIiIicnREysyt45qyZXDNrYGbfA5v8j2uZ2duZHpmIiIiIyHlKT7nCYOB6YDeAc24NcGVmBiUiIiIiciHSU64Q4Zz77bSUeMDJd0VEREQkc4XR7HKZIj2D3K1m1gBw/qtV3AdszNywRERERETOX3oGuXeTVLJQEvgT+NrfJiIiIiIeUSY3sLMOcp1zO/FfN1hEREREJBScdZBrZv8FzrgOn3Oub6ZEJCIiIiJygdJTrvD1KfezAR2BrZkTjoiIiIicjZnmyT2b9JQrjD31sZmNAmZlWkQiIiIiIhfofC7rWwYoldGBiIiIiIhklPTU5O7l75rcCGAP0C8zgxIRERGRwDS7QmABB7mWVOxRC4jzNyU65844CU1EREREJJgEHOQ655yZjXfOxVysgERERETk7HTeWWDpqcldamZ1Mz0SEREREZEMkuYg18xOZnmbkDTQ/cnMVprZKjNbeXHC++e6s08vShYtREzt6sltLz7/LPXr1CQ2pjbXt27J9u3bPYzw/M2cMZ2a1SpRrXJ5Br42wOtwLoj6EpxCoS8/fvE4y0Y9wOIR97Hwg3uT2+++qRFrRj/Mio8fpP891wLQpWVtFo+4L/l2aGF/alYoAsALd7Zk0/gn2PX1C15045yEwnE51b139qZcyctoGFMzua3nrV1oEluXJrF1qVGpLE1ik3JAJ06c4K4+PWlUrxb1a1fjPwODu39DBr1JvdrVqV+nBj27d+Po0aMMHzaEmlUqkCtrBPHx8V6HmG5VKpahft2aNKxfhyaN6gNw2y1daFi/Dg3r16FKxTI0rF/H4yjFC5ZWia2ZrXTO1TWzcqktd879nKmRhZCYmHpu0ZLlGbrPhQvmkzNnLvr0uo0Vq9cBcODAAXLnzg3A0LcH8+MPG3h72PAMfd7M5vP5qFG1IlOmzaJY8eI0aVifkR+PpkrVql6Hds7Ul+B0MfuSr9mT573tj188TuNeQ9i9/3ByW7O6ZXmix5V0fHQEx0/4KJgvJ7v2HkqxXbWyhRn379uo2mkgAA2qleD3P/bx/dhHKHj1C+cdz975r573tulxsf/GjickXvA+Fi1Meh++q09PFq9Ye8byp594lNx58vDEU88ybsynTJ0yiY9Gjebw4cPE1qnO5JnfUKpU6QuOIzKDzy7aHhfHNVc2Zfma9WTPnp3u3TrT6trW1KhZi7x589G65ZXM/3YZBQoUyNDnBciM/65XqViGBQHi7ff4I+TJk4cnn34uQ583Z9aIFc65ehm603NQpEJ112PQl149fbJ/t6nk6e8hkEDlCgZJg9nUbhcpvn+sJk2bkT9//hRtJwe4AIcPHwrJSaCXLV1KuXLlKVO2LNHR0XTq3IXJkyZ4HdZ5UV+CUyj3pW/HWF4fNZfjJ3wAZwxwAW6+phaffb0m+fHS9Vv5Y/dfFy3G8xWKx6Vxk2bkO+19+CTnHOO/GMdNNydd9d7MOHz4EAkJCRw9coQs0dFccknuVLcNBgm+BI4cOUJCQgJHDh+mSJGi1Kpdh1KlS3sdWoZyzvHlF+PodHNXr0MRDwQa5BY0s4fTul20CCWF5599mvJlSjBm9Cc8+8L/eR3OOdu+PY7ixUskPy5WrDhxcXEBtghe6ktwCpW+OOeY9FYvFn34L3q1T/oXa/kSBWhcqwzz/3sPM4feQUyV4mdsd9PVNfls1poz2oNdqByX9Pp20QIKFi5MufIVAGh/w03kyJGTimWKUa1iae578OEzEhXBomixYtz/4CNUKV+KcqWKkjtPHq66pqXXYZ03w2jXphWNG9bjw/ffS7Fs0cIFFCpUmPIVKngUnXgp0CA3EsgFXJLG7aIys6fNbL2ZrTWz1WYWmwH7nGtmAVPs6VnnYnrxpf5s/nUrXbrewvBhQ7wO55ylVh4TihlpUF+CVaj0pcVdw7n89iF0eOQj7ryhEY1rlyYqKoJ8ubPT7I5hPDVkGh+/lDL7VL9qCQ4fPcGGX/70KOrzFyrHJb0+/2wMN3Xqkvx4xbKlREZG8tMv21j7w88MGfQmv/76i4cRpm3v3r1MmTyRdT/9wuYtcRw+dIgxn37sdVjnbfbchXy7ZAXjJ07l3eHDWLhgfvKycWNH0+nmLgG2Dm0RQXALZoGmENvhnAuKVKGZNQKuB+o6546ZWQEg2uOwPHVzl27c0L4Nzz7/otehnJNixYqzbdvW5MdxcdsoWrSohxGdP/UlOIVKX3bEJ5UY7Np7iInz11O/Sgnidh7gq7lJNfjLf9hGonMUyJuT+H1JZQudQjSLC6FzXNIjISGBSRPGM2/RsuS2cZ+N5uqWrciSJQsFCxWiYaPLWbViOWXKlPUw0tTN+eZrSpcuTcGCBQFo16Eji7/7li7dbvU4svNTxP93VKhQIdq178DyZUtp0rQZCQkJTJgwnkXfZew5MxI6zlqTGySKAPHOuWMAzrl459x2M3vOzJaZ2Toze89/8YqT2dd/m9lSM9toZk397dnNbIw/GzwWyH7yCczsHTNb7s8WB+XIcfOmTcn3p0yaSMVKlT2M5vzUq1+fzZs3seXXXzl+/Djjxo6hzfXtvA7rvKgvwSkU+pIjWxZy5YhOvn91gwqs/+VPJs1fT/OYpHN9y5coQHRUZPIA18y4oUUNxn0dmoPcUDgu6TX3m6+pWLEyxYr/XU5SvHhJ5s+dg3OOQ4cOsWzpkqB9jy5RoiRLlyzh8OHDOOeYO+cbKlWu4nVY5+XQoUP89ddfyfdnfz2LqtWSZiX6ZvbXVKqU8jiFGzPvb8EsUCb3qosWxdnNBJ4zs43A18BY59w8YMjJbLOZjSIp2zvJv02Uc66BmV0HPA9cDdwNHHbO1TSzmsCpU6E97ZzbY2aRwGwzq+mcO/N0Wj8z6wv0BShRsmSGdhbgtlu7smDeXOLj4ylXujjPPvci06dPZdPGn4iwCEqWKsXgoaE1swJAVFQUbw4aQts2rfD5fPTo2Yuq1ap5HdZ5UV+CUyj0pVD+XIx9tTsAUZERjJ21mllLNpIlKpJ3n76R5R8/wPETPvq8PC55mya1SxO3cz9btu9Nsa/+91xL55a1yZEtC5u/6sdHk5bR/4PZF7U/6REKx+V0vW7rxsIF89gdH0+VciV58tnnua1nb74YN5Ybb+6cYt077rqHe/r2omFMTZxz3NK9J9Vr1Exjz96q3yCWDjfcSOPYGKKioqhVuw69+vRl2JDBvPXGQP784w8a1qtFq2tbM3T4+16HG9DOP/+ky803AOBLSODmLl1p2Spp6r3Px40N61IFObs0pxALNv7BZ1PgSuBOoB/wF/A4kAPID7ztnBtgZnNJGrQuMrPCwCLnXHkz+woY7Jz7xr/PlUBf59xyM7uLpEFrFEmZ4/ucc2P8+3rUOZfm/zsyYwoxEQl+FzKFWLDJ7CnELraMmEIsWGT0FGJeCp+eBMcUYr0Gez+F2CvXBe8UYgEv6xtMnHM+YC4w18y+J2mgWxOo55zbamYvANlO2eSY/6ePlP08Y1RvZmWAR4H6zrm9ZjbitH2JiIiIBA0zIyLY6wU8FuwnxgFgZpXM7NT5P2oDP/nvx5tZLuCmdOxqPnCLf5/VSRokA+QGDgH7/Znf1hkSuIiIiIh4IlQyubmAt80sL5AAbCaptGAf8D2wBViW5tZ/ewf4yMzWAquBpQDOuTVmtgpYD/wCLMroDoiIiIjIxRMSg1zn3Arg8lQWPeO/nb5+81PuxwOl/fePAKlWoTvneqbR3jy1dhEREREvqVohsJAoVxARERERORca5IqIiIhI2AmJcgURERERSSmMZpfLFMrkioiIiEjYUSZXREREJMQYaJ7cs1AmV0RERETCjga5IiIiIhJ2VK4gIiIiEoJUrRCYMrkiIiIiEnY0yBURERGRsKNyBREREZFQY5on92yUyRURERGRsKNMroiIiEgIMpTKDUSZXBEREREJOxrkioiIiEjYUbmCiIiISIhJuqyv11EEN2VyRURERCTsaJArIiIiImFH5QoiIiIiIUjlCoEpkysiIiIiYUeZ3Axw+LiP1Vv2eR1GhqhdOq/XIWSYo8d9XoeQYbJEhc/30V0HjnkdQobZO/9Vr0PIMF1HLPc6hAw1umc9r0PIMAm+RK9DyDCRkeHzXhYMzJTKDUR/bSIiIiISdjTIFREREZGwo3IFERERkRCjeXLPTplcEREREQk7GuSKiIiISNhRuYKIiIhIqDHQ5AqBKZMrIiIiImEWRtuQAAAgAElEQVRHg1wRERERCTsqVxAREREJQRGqVwhImVwRERERCTvK5IqIiIiEGM2Te3bK5IqIiIhI2NEgV0RERETCjsoVREREREKQzjsLTJlcEREREQk7GuSKiIiISNhRuYKIiIhIyDEiUL1CIMrkeuzlfv/iutgK3HJdozOWffL+2zSqkI99e3anaN+wdiWNK13KN9MmALAj7nd6dmjObW2b0q11I7789MOLEnt63dmnFyWLFiKmdvXktj179tDm2muoXqUCba69hr1793oYYdq2bdtK29ZXEVu3Oo3q1WT40MEplr/91n/IlzOK3fHxKdpXrljGpZdEM2H8Fxcz3HOy8aefaFS/TvKtSIE8DB38Fv1feoEKZYont8+YNtXrUFN1YP8+7r69K1c1qsXVl9dm5bLFbFi3lhtaX8G1zerR+5Yb+euvAwCsXrmM65rHcl3zWFo3b8CMKRM8jj79Zs6YTs1qlahWuTwDXxvgdThnyBJpvNauCm90rMqgG6vRpW7RFMv7NCrBpz3qJD+uelkuXu9Qhc97xdCodL4z9pc9SwTvd63JHY1KZnrsFyLYj8vp7u7bmzIlLqNB3ZrJbU8/+Th1a1alYb3adL35Bvbt2wfA7t27ua7lVVx2aW4eefA+r0I+L6F2XCRzaZDrsTY3dOXNDz8/o/3PHdtYtmgulxUtnqLd5/MxbOALxDZtkdxWoOBlvDd2Bv+btID3P5/FqPfeYtefOzI99vTq3qMnEyZPT9H2+msDaN7iKtb9sInmLa7i9SB9M4qKjOLlVwayZOU6Zs5ZxPvvvcOPP2wAkgbAc7/5muIlUn4Y+3w+XnjmSVpc3dKLkNOtYqVKfLdsFd8tW8XCxcvJniMHbdt3BOBf9z2YvKxV6+s8jjR1Lz71KFe0aMns79Ywde5SyleszJMP3c3jz7zM9PnLaXVdO94b8iYAlSpXY+LXi5g6dwkjx0zg6UfvIyEhweMenJ3P5+PB++9lwqRprFq7gXFjRvPDhg1eh5XCCZ/juak/8fD4DTz85QbqFM9NxYI5AShXIAc5o1P+w3DXweO8PX8L83/endru6BZTjPU7/sr0uC9EKByX093SvQfjJ6b8wtqixdUsXbmWxctXU75CRf4zMOl9OFu2bDzz/Iv0H/CaF6Get1A8LhfCSDrxzOtbMNMg12N1GjQmd54zsxmD+j/NvY+/cMZf0Lj/vUfzVm3Jl79gcluW6Giis2YF4MTx47jExEyN+Vw1adqM/Pnzp2ibPGkCt3bvAcCt3XswaeJXXoR2VpcVKUKtOnUBuOSSS6hYqTI7tscB8PQTj/DCywOw047Re+8MoW2HGyhYsNBFj/d8zf1mNmXLlqNkqVJeh5Iuf/11gKWLF9L51p4AREdHkztPXn7ZvInYy5sA0KR5C6ZPTvq7yp4jB1FRSYOtY8eOBf87s9+ypUspV648ZcqWJTo6mk6duzB5UvBloY8mJL3nREYYkRGGI2mS+h4NivO/pdtSrLvr4HF+23ME587cT9lLc5AnexZWxx24CFGfv1A5Lqdq0rQZ+fKlfB++6pqWya+L+g1i2b4t6VjlzJmTyxs3IWvWbBc9zgsRisdFMpcGuUFoweypFCxchApVaqRo3/nHdubNmkzHrr3O2ObPHdu49frGtG9WnVv7PkDBwkUuVrjnZeeff1KkSFKMRYoUYdfOnR5HdHa//7aFtWtWE1M/lqlTJlGkSDFq1KyVYp3t2+OYPOkrevW506Moz8/n48Zw081dkh+/O3wosTG1uLtvr6AsJdm65VfyX1qAx+7rS5srG/LEg3dz+NAhKlapyqzpkwGYOvFLdsT9PcBatWIpLZvU5dpm9eg/cHDyh3sw2749juLFSyQ/LlasOHFxcR5GlLoIgzc6VmXErbVYE3eATbsOcV3VQiz7fT97j5xI1z4MuL1hCUYu3Zq5wWaAUDku52LUyI+4ptW1XodxQcLxuMiFCctBrpk9bWbrzWytma02s1gz22JmBVJZt52Z9UtjP83N7PLMj/hvR48cZsSwN7jjwSfPWPZW/6e497EXiIyMPGNZ4SLF+XjyIsZ9vYKp48ewJz74B42h5ODBg9zW7WZefe0NoqKieOO1V3jy2RfOWO+pxx/mhZdeTfUYBavjx48zZfIkOt7YCYA+fe/m+x82892yVRS+rAhPPfGIxxGeKcGXwPq1q7nl9juYMmcxOXLk4J3Br/PaoHcZ9eG7tL3qcg4dPEiW6OjkberENGDmwpVMmLWQYYMGcuzoUQ97kD4ulXTn6f85CAaJDh4ev4E+o9dSoWBOql6Wi8vL5GPK+j/TvY9rqxZkxdb97D6UvkGxl0LluKTXwAGvEBUVReeut3gdygUJt+NyVpb0BdPrWzAL/lTGOTKzRsD1QF3n3DH/wDY6rfWdcxOBiansJwpoDhwEvs2caM+07fdf2bHtN7q3bQrArj+207PDFXzwxWx+XLeKZx/qDcD+vXv4bt4sIqOiuOKaNsnbFyxchLLlK7N62Xe0aN3+YoV9zgoVLsyOHTsoUqQIO3bsoGCh4P3X/okTJ+jRrROdOnelbfuOrF/3Pb9t2ULThkllDNvjtnFF4/rMnvcdq1auoHePpA+KPbvjmTVjGlFRUbRpG7zHYub0adSuXZfChQsDJP8EuL3XHdzUsa1XoaWpSJFiXFa0GHViGgDQum1Hhg/+D488+TyjxiVlcn/5eRPfzJp2xrblK1YmR46c/PTjemrWjrmocZ+rYsWKs23b35nNuLhtFC1aNMAW3jp83Me6HX9RvcglXJY7G+/cnPTfqKxREQzrVJ17xq1Lc9tKhXJR9bJctK5SkGxZIoiKiOBogo9Ry4IvExdqxyWQT0aNZNq0KUyeNivkB4ThdFwkY4TdIBcoAsQ7544BOOfiIfnb3H1m1hbIAnRyzv1oZj2Bes65f5nZCGAPUMf/szHgM7NbgfuccwsyO/jylaoxdcmm5Mcdm9fkoy/nkDf/pXw5Z01y+0uP30PjK1txxTVt2Lkjjtz58pMtW3YO7N/H2pVL6NLrnswO9YK0ub4dH48ayWOP9+PjUSO5PkgHgc457rv7DipWqsK99z8EQLXqNdj0298n9tWsUo45C5ZwaYECrNmwObn9nr69aNW6TVAPcAHGfTaGTp3/LlX4Y8cOLvOXkkyaMJ6q1aqntalnCha+jCJFi/Pz5o2UK1+RbxfMpXylysTv2kmBgoVITExkyBsDuKXHHQBs/W0LRYoVJyoqim1bf+OXzRspXiL464/r1a/P5s2b2PLrrxQtVoxxY8cwYtSnXoeVQu5sUSQkOg4f9xEdadQqlpvxa/6g16d/v1992qNOwAEuwFtzf02+f2WFSylfIGdQDnAhNI5LesyaOZ03/zOQabPmkCNHDq/DuWDhclwk44TjIHcm8JyZbQS+BsY65+b5l8U75+qa2T3Ao0CfVLavCFztnPOZ2QvAQefc66evZGZ9gb7AGTMgnIvnHuzNyqWL2Ld3N+2aVKPPA/1o16n7Oe1jy88bGTzgGcwM5xzdev+L8pWqnXdMGe22W7uyYN5c4uPjKVe6OM8+9yKPPt6PW7vezMiPPqBEiZJ8Mmac12GmavF3ixg7+mOqVqtB04ZJWb9nX3iJltcG54wD5+rw4cPMmT2LwUOHJ7c989QTrF2zGjOjVKnSKZYFkxdffYOH7rqd4yeOU7JUaQYOfo8vx37C/z58F4Br27SnU7fbAFi25FuGD36dqKgsRERE8NJrg8h/6RnVS0EnKiqKNwcNoW2bVvh8Pnr07EXVasHz2gbIlyML9zcrQ0QERGAs+nUPy7fuT3P98gVy8MQ15ckVHUn9knnpElOUB75YfxEjvnChcFxOd3v3bixYMI/d8fFUKleSp555njcG/ptjx47Rvk0rIOnks0FD3gGgWsWy/PXXAY4fP87kSROYMHk6latU9bILZxWKx+VCRYR49j2zWWo1LKHOzCKBpsCVwJ1AP+AFoLFzLs7MYoH+zrmrU8nkznHOjfTv5wXSGOSeqkqNOu6j8XMyqzsXVe3Seb0OIcMcPe7zOoQMkyUqfMrndx045nUIGeayvKF19nkgXUcs9zqEDDW6Zz2vQ8gwCb7gmjHnQkRFhs97WfYstsI559kfWqkqNd3TH03y6umT3dmotKe/h0DCMZOLc84HzAXmmtn3QA//opOfrj7S7vuhzI1ORERERDJb2A1yzawSkOicO1nYWhv4DaiR9lZp+gvInVGxiYiIiGSEkxeDkLSFz/8N/pYLGGlmG8xsLVCVpFKF8zEJ6OifhqxpRgUoIiIiIpkr7DK5zrkVQGpz25Y+ZZ3lJE0PhnNuBDDCf7/nafvaCNREREREJMjoxLPAwjGTKyIiIiL/cBrkioiIiEjYCbtyBREREZF/AlUrBKZMroiIiIiEHQ1yRURERCTsqFxBREREJMQYylSejX4/IiIiIhJ2lMkVERERCTUGpjPPAlImV0RERETCjga5IiIiIhJ2VK4gIiIiEoJUrBCYMrkiIiIiEnY0yBURERGRsKNyBREREZEQY0CEZlcISJlcEREREQk7yuSKiIiIhCDlcQNTJldEREREwo4GuSIiIiISdlSuICIiIhKCdN5ZYMrkioiIiEjYUSY3A+SIjqR26bxehyGnyRYd6XUIkorL8mbzOoQM45zzOoQMM7pnPa9DyFD5Yh/wOoQMs3fJIK9DyDAJvkSvQ5B/EA1yRUREREKOYapXCEjlCiIiIiISdjTIFREREZGwo3IFERERkRBjKFN5Nvr9iIiIiEimMLMSZjbHzH4ws/Vm9oC/Pb+ZzTKzTf6f+fztZmaDzWyzma01s7qn7KuHf/1NZtbjbM+tQa6IiIhICDIzz2/pkAA84pyrAjQE7jWzqkA/YLZzrgIw2/8YoDVQwX/rC7zj72t+4HkgFmgAPH9yYJwWDXJFREREJFM453Y451b67/8F/AAUA9oDI/2rjQQ6+O+3B/7nkiwG8ppZEaAVMMs5t8c5txeYBVwb6LlVkysiIiIi56uAmS0/5fF7zrn3UlvRzEoDdYAlQGHn3A5IGgibWSH/asWAradsts3fllZ7mjTIFREREQlBQTJLbrxz7qxXkzGzXMAXwIPOuQMBSh1SW+ACtKdJ5QoiIiIikmnMLAtJA9xPnHNf+pv/9Jch4P+509++DShxyubFge0B2tOkQa6IiIiIZApLStl+APzgnHvjlEUTgZMzJPQAJpzSfpt/loWGwH5/WcMMoKWZ5fOfcNbS35YmlSuIiIiIhBojVC7r2xjoDnxvZqv9bU8BA4DPzKw38DvQyb9sKnAdsBk4DNwO4JzbY2YvAcv86/2fc25PoCfWIFdEREREMoVzbiFplw9flcr6Drg3jX19CHyY3ufWIFdEREQkxOiKZ2en34+IiIiIhB0NckVEREQk7KhcQURERCQEhciJZ55RJjcE3NmnFyWLFiKmdnWvQ8kQM2dMp2a1SlSrXJ6Brw3wOpwLor4Ep1Duy9GjR2l6eSyxMbWJqVWdl158HoA538ymUYMYYuvV4armTfl582aPIz13oXJcfpz0HMvGPsHiTx9j4ahHAKhZsRjzRjyU3FavWkkAurSOYemYJ1g65gnmfPggNSoUBSBrdBQLRj7MktGPs+KzfjxzZ2vP+nO61D5T1q5ZwxVNGlGvdg1u7NCWAwcOeBhhYHf37U2ZEpfRoG7N5LbxX4yjfp0a5M4excoVf1986/jx49x1Ry9iY2rRqH4dFsyb60HE4hUNckNA9x49mTB5utdhZAifz8eD99/LhEnTWLV2A+PGjOaHDRu8Duu8qC/BKdT7kjVrVqbNnM2SFatZvHwVs2bOYOmSxTzwr3v4aOTHLFm+ipu7dOXfr/b3OtRzEmrH5do7h9Cw20CadP8PAP0faEf/96bTsNtAXho+jf73twNgS9xuWt4xmAZd/s2r789g6DOdATh2PIFr7xpCbNfXiO32Gi0vr0yD6qU868+pUvtMufvOPrz8ygCWr/6edu078uZ/BnoU3dnd0r0H4ydOTdFWpVp1Phn7OY2bNEvRPuLD9wFYsmINE6fM4Kl+j5GYmHjRYhVvaZAbApo0bUb+/Pm9DiNDLFu6lHLlylOmbFmio6Pp1LkLkydNOPuGQUh9CU6h3hczI1euXACcOHGCEydOgBlmxoG/krJrB/bv57IiRbwM85yF+nFxzpE7ZzYA8uTKxo74pGOxeO0W9v11BICl32+hWKG8ydscOnIcgCxRkURFRQa+/uhFlNpnyqaNP9GkadIAscXV1/DV+C+8CC1dmjRtRr58KeOvXLkKFStWOmPdH3/YQPMrWwBQsFAh8uTJmyLTG+osCG7BTINcuai2b4+jePG/r8pXrFhx4uLiPIzo/KkvwSkc+uLz+YitV4dSxQpz1VVX06BBLMPe/S83tGtD+TIlGP3Jxzz6eD+vwzwnoXRcnINJQ+9m0ceP0qtjIwAee308rzzYnk1TXuDVB9vz3NuTztiuZ4eGzPj2h+THERHG4k8f4/dZ/flm8U8sW/fbRevDuaparTqTJ00E4MvPx7Ft61aPI8oY1WvUZMrkiSQkJLDl119ZvWoFcdvCo29ydkE1yDWzp81svZmtNbPVZhabgftubmaTM2p/cn6S5nhOKVQL59WX4BQOfYmMjGTJ8lVs+nUry5cvY/26dbw96C2+nDiFzb9upXuPnjzx2MNeh3lOQum4tOj1Fpff8jod7hvOnTc3pXGdcvTt1JjH/zOeCm1e4PE3xvPOc11TbNOsXnl6tG/IM4MnJrclJjoadhtI+dbPU696KaqWC97s+7v//ZB33xnK5Q1iOHjwL6Kjo70OKUPc1rMXxYoVp9nlDXjisYeIbdiIyCidc/9PETRH2swaAdcDdZ1zx8ysABAUrzIzi3LOJXgdRzgoVqw42075Fh0Xt42iRYt6GNH5U1+CUzj1JW/evDRtdgUzZ0zj++/X0KBB0vf+mzp1pv31wXMiU3qE0nE5WYqwa+9BJs5ZS/3qJbnl+gY8MvBLAL6YtZphz/w9yK1evijvPNuV9vcNZ8/+w2fsb//BI8xfvpmWl1dmw887Lk4nzlGlypWZPG0mAJs2bmTa1CkeR5QxoqKiGDDwjeTHVzVvQvnyFTyMKGMF6ffEoBFMmdwiQLxz7hiAcy7eObfdzLaY2YtmttLMvjezygBmltPMPjSzZWa2ysza+9tLm9kC//orzezy05/IzOr7tykbYD89zWycmU0CZl68X0N4q1e/Pps3b2LLr79y/Phxxo0dQ5vr23kd1nlRX4JTqPdl165d7Nu3D4AjR44w55vZVKpchQP797Np40YAZs+eRaXKVbwM85yFynHJkS2aXDmyJt+/umFl1m/ewY5d+2kaUx6A5vUrsnnrLgBKXJaPMa/3ovezo9j8+67k/RTIm5M8ubIDkC1rFlrEVuSnLTsvcm/Sb+fOpNgSExMZ8MrL3NH3Lo8jyhiHDx/m0KFDAHzz9SyiIqOoXKWqx1HJxRI0mVySBpLPmdlG4GtgrHNunn9ZvHOurpndAzwK9AGeBr5xzvUys7zAUjP7GtgJXOOcO2pmFYDRQL2TT+If9L4NtHfO/W5mr6SxH4BGQE3n3J7TgzWzvkBfgBIlS2b07yKF227tyoJ5c4mPj6dc6eI8+9yL9OzVO1OfM7NERUXx5qAhtG3TCp/PR4+evaharZrXYZ0X9SU4hXpf/tixgzt69yTR5yMxMZEbburEdW2uZ8g779Gt801ERESQN18+hr/3gdehnpNQOS6FLr2Esa8nvb9GRUYwdvoKZn33I/e+PJaBj95AVGQEx46f4F8vjwHgyTtakT9PTt7q1wmABF8iTbr/h8sK5OG/L95CZGQEEWZ88fUqpi1Y71m/TpXaZ8rBgwd5d/hQANp3uIHbet7ucZRpu717NxYsmMfu+HgqlSvJU888T778+Xns4QeI37WLmzq2pWbNWnw1eTq7du6kQ9vWREREULRoMf774Uivw88wSZf1VSo3EEutTsorZhYJNAWuBO4E+gEvAI2dc3H+Gt3+zrmrzWw5kA04WUaQH2gFbAeGALUBH1DROZfDzJoDHwBHgJbOue3+50xrP7HAFc65s77SY2LquUVLwudsTRFJn2B6/7xQwVofe77yxT7gdQgZZu+SQV6HkGESfOEzfdcl2SJXOOfqnX3NzFGhWi33xhjv/9HcruZlnv4eAgmmTC7OOR8wF5hrZt8DPfyLjvl/+vg7ZgNudM79dOo+zOwF4E+gFknlGEdPWbyDpAFtHZIGw4H2EwscuuBOiYiIiMhFFzQ1uWZWyV9ecFJtINB8KzOA+8yffjCzOv72PMAO51wi0B2IPGWbfUAb4BV/ZjfQfkRERESClpn3t2AWNINcIBcw0sw2mNlaoCpJpQppeQnIAqw1s3X+xwDDgB5mthioyGnZWOfcn0BbYKg/W5vWfkREREQkRAVNuYJzbgVwxkwIQOlT1lkONPffP0JS3e7p+9kE1Dyl6Ul/+1ySSiFwzv0OnHrGQ2r7GQGMSH8PRERERCRYBM0gV0RERETSyzDNrhBQMJUriIiIiIhkCGVyRUREREJQsJ/45TVlckVEREQk7GiQKyIiIiJhR+UKIiIiIiFGl/U9O2VyRURERCTsaJArIiIiImFH5QoiIiIioSYELqvrNWVyRURERCTsKJMrIiIiEoKUyQ1MmVwRERERCTsa5IqIiIhI2FG5goiIiEgIMs2TG5AyuSIiIiISdjTIFREREZGwo3IFERERkRBjQISqFQJSJldEREREwo4GuSIiIiISdlSuICIiIhKCNLtCYBrkZgAHOOe8DiNDmC6fIpJu4fR6CZf3sJP2LhnkdQgZJl/9f3kdQobZu2yI1yHIP4gGuSIiIiIhKIy+Z2cK1eSKiIiISNjRIFdEREREwo7KFURERERCkE48C0yZXBEREREJOxrkioiIiEjYUbmCiIiISIjRZX3PTplcEREREQk7yuSKiIiIhBzTiWdnoUyuiIiIiIQdDXJFREREJOyoXEFEREQk1Jgu63s2yuSKiIiISNjRIFdEREREwo7KFURERERCkKoVAlMmV0RERETCjjK5IiIiIiEm6YpnyuUGokxuEPP5fDSsX5cbOrQFoG/v26lSsSyx9eoQW68Oa1av9jjC8zNzxnRqVqtEtcrlGfjaAK/DuSA+n4+G9epwQ/vrvQ7lgg1+603q1qpGTO3q3HZrV44ePep1SOl2Z59elCxaiJja1ZPbbu3WmdiY2sTG1KZS+dLExtT2MMLzk1q/QsnRo0dpenkssTG1ialVnZdefD7F8ocfvI+C+S7xKLoLFwqv/x+nvMiyz55i8Zh+LPzkcQBqVizGvJGPJLfVq1YKgNy5svH5W3eyZGw/Vnz+NN3bNUyxr0tyZuPnGS/z5hOdLno/0uPo0aM0adSABnVrUbdWtTP+3uSfR4PcIDb07UFUrlwlRdsrr77GkuWrWLJ8FbVqh96Hts/n48H772XCpGmsWruBcWNG88OGDV6Hdd6GDB5EpSpVzr5ikIuLi2PY0MEsWrycFavX4fP5GDd2jNdhpVv3Hj2ZMHl6iraPPx3LkhWrWbJiNR063kj7jjd4FN35S61foSRr1qxMmzmbJStWs3j5KmbNnMHSJYsBWLFiOfv37fc4wgsTKq//a/sOomGXATS55TUA+j/Ygf7vTaNhlwG89M5k+j/YAYA7b27Gj7/8QWznAbS6YxADHu5IlqjI5P08f08bFqzY7Ekf0iNr1qxMn/UNS1euYcny1cycMZ0lixd7HZZ4SIPcILVt2zamT5tKz169vQ4lQy1bupRy5cpTpmxZoqOj6dS5C5MnTfA6rPOSdIymcHuvPl6HkiESEhI4cuRI0s/DhylStKjXIaVbk6bNyJ8/f6rLnHN88fln3Ny560WO6sIF6lcoMDNy5coFwIkTJzhx4gSY4fP5eLrf47z86r89jvD8hfLr3znInTMb8P/t3XecVdXVxvHfQxERVIyCBVCsoBiRIlhiid2IiooiVsSINQr2aIwtirHEbtT4GmPvRuy9IihI1FhQUFCaEXtBpa33j30Gr+NQZeace3m+fObDzLln7t1nzi3rrL323rB008ZMmpwuNgJo2qQRAE0aN+LzL6cwfcZMADqu3ZoWyy7FE0PezqXN86L68236tGmowrvzVYCvInOQW1AnHDuAvwz8K/Xq/fQUnf7nP9G1UwdOOG4AP/zwQ06tW3ATJ06gVavWs35u2bIVEyZMyLFFC+74Y/tz9sDzfnaOylHLli3pP+A41lptZVZtvSJLLbU0W2+zbd7NWigGv/A8y7dYnjXWXDPvpiySZsyYQbcuHVml5fJstdXWdO3ajauuvJwdu+/EiiuumHfzFli5vP4jgvuvPJLBN59A3902AeD4C+7inP49GPXwWQwcsCt/viwlGq667VnarboC7z92NsPvPJnjzr+LiEAS5x6zGydfdG+ehzJPZsyYQbfO67PySi3Ycutt6NqtW95NshwV+9W5EEiaIelVSa9JGiFp47zbNDcPPfgAzVs0p1Onzj/ZfsZfzuHVN97m+SEv8/lnn3Ph+eWXBYmIn20rxyvthx58gBbNW9Cpc+e571wGPv/8cx64/z7eHjWG9z+cyLdTvuXWm2/Ku1kLxR233coee5VfFrdS1K9fn5eG/4dRY8YxfPgwXnj+Oe65+y4OO+IPeTdtgZXT63/LAy9i473/So8jr+SQXpuySafV6bfHppxw4T2sucOpnHDB3fz9tH0A2GbjtXn9nfGstu0pdNtrIBedtAdLNlmcQ/bclEdfeJPx//si56OZu/r16/PSK68yeux4hg97mTffeCPvJlmOKj7IBb6LiPUjogPwR2Bg3g2am6EvDubBB+6n3Zqrsv++vXn26afoe8B+rLjiikiiUaNG7HdAH4YPH5Z3U+dby5atGD9+3KyfJ0wYzwQtfR4AACAASURBVEpl1C1eZciLg3nggUG0XaMN+++zF888/RQH7r9v3s1aYE89+QRt2qxK8+bNadiwIT167MbQIS/m3axfbPr06dz373vouUevvJuyyGvWrBmbbrY5zz7zNO+9N5p1116TdmuuypQpU1h37fLKspfT67+qFGHy598w6KnX2aB9G/bp3o1/P5kGLt/9+H9mDTzbb+cNue+p1wB4f9wnjJ3wKW3bLE+39Vbl0F6bMfLBMxg4YFf27t6Vs47aOZ8DmkfNmjVjs8234LHHyremfZ7kXatQ8BzVohDklloK+BxAUlNJT2bZ3f9K2qVqJ0mnShop6XFJt0o6ri4beebZAxk9ZhwjR43hhptuZfPfbsl1/7qRSZMmAVn306B/036d9nXZrIWiywYbMHr0KMaOGcPUqVO58/bb2LF7sd8sa3LW2QN5b+x43hk9lhtuvo0tfrsl/7yhfDOfrVuvzMsvD2XKlClEBE8/9SRt2xV/QM3cPPXkE6zVth2tWrXKuymLpMmTJ/PFFyn799133/H0U0/SsVNnxo6bxMhRYxg5agxLLLEEb7w9KueWzp9yef0vsfhiNF2i0azvt96oHW++N5FJk79k087pwmKLrmsx+sPJAIz76HO26NoWgBa/WpK12izPmAmfcOAp/2Kt3/2Zdjuexh8vupdbHniZUy8dlM9BzUH159tTTz5B27btcm6V5WlRmCe3saRXgcWBFYEts+3fA7tGxFeSlgOGShoEdAZ2BzqS/j4jgFeq36mkfkA/gNYrr1zrBwHQ94B9+WTyZCKC9Tqsz6VX/L1OHndhatCgARddcjk77bgdM2bM4IA+fVmnffkF65Wma7du7LpbTzbq2okGDRrQoUNHDjq4X97Nmmf779ub5599hk8++YTV27Ti1D+fQZ++B3Hn7beV5YCzKrM7rnLx0aRJHHxQH2bOmMHMmTPZrece/G7H4k63VWlaLLskt//tYAAa1K/P7Q8P5/EX3+aIKbdw/vE9adCgHj/8MJ0j/3IrAOf+4xGuOWNfht1xMhKccsl9fPrFt3kewnz5aNIkDu57ADNmzGBmzGT3nnv6+baIU001kpVE0jcR0TT7fiPgWmBdUgB7EbAZMBNoC6wK7AUsExGnZb/zN2BiRFwwu8fo1LlLDB5afqUDNSnH+lgz++Uq7bOgkt7LltngyLybsNB8PuzyvJuw0DRuqFcioktej7/2rzvG9f9+Jq+Hn2XDNZrl+neYk0UhkztLRAzJsrbNgd9l/3eOiGmSxpKyvZXzzmhmZma2iFqkanIltQPqA58CSwMfZwHub4FVst1eAHaStLikpsCO+bTWzMzMbPak/L+KbFHI5FbV5ELK0h4QETMk3QzcL2k48CowEiAihmW1ua8BHwDDgfJelsfMzMxsEVPxQW5E1J/N9k+AjWbzaxdExOmSlgCeAy6srfaZmZmZ2cJX8UHuArpG0jqkGt1/RcSIvBtkZmZmVqrg1QK5c5Bbg4jYO+82mJmZmdmCW6QGnpmZmZnZosGZXDMzM7Ny5HqFOXIm18zMzMwqjjO5ZmZmZmVGgJzKnSNncs3MzMys4jjINTMzM7OK43IFMzMzs3JTBsvq5s2ZXDMzMzOrOA5yzczMzKziuFzBzMzMrAy5WmHOnMk1MzMzs4rjINfMzMzMKo7LFczMzMzKkesV5siZXDMzMzOrOM7kmpmZmZUdeVnfuXAm18zMzMwqjoNcMzMzM6s4LlcwMzMzK0Ne1nfOHOQuBALkZ5rZIici8m7CQlNp72HfTZ2RdxMWms+HXZ53ExaaZX5zQt5NsEWIyxXMzMzMrOI4k2tmZmZWZoSnyZ0bZ3LNzMzMrOI4k2tmZmZWjpzKnSNncs3MzMys4jjINTMzM7OK43IFMzMzszLkZX3nzJlcMzMzM6s4DnLNzMzMrOK4XMHMzMysDFXYQoULnTO5ZmZmZlZxnMk1MzMzK0NO5M6ZM7lmZmZmVnEc5JqZmZlZxXG5gpmZmVm5Ea5XmAtncs3MzMys4jjINTMzM7OK4yC3DDz26COs174t7dutwfnnnZt3c36xSjoeH0sxlfOxjB83ju232ZKOv16Hzh3W5YrLLgHgjNNOpWunDnTr0pGdfrcdEydOzLml86/czsv48ePYeYet6NZpXTbqsh5XXXHprNuu+fvldF1/HTbqsh6nnXIiAJ99+ik777AVrVsszQnHHJVXs+fbF198Qe9ePemwbjvW//XaDB0yJO8m1WjkvScx7KYBDL2hPy/8M/19b/zLPgy9oT9Db+jPyHtPYugN/QH41VJL8MgVhzD5qbO46NhdfnI/Hdu2ZNhNA3jjzhO48Jid6/w4FiYV4F+RuSa34GbMmEH/o47gwYcfp2WrVvxmww3o3n1n1l5nnbybtkAq6Xh8LMVU7sdSv0EDBp53AR07duLrr79mk25d2HKrbRhw7PGcdsZZAFx5+aUMPPtMLrviqpxbO+/K8bw0qN+As845nw7ZudjyN13ZYsutmfzx/3j4gUE8/9J/aNSoEZM//hiARosvzsmnnsHbb73J22+9mXPr591xA45m222359bb72Lq1KlMmTIl7ybN1vZHXM2nX/7Yvv3+dPOs7889qjtffvM9AN9PncaZ1zzKOqutQPvVlv/JfVx6wq4cee7dvPTGh/z7or5su1FbHhvyTt0cgNUpZ3ILbtjLL7P66muw6mqrsdhii7FHr7144P778m7WAquk4/GxFFO5H8uKK65Ix46dAFhyySVp225tJk6cwFJLLTVrn2+//RaV2VJH5XheVlhxRTqUnIu12rZj0sQJXHft1Rx97Ak0atQIgOYtWgDQpEkTNtz4NzRqtHhubZ5fX331FS+88Bx9+h4EwGKLLUazZs1ybtWC2X2r9bjj8VcBmPL9NF58bSzfT532k31WWHZJlmyyOC+98SEAtzw0gp02a1/nbbW64SC34CZOnECrVq1n/dyyZSsmTJiQY4t+mUo6Hh9LMVXSsXwwdiyvvfYfNujaDYDTTj2FNVdbmdtvvYVTTzsz59bNn3I/Lx9+MJbXX3uVzht0471Roxjy4gtsvflGdN/ut4x4ZVjezVtgY95/n+WWa06/gw5kwy4dOazf7/n222/zblaNIuD+Sw9m8PVH0XeXbj+5bZP1V+V/n33De+M+meN9rNR8aSZM/nLWzxM+/oKVmi9dK+2tbSIt65v31zy1VbpO0seS3ijZ9itJj0salf2/TLZdki6VNFrS65I6lfzOAdn+oyQdMLfHrdUgV9KukkJSu3ncf6yk5WrY/s18Pu587T+H++kjaaWFcV8LKiJ+tq3cMjilKul4fCzFVCnH8s0339C7V0/Ou+CiWVncM846m1Hvf0iv3ntz1ZWX59zC+VPO5+Wbb77hgL335Jzz/sZSSy3F9OnT+fKLL3j8mRc54+y/0ne/3jUeXzmYPn06r/5nBAcfchhDh/+HJZo04YKC1ktv2e9KNj7gEnoM+D8O6bkRm6y/6qzb9tx2fe7MsrhzUtNTLijPc1dmrge2r7btJODJiFgTeDL7GWAHYM3sqx/wd0hBMXAa0A3oCpxWFRjPTm1ncnsDLwB71fLj1JY+QK5BbsuWrRg/ftysnydMGM9KK+XapF+kko7Hx1JMlXAs06ZNY+9ePdmr99702HW3n93ea6+9ue/ee3Jo2YIr1/Mybdo0Dth7D3r26s1Ou+wKwEotW9J95x5IonOXrtSrV49PP5lzBrGoWrZqRctWrejaLWVGd929J6/+Z0TOrarZpE++AmDy598y6Nk32WCd1DNQv349dtliXe56/LW53seEj7+kZUnmtmWLZkya/FXtNLgOqABf8yIingM+q7Z5F+Bf2ff/AnqUbL8hkqFAM0krAtsBj0fEZxHxOfA4Pw+cf6LWglxJTYFNgIMoCXIlbSHpGUl3SRop6WZVu5yX1FjSI5IOruF+j5c0LEthnzGHx79Q0ghJT0pqnm1bX9LQ7HfvLUmN/2y7pJ5AF+BmSa9KarxQ/jDzqcsGGzB69CjGjhnD1KlTufP229ixe/mOBq2k4/GxFFO5H0tEcFi/39O2XTuO6n/MrO2jR42a9f2DDwxirbbz1EFWGOV4XiKCow47mLXars0RRw2YtX3HnXbhuWefBmD0qHeZOnUqyy73s07IsrDCCivQqlVr3n0nDbx65qknabd28QYDLrF4Q5ou0WjW91t3XZM33/8IgC03WIN3x07+SRnC7Hz06dd8M+UHurZfGYC9f9eJB557q/YavmhYTtLwkq9+8/h7y0fEJIDs/xbZ9pbAuJL9xmfbZrd9tmpzdoUewCMR8a6kzyR1ioiqy8OOQHtgIjCYFAy/kN3WFLiNFMXfUHqHkrYlpa+7ki4gBknaLLtCKNUEGBERx0r6Mym9fSRwA/CHiHhW0pnZ9v41bY+I/pKOBI6LiOHVDy47if0AWq+88gL/keamQYMGXHTJ5ey043bMmDGDA/r0ZZ325VskX0nH42MppnI/liEvDuaWm29k3XV/TbcuHYFUpvCvf17HqHffoV69erReeRUuveLvObd0/pTjeXlpyGBuv/Um1mn/azbbsDMAp55+FvvsfyB/OPT3bNylA4stthhXXnPdrNKLDmuvztdff8W0qVN58P77uHvQw4UMGkv97eLLOHD/fZg6dSptVluNa679Z95N+pkWv1qS2/+6PwAN6tfj9sde5fGh7wKwxzbrzxpwVmrkvSex5BKLs1jD+uy0eXu6H3UtI8d+zFHn3cs1p+5J40YNeWzISB4dMrJOj6UCfRIRXRbi/dWUII45bJ/9HdVWHZGkB4GLI+JxSUcBrSPieElbAKdExDbZfn8HBkfETZLGAl8C50XEzSX39U1ENJV0AdAT+CK7qSkwMCL+r9pjzwAaRcR0SasB9wCbA/+NiJWzfVYH7gR+W9P2iOgk6RlmE+SW6ty5Swx+aY67mFkFKtc6zJqUS33svPpu6oy8m7DQNF6sft5NWGiW+c0JeTdhofn+pfNfWcjB3XxZt0OnuPOR5/N6+FnWWanpPP0dJLUBHoiIdbOf3wG2iIhJWTnCMxHRVtLV2fe3lu5X9RURh2Tbf7JfTWqlXEHSssCWwLVZ4Ho80KukLOGHkt1n8NOM8mBgh+olDFV3TQpq18++1qge4M5G5XwSmZmZmZW/QUDVDAkHAPeVbN8/m2VhQ+DLrJzhUWDbrKR0GWDbbNts1VZNbk9SucEqEdEmIloDY4DfzMPv/hn4FLiyhtseBfpm9b5IaimpRQ371cvaALA38EJEfAl8LmnTbPt+wLOz2559/zWw5Dy02czMzMxqIOlWYAjQVtJ4SQcB5wLbSBoFbJP9DPAQ8D4wGvgHcDhARHwGnAUMy77OzLbNVm3V5PYuaWyVu0kB5+3z8Pv9gesknRcRs/o2IuIxSWsDQ7JE7zfAvsDH1X7/W6C9pFdI5Q+9su0HAFdJWoL0BzxwLtuvz7Z/B2wUEd/NQ9vNzMzMal3Rl9WtEhG9Z3PTVjXsG8ARs7mf64Dr5vVxayXIjYgtath2acmPz5RsP7Lk+zYl+xxYsr1pyfeXAJfM5fGr9j+12vZXgQ1r2H922+8mBedmZmZmVkZqc3YFMzMzM6slFTZedKHzsr5mZmZmVnEc5JqZmZlZxXG5gpmZmVkZcrXCnDmTa2ZmZmYVx0GumZmZmVUclyuYmZmZlSPXK8yRM7lmZmZmVnEc5JqZmZlZxXG5gpmZmVmZEeWzrG9enMk1MzMzs4rjTK6ZmZlZuZGX9Z0bZ3LNzMzMrOI4yDUzMzOziuNyBTMzM7My5GqFOXMm18zMzMwqjoNcMzMzM6s4LlcwMzMzK0euV5gjZ3LNzMzMrOI4k2tmZmZWduQVz+bCQe5CMGLEK580bqgP6uChlgM+qYPHqQs+lmLysRSTj6WYfCzFVFfHskodPIb9Ag5yF4KIaF4XjyNpeER0qYvHqm0+lmLysRSTj6WYfCzFVEnHYr+Mg1wzMzOzMuRlfefMA8/MzMzMrOI4yC0v1+TdgIXIx1JMPpZi8rEUk4+lmCrpWOwXUETk3QYzMzMzmw/rrd85Bj0xOO9msGrzxq8UtQbamVwzMzMzqzgeeGZmZmZWjjzwbI6cybVCkn46ZrT6z2aWSGrq10ex+fyUB0n1sv99viqEg9wKVtMLtRxevJIUWbG4pKMkbRJlXjxe+ncvh3NQpZzaOjuSflXyfds827KwSVoTuBFYP++2LAhJFd+bWO39bKm82zOvKuG1Pz8kLQNUnZ+yfD3ZzznIrWAREZK2ltRP0pFV2/Ju19yUfCDsCGwFjMu3Rb+MpHolx7Q70D7nJs2Tah/OvSTtmneb5leWmdlS0qWSDgVOLKdAY24iYhQwBjhJ0np5t2d+SFoa2CD7fhtJ6+TcpFpR8hrqB1wtqUHRA0hJawH7S1os77bUoU1J7w9nADeWSw+JCvCvyBzkVqCqF6akLsBlwJKkN6xbqu9TVJJWB04BJkTEh5LqFb3NsxMRMwEkbQjsB0zIt0XzpuTD+TigPzCy9Paqrr0ii4iZEXEX6QPsHOC0iPhKUsOcm/aLKKkHEBHHkALd08os0F0e2EzSfaT3qbpYGj0XkrYAdgQOi4jpRUw2lHxuVL1WjgR6SGqUa8PqSEQMAroCRwOHR8Q3RTxPNn8K/yFl8y/L4HYFDgLOiogLI6Ir8CtJN1btk2sjq6khgJ0A/BPYXNJuWbAS5RjoZgHJb4HngYcj4nNJi+fdrnkhaQ2ge0RsBHyYZdxOgB+D9yKqVh7SCHgSeAEYKKlBREzLrXG/UFWGPSJmSloWICJOAt4Czih6oFt1biLiXaAlKbC4A/ghz3YtTNWef8sC25GOc83cGjUX2fvrpsDfgf8DXgU2A3pVaka3hs+TS0nPxX0ltcuhSbaQOcitXO2ArYEOJd2ze5AC3WXya9bPVesW30vS0cBvgPuAs0hZ6B5QvOB8dkrfPLOA5GngJuDUbNv3kurn1b7Zqfbh3BSYBDSUdCdwEbAP0EfSuTk1ca6qPZ/WBpaLiOMiYmegPnBrdtsWkrbLsakLpOTYjgQulnSOpNUj4lTgNeBUSZ1ybeRsVDs3BwDLACeTZvrpL2ml7LblyvGCFn52jEsAnwF/I9VO95FU5HKljYB7IuJhUib3LVLv066VFuhWO0+7S+oFzIiIfsCXwJ8kNZd0SPZcLSQp/68ic5BbIUq6mlaRtERE3AAcBnQDNpW0HCnwXQUoVFdtyRvNIcBRwERSgLsR8AhwG3C0pO65NXI+VHvz3FVSH0ldIuJA4ClJr0qqHxEzihToVmv3kcAA4DtSj8BY4OKI6EMK1L8rahBScgwDgKuBGyRdnXXv9wPqSxpBCtpH59fSBSfpYGBP4I/Z/wMlbRoRp5PO1YCidTNLWqrk3GwIbE/qvv8n8BLQCugp6WTgz0Ch2j+vSo7xWFJW9BFgDeAW4COgX4Gz7SOBbpLWiYgfIuLKbPuGQEUN2iwd3AycAHQA+kq6PiKOBz4mvUccD/wnt4baL1LxI1sXFVlX0w7A6cBoSY1JQcpfgTOB8cAXwB8j4uPcGlqDLPhoAWwM7AT8DhgKPJAFgg8CM0hZqsKr9iHXHXgcOEzSnyNif0nXA2MktYmIGTk29SeqDZDZF+iZlSSMJL3RVwW/BwP7FDmrLmlfYLeI2FTSOaQ6u4YR0RfYTVJPYHhEjM2znfNK0gbASqSAqSGwFim43ZMU1L5Pyjz9JSKOl7RcRBSm+1+pxn5PSRcBjYETgdbAesCLEXGfpOlAJ9Lr/5CI+D63Bv9CkvYGto+IbSS9AuwfEYdJmgr0IXWH/ykipubYRmWfG52BZsAo0vNrQ1LmtinpM2M6sDLQA/hvXu2tDVnZ2G9J72ejs2z1PyWdGBHHZCULnxXtM9PmnTO5FULSqsCFpMD2j8BjwN3AcFKQ2xx4JCLuz62RJap158+MiI+Ad0i1YPsC22QB7jHAqhFxZ0QUepaFal39ywOdI+K3wDTgU+AZgCwb+hDQps4bOQdKg/sWB7YFzgZ+kHSkpP+TdHzWG1D1gfBGro2tpoas8uvAPpKOIM1msRKpvvsepZrcu8olwM2sSRqIuXVEfJN93wTYMSK2zmpy1wB+l/XkfJJjW2syk5TVbAcsSxrI+BawYRYAExEPkp53W0fE63k1dEHo54MwmwHnZL0Jk0nHC/AecAlwXkEC3B1I5TsbAcNIFx13kwLbS0klFgNIvWlLFqnnaUHU8D5RD/gVWZY6Oyc3kQZFEhEjix7gqgBfReZMbplSGh3eICK+y7olpwEjIuLFbJerlAYN7RIR12YBynGSPgGeyjMLV61b/AigKXBednNL4MBsUM0ewIHAoHxaOn9KjmlV0kjxGZLuAJYgnYdpkvYj/f0PzbGps5SeC0BZrfADpO7ij0nddMOBX5NqC/cuUoYQfvZ8Wpp0Kl7PAo9uwFUR8aWkm0kB/DKkwKPwlKafmxkRtyjVF/8xC2LvlDQNWCXr+m9GGih0eURMybXRJarOTUSMkbQkaVzACqRa+7OBPwEh6YGIGJX1HHybY5MXSPw4g8r2wNPZ5jOB/wE7Za/9P5Iuto7KuxckC3Dbk2ZR2IF0gQQpwDsiIv4q6TpSsNsVOAPYs0g9T/Or2vvERqTEw0fAQOAKSZ9nn5+tgNWzC/4f8j5X9ss4yC1DWTdSJ1KmbTWgC+nNqmPWBfaXbNfPSUEjEfHP7ENxVN4v2mrd+buSpmuJrCtzReAEpQn8lwd6R0TZ1E0qTc5/Cimb/jrpQ/2w7EPuQOBYfvwQzF3JudgPaCtpOPAGqUt1YqSZIPYC1gUaR0ThApCSYziONGCxjaTzgWdJ3avdlWYbWZdUglEWAS78JHg6nBSIfAD8TdL0iLhX0sWkHpzFSV3ihZmertoFFBHxtaSrgP2Bk4BzScHuecBUSWMiYno+rV0wSgP8mkTE81kQfxqpPGkQqUdqONAu268X6SIxl/ffLGPegTS46r6IeFNpsNUKwNkRsbykE4GHJW0fEU8pDVreDdgjIt7Mo90LS8n7xB9Iz8G3SGNUzgH+ANypNJ3dFqT3ieKXy5TBwK+8OcgtM5KakepWvweOI5UhHBsRnyrNQHBP1lX+HKleb0DV70bETTk0eZZqV9JNSLVfOwBLZ0HW+sDFQADLAeMiYlJe7V1AQZqXuA1wffb9FZJeBzYhZUPG59a6GigtkrAvKdi4nPSBd7Wk+pL6kgLzXkULcLNawvrAu6SLvj1JM4psT1pEpCHpdTA1235S0f72c5N1r64G9AV2jYhxknoDJysNXrxK0j0ARepWlbRaRLyffd+fFFyNIQ0EvBo4nFTnfSHpfWxKGQa4DUg9BXtIOjUiBmfd+UtGxHhJB5FeO0eTSjT2iYi3cmrrWsA9wKPARpJWjIirIuJdSZsBL2e7DiVNtTcFINKc0kdGGU+5VypLQvQhzVn8FWkcyHmkC5AtSe8nA4teGmfzzjW55WcVUmD4KmlE8hjga0ktIq1+tA3pvK4HnBwRT+XW0mpKAty2WcDUlDTi+DJSlqoj8IeIeD8iXi6nAFfSmlnX8mjgAVLd3XR+nFT9JtJAlNyzIdVqhxuSnis9gKVJAeO12c0rkALE3QtYg7sjcB2wNul51Bx4JyK+iog7SHWFJwKTI+IS0iC03P/286L0/GSvmXGkQUFtsnriW4GHSQNkto+IjwsW4C5Lygb+Kcug706ap7gJ8A/SxccVwNek18bYiJiYV3sXVBaU30GqVz1J0lbAkxHxhaTFI+Jt4ISI+D2wb17PP6WV5G4nDTo+FrgybVbV0rXvAMtJugS4gHQxOLTqeVjOAW5WslT6mpoBfBQRH0XElIh4gpR13zwi3omItxzgVhZncstMRLwmaTAp47YPqXv2AFJgdTtpyqczI+J/8PMuw7xldcJ/kXQD0JM0knpYRIzNApd9JDWOiO9ybehcVMtKr00KqFZSmtrpHlLZRZeIeJzUZVkI1drdmxR8fECasu2biNg6u+0PpNksbomCLfogaXPSRcQ+EfFStu0d0qCrbhHxUkQ8JmkIqQbyfdIFR+FVOz9tgGkRMUHSOFI36jjSbApDSYFuoUa7K03z1540feHfSCvN/TUiHpDUHDiCNADtCFIGrV4ZZnBnnaOsB+020mfpQKCLpJZAS0mTSFPtHUqWGc3Jr4AO8eOg4xNIi+0cojSV3sGk6dp+A5waES9D+cxJPhdVx9Ba0kcR8b6kaZL+FRFVc982pGCDgOeP6xXmxEFuGcgyhLMCjYi4IquV6hYR/1YaVLaDpI6kOU13IA14KOIb1VfAvaTsTpOIuA1mzWnah5TxKKcAd2lSlq0/qa7rXFIg0pWUdX88r3bWpKTduwC/J63C9j7pQ/jy7La9gENI3eOFCnAznYHLIuKlLLM5ndSjMYE0PdimwCfA5qQBdEV8HfxMtefVMaTX8vuSniXVev4dOEtpmqPVSaUvRarB7U4aTHZWVs+5I+niaRfSdICTJV1Gqse9kHSRUlYDmaqdo61IZWOjI+JKSUF6HT1Dmt2mAVA/72OMiBck7SjpfdJr/a6IODN7Hr0B9I+IC4EnoHiJkQWRnRtFxBPZBftBwBuS/kf6nPk/SY+SSjO6k0qdrAI5yC04pZkTdpd0L6n+a5uIOIX0ob4p8GCk2RMmkOad3DsiCpM5rKIfZxWYIOlx0mwQO0qaERF3kka09s6rZm1+lHzIHU6q7foMeIoU4K5CGuC0G2mE7vLAx0X60JDUhbToxp1Z7eBjpCmqemUfCEsDe2XlL4VR8uG7KmlFIkgzWNSLNHvC+aQMYTtSemPncqrBLXledSPVGHcnZdhuJgVLfbIL2XVJc8u+n1tjq5G0Aqn+9PcRMUxSk+y1PoC0GMeREXF5lvkcSMrgllWACz9bbW5/4H7geklbRcTfs0D3QFLpzOAcm/oTEfFw1sv0KGmGWvPuJAAAFBFJREFUESJiqqS/kmbmKN23MO9Vv0AL4GalevB2wF6keGcAaWq0PUgZ7Kmk8Qbv5NVQq10OcgsuIn7IsoVjSFOe9M1uuoMUlJweEadHWoYRKMaVeFUbStrSDThPUueImCjpOdJgoAGSvs5qxQqtWhbnd6TBM7uQBjmtQVqe9LxIk4qPIHU1/y+3BmeUBlssS5rK7BVSxvM9YC9JgyPiv5IuINW2Lkea/Lxo86yWfvjeSxp41TkiXlHSINJMEN+SusE/iIJNdTY3Wd3geqS61eHAh5Hmit6NNPJ7pYg4mmKuvvQD6cL1e6Wpl46XtAWpR2kccKKk5hFxWkR8lmM7fzFJWwO9SXNGH0G6EHldUqdIAwFnAB/m2caaRMSTknYm1d2voVQ6djzpgrdiZO/Tt0r6gTQW4u6IGKk0UHAAqZa/c0RcnWtDFwLh2RXmxgPPCkw/TjD+EOlDrxFp9amqqYUOIc1M0K3094oS4GY/rgAQEUeSBpgNyT6s/0eqJ3yONNVWoSmtOLW/0kpykAY6PRgR7wH/JHX1rUMKJomID6MAA+eyLuPbSTXDJ5PqbJclzeH5LGmJ0fYRMTUiPouId4sY4FbzEqmbsVcW6M6MiOlZmcV+wHflEuBmgS2QXrcR8Ro/DsTsJqlhRHxAGv29nqTlS3+nQL4gZQkvIC2V3IYUYFwKvEiqod5KqS63rNTw9x5BGk/QE9g2IlYmZXRHSmodEf+Igg5eioiHgCMlTSGVkvSPiMdybtZCl30G3UN6P9hH0uYRMT0iviJlb1vn20KrK87kFlT2Ip2ZdU9eDuxMGszxnKQ9s+6VFqQMbxvSB38hlGQ7/0CqFZ7Kjx+AM4GXJd1EmgptxyiPkdVNSCPBZ5A+vN8EDpe0RUQ8Azyd1VGuTlpCOXdKE9OfCgyIiGezbaeRBinuQBrhfhgp63ZORLybW2PnQ0R8K+kfpDq7v0kaRqqN7Ema37KQAUZNSl4rPUkDhF6KiH9kF7inA2dKeinSYgrbREEHaWW9NleTAtrWwH1VFxqSDiENcLww7wvw+VWt96Ytqczi7ezn1qReBUh1uMuQEhGFFhGPSNoJWCoiHsm7PQtbVQ9idu7uzkrlnpB0Bimh0p5U414RinjFWyQOcgtGaaGH77Juyi1JgdU5EfEpaVaChsBtSgM4jiV1ba6ZX4trlnXp9SPNWbolKfj7U0T8WWkAxFKkqanG5tfKuZP0a2D9iLhRafGKM5XmwhxEyuD2VZpk/UvSwhuFWLhCaTGNh0h1qc8qTWn0fUSckQVQg0hd4/cC25EGBJaNrN7zfFIt9NbAJNKxlkWgrrRq2ZTs+/6kgZhPABdLui3SPMUzSAO0+gNDihrgVom03PCQ7AsApVUL2wNjyi3AhZ9chBxDqr+fJukr4FDSa6aDpEtJc3zvGWl58sKLiCehGKVtv1RNx5AFuvUkERE3Z4mW24GrSImVQiQirPY5yC0QpRkTzid1K39Kmg6sBylr+CBARJwmaSJpftDjSmtxi0Jp1O6vgOcjjf6+UWnE+3GSVo40j2m5+DWwq9IAuVsknU7KsH1PmjlhAmmWgs9JyxEXYrR7RHyWZWvOlTQk0oCfRhHxQ/Yc2hxoFxH/kfROuXTvl4o0C8cL2VfZyEpItsmC9FbARhGxqdKKbUsDnSUdmtV3TiU9x8qKpBVJJRYHkwb2FOLib0FI2oY04HcrSX8BNsheXzeRLhDXJ63aWBYBbqlKCnAl7UBafOc1Uj37dyUZ3TuV6vXfc4C7aHGQWyCRVpc5lVRnu0XW1bIF8JiktyPilmy/qyUtFhFTIf+rcUltqjKyWddka9IiD0dJ2iEiHo607OUAUt1q4QZlVFf1N80C2+9JqxrVi4ibsm6vPwPXZlmCh0jdmIWaND0iHpRUVR7SJdLArIZZO78klV5QjgFuudKP02ydlmWjPwOOyQLf7qSp5/4E/CF7Cpbr4JgvSFPr7VLOAW7mU9LAv78AG5DOE0DbSAtz3JpbyxZRJe/PpZn2HqRymWNJS6s/Ua104aEcm1xrClmhXyAOcgtAkkhz+s2MiI+zWsqjJc2MtD79dsDdWWB7PaTpX6p+P+cA93fAJUprs+9AWrVsYER8oLTgQy+lFXfGkwbTFGrlrNkpefNcl9S1P5U0gIEs0J1JOu6Z2QddIadDijR10JHA8JJAd3/SgMCyyzyVM/18mq3GpBp1kXpmHos0gO590oDMe2d/b8WWZdkfzLsd86t6wiB7b55OKk/4hLRqYUj6PXCA0mwFX5R7RrQMLQt8kpVerQZ0jYjNstKfz4GnstK+6T43izYHuQWQvQhDadaBiRFxg6Svgf5Z9vBuSb2A+5XmNP0oCjBJfxZ8XwDsFxFfS+pBqo88LtvlQdJUVf1IAe6+5dRVJGk10rrzI4GLs837ZIHtLZKOoCCDzOakJNB9TtKVpBHHB0WBloJdRFSfZutE0ipT00nlPV2UpnXamFRf7PNTx0oubo8m1ayPJc0QcSkp0D1cae7rHqR5vT/PqamLpOyiozkwRlLviBiU9YZMlnQLafBf90iDtvcEniZbGMkWTQ5ycyRpJVJm4LosYByotKjD1VkGdyapy79hRNwmqWVR3lQlbQvcQFoxq2rey0NJE9ffSFotawIwQdLTFHz5zppKPiItAfkosAlpNbPLspsOlTS9nGqLs0C3PmnJ4Y4R8WbebVoElU6z1Z400Ow24G3S8tbXk1bMOqcCuvjLin46EPA3pJk6riYFuteTFn74mLQQR33SLB5lMcix0mS9nX2Bf0rqExH3Z/W2HYF+WW/IAaRky/O5NrYOyPMrzJGD3Hy1A/ZTmoqmA2mQxsbAzpKWiTSivyEpo/sM2RVpAWpwtyJNa3YMqdv7IEkPZHW3+wBXKK3n3jsrm5pJ6pYtsvqkjBqSdgdWjoiLIuIuSdOBbUhvoH/Pfv5vjm1dIBHxgKRmVR/mVreybu7ZTbPVDxgREXfn2cZFkX4cCHgesBlpkZe/Zq+X5qQL3H9RoXPKlpOqz72IuF3Sl8AdSkuUX0xaue2vkiaTFh8q1LLXlg8vBpGvocA5pGxBw4h4JSIuAwYDv5HUNyLuAnaLiI9KXuB51xh9BfSJiJtJc65OJS3Ru0mkybaPABYnTbFVeEqjp2+UdJLSCN3xwIHZIDoi4t+keryDlUa9P1Kub54OcPMVEd9ExJCIuKMkwN2DlCF8Nd/WLXqygYDnAE9Hmq97MClY6g4QEZNJC1mMBi6U1FA/LtJjdaT0by5pb0nHRprjty9pUYs1IuJQYCCpln2HRaa3SgX4KjC/WHOQ1RUBNImIx4FrgdWVFk8gIv5FWuFs06xEoVC1eRExLCJezOqF3yGVLUwFdpK0cRbo7keaCq3QskF+Z5Oya02APUnHcjhpNbDDsl3fBF6mjAcDWbFIWjEbKHM6cECk1fOsjlQbCHifpCaRFhI5HNguq2Mn0hzl5wKHRcS0IoyHWJRI6gA8KKlJtqklacYLsiRQH+A+SbtGxIsRcX9EFH4GH6sbLlfIQdZtuSOpa2V70mpAx5CCqpkRcUWkVY8eKnLGsOrNPiJGSboR2BvorTSn7EvA17k2cC7044IJu2R1XSuT5iluk9VEH0Wa1eK3pHKSnSItR2y2MFTSNFvlqPpAwOOVpmz8HzAOOFFS84g4LSI+m8P9WC2KiNeyErHbJe1KyrRPLrn9nixxdKmkx4EpvhCxKs7k5iAb2HABKYMwnnSx8SxwJdA9C64ocoBbXUSMIq0oM5G01HDhZR9cVQsmLJVd/U8nLZdMRAwGupAG0m3ngSa2MEXEdxHxoAPc3JQOBBxNWh79JtJMCi+SyhS2yupyrY4pqQ8QETuRLkpuAAJYWdIeknbOpnF7BlgrKwdapALcvCsVCl6t4ExuTpYFrgDIusMPJ023dT3pDXbybH+zwCJipKQLomCLIsxJ/LhgwivZTAqNSW+kSKqfXYQUfpowM5s/cxkIeAiph+3CAoyBWOSUDK6ekZXsTYiI3bPzdTJp5oulSCsENgZezcpKzH7CQW4tU1oI4dcRcXvJ5i9Jc8fuTppy63jgIGCpKOAyvfOjnALcKtn0WocBjwErRFoOcvGI+D7vtplZ7YmIb4Ah2RcwayBge2CMA9y6Vzp7UFYXvY+kV4ArI+KQrHShdUTsnO0za/VPs+pcrlCLJK1FCmKblGyrHxHPAIcAPSLiWuAdYHUKumrWoiAingB2BJ6W1MIBrtmipYaBgC4jyUFJgNsD2BI4ktQrfoikjSLiCKCepKpa3MLOv17bpGJ8FZkzubVEUlvS9Fp3RcR12baGETFNUktg3Yh4RNJOwBnAmRHxSo5NXuRlGd3FgEckdUmbnMkxW0R4IGBBSGoHnAncEhGvKC11fTSwV5Yo6q60QmiQanTNauRMbi3IShRuIi0J+aWkTSB15WfT1jwOrJntPgE4NCL+XTK1mOUkIu4DNouImQ5wzRYdHgiYH6Wlkkt9RVqdcZ8se/s5cCFpeseds3KyiXXdTis/zuQuZJIakwaVXUzK5B5Lmj9WEfECsBFwdraQAhExoup3HVQVQ1anZ2ZmtSzL2r4l6WLg7Yj4R0RMlHQuKbt+sqRzImKIpDMAj5co4WV958xB7kKWDVrqHREfAUi6GdiHtCLYdxExazGBbDGFRWq6EzMzsxLfkgb+/Q/oKWlT4A7SKnQXS5pGmlP+hIgYCjgJYfPM5Qq1oCTArVoR7EbSpOO7Sdq8ZD8HuGZmtsjKVpl7GehEGvz7MHAw8JCkzsBrwOWk0j6rLu9JcgueSHaQW4tKVwQjzb3agJTRbZZrw8zMzHJWMg7lRNIAsuWAScCvgZHAKcBewKNZMGw2X1yuUEciYrSka7Pvv8i7PWZmZnnKFuSoygeOBv5Gyugekw3GXguYHBFf5tlOK18OcutQltE1MzMzZg24/kHSjcDzwGUR8e/sNi+lPhcFrxbIncsVzMzMLFfZ+JUTgfqSlsi7PVYZHOSamZlZEQwBOufdCKscLlcwMzOz3EXESEm9ImJK3m0pF15Cas6cyTUzM7NCcIBrC5MzuWZmZmZlR17xbC6cyTUzMzOziuMg18zMzMwqjoNcMysbkmZIelXSG5Lu/CVTDUnaQtID2fc7SzppDvs2k3T4AjzG6ZKOm9ft1fa5XlLP+XisNpLemN82mll5EmngWd5fReYg18zKyXcRsX5ErAtMBQ4tvVHJfL+vRcSgiDh3Drs0A+Y7yDUzs/w4yDWzcvU8sEaWwXxb0pXACKC1pG0lDZE0Isv4NgWQtL2kkZJeAHaruiNJfSRdnn2/vKR7Jb2WfW0MnAusnmWRz8/2O17SMEmvSzqj5L5OkfSOpCeAtnM7CEkHZ/fzmqS7q2Wnt5b0vKR3JXXP9q8v6fySxz7kl/4hzcwqkYNcMys7khoAOwD/zTa1BW6IiI7At8CfgK0johMwHDhG0uLAP4CdgE2BFWZz95cCz0ZEB6AT8CZwEvBelkU+XtK2wJpAV2B9oLOkzSR1BvYCOpKC6A3m4XDuiYgNssd7Gzio5LY2wObAjsBV2TEcBHwZERtk93+wpFXn4XHMzBYpnkLMzMpJY0mvZt8/D/wfsBLwQUQMzbZvCKwDDFYqGFuMtJJSO2BMRIwCkHQT0K+Gx9gS2B8gImYAX0papto+22Zf/8l+bkoKepcE7q2a61PSoHk4pnUl/YVUEtEUeLTktjsiYiYwStL72TFsC6xXUq+7dPbY787DY5mZLTIc5JpZOfkuItYv3ZAFst+WbgIej4je1fZbH4iF1A4BAyPi6mqP0X8BHuN6oEdEvCapD7BFyW3V7yuyx/5DRJQGw0hqM5+Pa2ZW0VyuYGaVZiiwiaQ1ACQtIWktYCSwqqTVs/16z+b3nwQOy363vqSlgK9JWdoqjwJ9S2p9W0pqATwH7CqpsaQlSaURc7MkMElSQ2CfarftIale1ubVgHeyxz4s2x9Ja0lqMg+PY2YVJu+ZFYo+u4IzuWZWUSJicpYRvVVSo2zznyLiXUn9gAclfQK8AKxbw10cDVwj6SBgBnBYRAyRNDibouvhrC53bWBIlkn+Btg3IkZIuh14FfiAVFIxN6cCL2X7/5efBtPvAM8CywOHRsT3kq4l1eqOUHrwyUCPefvrmJktOhSxsHrvzMzMzKwudOzUJZ4Z/HLezaDZEvVfiYguebejJi5XMDMzM7OK4yDXzMzMzCqOa3LNzMzMyk0ZDPzKmzO5ZmZmZlZxHOSamZmZWcVxuYKZmZlZmVH2ZbPnTK6ZmZmZVRxncs3MzMzKkVO5c+RMrpmZmZlVHAe5ZmZmZlZxXK5gZmZmVobkeoU5cibXzMzMzCqOg1wzMzMzqzguVzAzMzMrQ17Wd86cyTUzMzOziuNMrpmZmVkZciJ3zpzJNTMzM7OK4yDXzMzMzCqOyxXMzMzMypHrFebImVwzMzMzqzgOcs3MzMys4rhcwczMzKwMeVnfOXMm18zMzMwqjoNcMzMzM6s1kraX9I6k0ZJOqqvHdbmCmZmZWZkR5bGsr6T6wBXANsB4YJikQRHxVm0/tjO5ZmZmZlZbugKjI+L9iJgK3AbsUhcP7EyumZmZWZkZMeKVRxs31HJ5twNYXNLwkp+viYhrSn5uCYwr+Xk80K0uGuYg18zMzKzMRMT2ebdhHtVUVBF18cAuVzAzMzOz2jIeaF3ycytgYl08sINcMzMzM6stw4A1Ja0qaTFgL2BQXTywyxXMzMzMrFZExHRJRwKPAvWB6yLizbp4bEXUSVmEmZmZmVmdcbmCmZmZmVUcB7lmZmZmVnEc5JqZmZlZxXGQa2ZmZmYVx0GumZmZmVUcB7lmZmZmVnEc5JqZmZlZxfl/+i3y6Tyd570AAAAASUVORK5CYII=%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The confusion matrix has three axes:</p>
<ul>
<li>Prediction label (class)</li>
<li>True label</li>
<li>Heat map value (color)  </li>
</ul>
<p>The prediction label and true labels show us which prediction class we are dealing with. The matrix diagonal represents locations in the matrix where the prediction and the truth are the same, so this is where we want the heat map to be darker.</p>
<p>Any values that are not on the diagonal are incorrect predictions because the prediction and the true label don't match. To read the plot, we can use these steps:</p>
<ol>
<li>Choose a prediction label on the horizontal axis.</li>
<li>Check the diagonal location for this label to see the total number correct.</li>
<li>Check the other non-diagonal locations to see where the network is confused.</li>
</ol>
<p>For example, the network is confusing a T-shirt/top with a shirt, but is not confusing the T-shirt/top with things like: Ankle boot, Sneaker, Sandal.
If we think about it, this makes pretty good sense. As our model learns, we will see the numbers that lie outside the diagonal become smaller and smaller.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Analyse-training-loop-by-using-TensorBoard-with-PyTorch">
<a class="anchor" href="#Analyse-training-loop-by-using-TensorBoard-with-PyTorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analyse training loop by using TensorBoard with PyTorch<a class="anchor-link" href="#Analyse-training-loop-by-using-TensorBoard-with-PyTorch"> </a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://www.tensorflow.org/tensorboard/">Tensorboard</a> provides visualization and tooling needed for machine learning experimentation. With tensorboard, we can:</p>
<ul>
<li>Tracking and visualizing metrics such as loss and accuracy</li>
<li>Visualizing the model graph (ops and layers)</li>
<li>Viewing histograms of weights, biases, or other tensors as they change over time</li>
<li>Projecting embeddings to a lower dimensional space</li>
<li>Displaying images, text, and audio data</li>
<li>Profiling TensorFlow programs</li>
<li>And much more</li>
</ul>
<p>It is a font-end web interface that essentially reads data from a file and displays it. PyTorch has created a utility class called <code>SummaryWriter</code> which will help us get the data out of our program, save on disk so as to tensorboard can read.<br>
To use tensorboard, PyTorch version 1.1.0 is required.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" torch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> torch version: 1.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install <span class="nv">tensorboard</span><span class="o">==</span><span class="m">1</span>.15.0<span class="p">;</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: tensorboard==1.15.0 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (1.15.0)
Requirement already satisfied: six&gt;=1.10.0 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (1.14.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (3.2.1)
Requirement already satisfied: absl-py&gt;=0.4 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (0.9.0)
Requirement already satisfied: protobuf&gt;=3.6.0 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (3.11.3)
Requirement already satisfied: numpy&gt;=1.12.0 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (1.18.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (45.2.0.post20200210)
Requirement already satisfied: grpcio&gt;=1.6.3 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (1.28.1)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (1.0.1)
Requirement already satisfied: wheel&gt;=0.26; python_version &gt;= "3" in /Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages (from tensorboard==1.15.0) (0.34.2)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The SummaryWriter class comes with a bunch of method that we can call to selectively pick and choose which data we want to be available to TensorBoard. We will add 4 types of data to tensorboard for visualization:</p>
<ol>
<li>images</li>
<li>graph</li>
<li>scalar value</li>
<li>histogram</li>
</ol>
<p>These added values are even updated and showed in real-time on tensorboard as the network trains.</p>
<p>It is helpful to see the loss and accuracy values over time. However, the real power of TensorBoard is its out-of-the-box capability of comparing multiple runs. This allows us to rapidly experiment by varying the hyperparameter values and comparing runs to see which parameters are working best.</p>
<p>One more thing to be notices, with PyTorch's SummaryWriter a run starts when the writer object instance is created and ends when the writer instance is closed or goes out of scope.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">preds</span><span class="p">,</span> <span class="n">lbs</span><span class="p">:</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">lbs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dl</span><span class="p">))</span>    
<span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

<span class="n">tb</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">()</span>
<span class="n">tb</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">'image'</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span> <span class="c1">#1. Add a batch of images to the writer</span>
<span class="n">tb</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgs</span><span class="p">)</span>   <span class="c1">#2. Add graph of our model to the writer</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_acc</span>  <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">lbls</span><span class="p">)</span>
        
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">total_acc</span> <span class="o">+=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">lbls</span><span class="p">)</span>
    
    <span class="n">nr_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span>
    <span class="c1">#3. Add scalar values, average loss and average accuracy, to display on tensorboard over time or over epoch.</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'Average_Loss'</span><span class="p">,</span> <span class="n">total_loss</span><span class="o">/</span><span class="n">nr_batch</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span> 
    <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'Average_Accuracy'</span><span class="p">,</span> <span class="n">total_acc</span><span class="o">/</span><span class="n">nr_batch</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    
    <span class="c1">#4. Add values to histograms to see its frequency distributions.</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="s1">'conv1.bias'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="s1">'conv1.weight'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="s1">'conv1.weight.grad'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch:       </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="n">nr_batch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_acc : </span><span class="si">{</span><span class="n">total_acc</span><span class="o">/</span><span class="n">nr_batch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">tb</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  after removing the cwd from sys.path.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch:       0 
avg_loss: 0.06133313849568367 
avg_acc : 0.7699666666666667
epoch:       1 
avg_loss: 0.05296260863542557 
avg_acc : 0.80595
epoch:       2 
avg_loss: 0.051954615861177444 
avg_acc : 0.8122833333333334
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default, the PyTorch SummaryWriter object writes the data to disk in a directory called <code>./runs</code> that is created in the current working directory.
To launch TensorBoard, we have 2 ways:</p>
<ol>
<li>run and show directly on jupyter notebook </li>
<li>run the tensorboard command at our terminal and open <code>http://localhost:6006</code> on browser.    </li>
</ol>
<p>To be noticed, the defaut save path and open port are able to change if you want.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 1. run and show directly on jupyter notebook </span>
<span class="o">%</span><span class="k">load_ext</span> tensorboard
<span class="o">%</span><span class="k">tensorboard</span> --logdir=runs --port=6006
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

      <iframe id="tensorboard-frame-3099573ceaef4d37" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-3099573ceaef4d37");
          const url = new URL("/", window.location);
          url.port = 6006;
          frame.src = url;
        })();
      </script>
  
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 2. run the tensorboard command at our terminal and open `http://localhost:6006` on browser.</span>
<span class="o">!</span>tensorboard --logdir<span class="o">=</span>runs
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow installation not found - running with reduced feature set.
TensorBoard 1.15.0 at http://VN0130.local:6006/ (Press CTRL+C to quit)
^C
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Hyperparameter-Experimenting---Training-Neural-Networks">
<a class="anchor" href="#Hyperparameter-Experimenting---Training-Neural-Networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameter Experimenting - Training Neural Networks<a class="anchor-link" href="#Hyperparameter-Experimenting---Training-Neural-Networks"> </a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The best part about TensorBoard is its out-of-the-box capability of tracking our hyperparameters over time and across runs. We can use TensorBoard to rapidly experiment with different training hyperparameters comparing the results.</p>
<p>To uniquely identify each run, we can either set the file name of the run directly, or pass a comment string to the constructor that will be appended to the auto-generated file name.</p>
<p>Note the <code>cross_entropy</code> function with <code>reduction=mean</code> has averaged the loss over batch size and our <code>total_loss</code> is then summed up. It is correct if we have a fix batch size and its value is divisible by number of sample (if not, last batch will has less sample than others). However, in the case of batch size vary, we have to change <code>reduction=sum</code>.</p>
<p>If we have a list of parameters, we can package them up into a set for each of our runs using the Cartesian product. The Cartesian product takes multiple sets as arguments and return a set of all ordered pairs. Note that this is equivalent to nested for-loops.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span> <span class="c1"># itertools' Cartesian product implementation</span>

<span class="c1"># define the list of parameters and their value list that we want to tolerate</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">param_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
<span class="c1"># use the Cartesian product to iterate over the pairs of parameters'values </span>
<span class="k">for</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.1 10
0.1 100
0.01 10
0.01 100
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">preds</span><span class="p">,</span> <span class="n">lbs</span><span class="p">:</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">lbs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>

<span class="k">for</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_values</span><span class="p">):</span>        
    <span class="n">train_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dl</span><span class="p">))</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

    <span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">" batch_size = </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, lr = </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">"</span>
    <span class="n">tb</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">comment</span><span class="o">=</span><span class="n">comment</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">'images'</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_acc</span>  <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
            <span class="n">loss</span>  <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">lbls</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'sum'</span><span class="p">)</span> 

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_acc</span>  <span class="o">+=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">lbls</span><span class="p">)</span>

        <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'average_loss'</span><span class="p">,</span> <span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'average_acc'</span><span class="p">,</span> <span class="n">total_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">epoch</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span><span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.grad"</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch:       </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_acc : </span><span class="si">{</span><span class="n">total_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">tb</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/phucnsp/anaconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  """Entry point for launching an IPython kernel.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch:       0 
avg_loss: 2.3510418080329893 
avg_acc : 0.10213333333333334
epoch:       1 
avg_loss: 2.3241496319452923 
avg_acc : 0.10206666666666667
epoch:       2 
avg_loss: 2.3241496464411417 
avg_acc : 0.10208333333333333
epoch:       0 
avg_loss: 2.31076997756958 
avg_acc : 0.09978333333333333
epoch:       1 
avg_loss: 2.3104461242675782 
avg_acc : 0.0994
epoch:       2 
avg_loss: 2.3104453076680502 
avg_acc : 0.09963333333333334
epoch:       0 
avg_loss: 2.3050063188870746 
avg_acc : 0.10093333333333333
epoch:       1 
avg_loss: 2.3049483956654866 
avg_acc : 0.1014
epoch:       2 
avg_loss: 2.3049483927408856 
avg_acc : 0.1014
epoch:       0 
avg_loss: 2.3035935297648114 
avg_acc : 0.10016666666666667
epoch:       1 
avg_loss: 2.303564562733968 
avg_acc : 0.09968333333333333
epoch:       2 
avg_loss: 2.303563890838623 
avg_acc : 0.09968333333333333
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>tensorboard --logdir<span class="o">=</span>runs
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow installation not found - running with reduced feature set.
TensorBoard 1.15.0 at http://VN0130.local:6007/ (Press CTRL+C to quit)
^C
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can refactor the way we manage parameters by using the following <code>RunBuilder</code> Class. The method <code>get_runs()</code> will get the runs for us that it builds based on the parameters we pass in.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="k">class</span> <span class="nc">RunBuilder</span><span class="p">():</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_runs</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="c1"># create new tuple subclass called Run with named fields got from params.keys</span>
        <span class="n">Run</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">'Run'</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>  
        <span class="n">runs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># use Cartesian product to pair parameters'values and pass to Run.</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">runs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Run</span><span class="p">(</span><span class="o">*</span><span class="n">v</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">runs</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">01</span><span class="p">,</span> <span class="o">.</span><span class="mi">001</span><span class="p">],</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">runs</span> <span class="o">=</span> <span class="n">RunBuilder</span><span class="o">.</span><span class="n">get_runs</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">runs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Run(lr=0.01, batch_size=10),
 Run(lr=0.01, batch_size=100),
 Run(lr=0.001, batch_size=10),
 Run(lr=0.001, batch_size=100)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the <code>RunBuilder</code> class has built and returned a list of four runs. Each of these runs has a learning rate and a batch size that defines the run.<br>
Notice the string representation of the run output. This string representation was automatically generated for us by the Run tuple class, and this string can be used to uniquely identify the run if we want to write out run statistics to disk for TensorBoard or any other visualization program.<br>
Additionally, because the run is object is a tuple with named attributes, we can access the values using dot notation like so:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">run</span> <span class="o">=</span> <span class="n">runs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">run</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">run</span><span class="o">.</span><span class="n">batch_size</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.01, 10)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All we have to do to add additional values is to add them to the original parameter list, and if we want to add an additional type of parameter, all we have to do is add it. The new parameter and its values will automatically become available to be consumed inside the run. The string output for the run also updates as well.</p>
<p>This functionality will allow us to have greater control as we experiment with different values during training.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">preds</span><span class="p">,</span> <span class="n">lbs</span><span class="p">:</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">lbs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>

<span class="c1"># for lr, batch_size in product(*param_values):                                  # old code</span>
<span class="k">for</span> <span class="n">run</span> <span class="ow">in</span> <span class="n">RunBuilder</span><span class="o">.</span><span class="n">get_runs</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>                                          <span class="c1"># Changes for RunBuilder</span>
    <span class="n">train_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">run</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1"># Changes for RunBuilder</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">run</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>                  <span class="c1"># Changes for RunBuilder</span>

    <span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dl</span><span class="p">))</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

<span class="c1">#     comment = f" batch_size = {batch_size}, lr = {lr}"                          # old code</span>
    <span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'-</span><span class="si">{</span><span class="n">run</span><span class="si">}</span><span class="s1">'</span>                                                           <span class="c1"># Changes for RunBuilder</span>
    <span class="n">tb</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">comment</span><span class="o">=</span><span class="n">comment</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">'images'</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_acc</span>  <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
            <span class="n">loss</span>  <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">lbls</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'sum'</span><span class="p">)</span> 

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_acc</span>  <span class="o">+=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">lbls</span><span class="p">)</span>

        <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'average_loss'</span><span class="p">,</span> <span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'average_acc'</span><span class="p">,</span> <span class="n">total_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">epoch</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span><span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.grad"</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"epoch:       </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">avg_acc : </span><span class="si">{</span><span class="n">total_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">tb</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Speeding-up-the-training-process-by-increasing-num_workers">
<a class="anchor" href="#Speeding-up-the-training-process-by-increasing-num_workers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Speeding up the training process by increasing num_workers<a class="anchor-link" href="#Speeding-up-the-training-process-by-increasing-num_workers"> </a>
</h5>
<p>To speed up the training process, we will make use of the <code>num_workers</code> optional attribute of the <code>DataLoader</code> class. By setting this number to <code>1</code>, default set to <code>0</code>, the speep can increase up to 20% and does not improve more or even worse with setting more than 1.</p>
<p>The num_workers attribute tells the data loader instance how many sub-processes to use for data loading. By default, the num_workers value is set to zero, the training process will work sequentially inside the main process. After a batch is used during the training process and another one is needed, we read the batch data from disk.<br>
Now, if we have a worker process, we can make use of the fact that our machine has multiple cores. This means that the next batch can already be loaded and ready to go by the time the main process is ready for another batch. This is where the speed up comes from.<br>
If we add more batches to the queue doesn't mean the batches are being processes faster because we are bounded by the time it takes to forward and backward propagate a given batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Stack-vs-Concat">
<a class="anchor" href="#Stack-vs-Concat" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stack vs Concat<a class="anchor-link" href="#Stack-vs-Concat"> </a>
</h2>
<p>Concatenating joins a sequence of tensors along an existing axis, and stacking joins a sequence of tensors along a new axis.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Now, letâ€™s concatenate these with one another. Notice that each of these tensors have a single axis. This </span>
<span class="c1"># means that the result of the cat function will also have a single axis. This is because when we concatenate, </span>
<span class="c1"># we do it along an existing axis. Notice that in this example, the only existing axis is the first axis.</span>
<span class="c1"># Alright, so we took three single axis tensors each having an axis length of three, and now we have a single </span>
<span class="c1"># tensor with an axis length of nine.</span>

<span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([9])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Now, letâ€™s stack these tensors along a new axis that weâ€™ll insert. Weâ€™ll insert an axis at the first index. </span>
<span class="c1"># Note that this insertion will be happening implicitly under the hood by the stack function.</span>
<span class="c1"># This gives us a new tensor that has a shape of 3 x 3. Notice how the three tensors are concatenated along </span>
<span class="c1"># the first axis of this tensor. Note that we can also insert the new axis explicitly, and preform the </span>
<span class="c1"># concatenation directly.</span>

<span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 3])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example of combining stack and concat</span>
<span class="c1"># Joining Images With An Existing Batch</span>
<span class="c1"># Suppose we have the same three separate image tensors. Only, this time, we already have a batch tensor. </span>
<span class="c1"># Assume our task is to join these three separate images with the batch.</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">(</span>
        <span class="n">batch</span>
        <span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">)</span>
            <span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Joining Batches Into A Single Batch</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">)</span>
    <span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 3, 28, 28])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Joining Images Into A Single Batch</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
    <span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">)</span>
    <span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 3, 28, 28])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Disabling-PyTorch-Gradient-Tracking">
<a class="anchor" href="#Disabling-PyTorch-Gradient-Tracking" aria-hidden="true"><span class="octicon octicon-link"></span></a>Disabling PyTorch Gradient Tracking<a class="anchor-link" href="#Disabling-PyTorch-Gradient-Tracking"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get predictions for the entire training set</span>
<span class="c1"># Note at the top, we have annotated the function using the @torch.no_grad() PyTorch decoration. </span>
<span class="c1"># This is because we want this functions execution to omit gradient tracking. This is because gradient </span>
<span class="c1"># tracking uses memory, and during inference (getting predictions while not training) there is no need to </span>
<span class="c1"># keep track of the computational graph. The decoration is one way of locally turning off the gradient tracking</span>
<span class="c1"># feature while executing specific functions. We specifically need the gradient calculation feature anytime we </span>
<span class="c1"># are going to calculate gradients using the backward() function. Otherwise, it is a good idea to turn it off</span>
<span class="c1"># because having it off will reduce memory consumption for computations, e.g. when we are using networks for </span>
<span class="c1"># predicting (inference).</span>

<span class="c1"># As another example, we can use Python's with context manger keyword to specify that a specify block of code</span>
<span class="c1"># should exclude gradient computations.</span>
<span class="c1"># Both of these options are valid</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_all_preds</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
    <span class="n">all_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">lbs</span> <span class="o">=</span> <span class="n">batch</span>
        
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">all_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">all_preds</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">all_preds</span>

<span class="c1"># Locally Disabling PyTorch Gradient Tracking</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">prediction_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="n">train_preds</span> <span class="o">=</span> <span class="n">get_all_preds</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prediction_loader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Effective-Pytorch">
<a class="anchor" href="#Effective-Pytorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effective Pytorch<a class="anchor-link" href="#Effective-Pytorch"> </a>
</h2>
<p><a href="https://github.com/vahidk/EffectivePyTorch?fbclid=IwAR1MhsjnjccWy6dIVtibFOCZbWhLtAj5pSTobnkUDxw_gHgfEswnVzqrKQ0#torchscript">https://github.com/vahidk/EffectivePyTorch?fbclid=IwAR1MhsjnjccWy6dIVtibFOCZbWhLtAj5pSTobnkUDxw_gHgfEswnVzqrKQ0#torchscript</a></p>
<ul>
<li>PyTorch is similar to NumPy, with the additional benefit that PyTorch allows you to perform your computations on CPUs, GPUs, and TPUs without any material change to your code. PyTorch also makes it easy to distribute your computation across multiple devices or machines. One of the most important features of PyTorch is automatic differentiation. It allows computing the gradients of your functions analytically in an efficient manner which is crucial for training machine learning models using gradient descent method</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The first thing to learn about PyTorch is the concept of Tensors. Tensors are simply multidimensional arrays. A PyTorch Tensor is very similar to a NumPy array with some magical additional functionality.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># One of the most commonly used operations in machine learning applications is matrix multiplication</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="nd">@y</span>
<span class="n">z</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-1.9095e+00,  2.7157e+00,  3.0564e+00, -2.6597e+00, -3.5740e+00],
        [ 5.7195e-01,  1.1266e+00, -2.7287e+00,  1.9540e+00,  2.5402e-03],
        [ 2.6661e+00,  3.8373e+00, -3.7645e+00,  2.2918e-02, -1.5655e+00]])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># add 2 tensors</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># convert between torch and numpy</span>
<span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Automatic Differentiation</span>
<span class="c1"># The most important advantage of PyTorch over NumPy is its automatic differentiation functionality which is </span>
<span class="c1"># very useful in optimization applications such as optimizing parameters of a neural network</span>
<span class="c1"># Say you have a composite function which is a chain of two functions: g(u(x)). To compute the derivative of g </span>
<span class="c1"># with respect to x we can use the chain rule which states that: dg/dx = dg/du * du/dx. PyTorch can analytically</span>
<span class="c1"># compute the derivatives for us.</span>

<span class="c1"># To compute the derivatives in PyTorch first we create a tensor and set its requires_grad to true. We can use </span>
<span class="c1"># tensor operations to define our functions. We assume u is a quadratic function and g is a simple linear </span>
<span class="c1"># function</span>

<span class="c1"># In this case our composite function is g(u(x)) = -x*x. So its derivative with respect to x is -2x. At point</span>
<span class="c1"># x=1, this is equal to -2.</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">u</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span>
<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">u</span><span class="p">):</span> <span class="k">return</span> <span class="o">-</span><span class="n">u</span>

<span class="n">dgdx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">g</span><span class="p">(</span><span class="n">u</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">x</span><span class="p">)</span>
<span class="n">dgdx</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(-2.),)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,
        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,
        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,
        42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,
        56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.,
        70., 71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81., 82., 83.,
        84., 85., 86., 87., 88., 89., 90., 91., 92., 93., 94., 95., 96., 97.,
        98., 99.])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># There are some predefined modules that act as a container for other modules. The most commonly used container </span>
<span class="c1"># module is torch.nn.Sequential. As its name implies it's used to to stack multiple modules (or layers) on top</span>
<span class="c1"># of each other. For example to stack two Linear layers with a ReLU nonlinearity in between you can do:</span>

<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># optimizing runtime with TorchScript</span>

<span class="c1"># PyTorch is optimized to perform operations on large tensors. Doing many operations on small tensors is quite</span>
<span class="c1"># inefficient in PyTorch. So, whenever possible you should rewrite your computations in batch form to reduce</span>
<span class="c1"># overhead and improve performance. If there's no way you can manually batch your operations, using TorchScript</span>
<span class="c1"># may improve your code's performance. TorchScript is simply a subset of Python functions that are recognized by</span>
<span class="c1"># PyTorch. PyTorch can automatically optimize your TorchScript code using its just in time (jit) compiler and </span>
<span class="c1"># reduce some overheads.</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">);</span> 

<span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
<span class="k">def</span> <span class="nf">batch_gather_jit</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
<span class="c1">#     import pdb; pdb.set_trace()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]]]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># %%timeit</span>
<span class="c1"># %time</span>
<span class="o">%</span><span class="k">time</span> batch_gather_jit(t, idx)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 4.27 ms, sys: 739 Âµs, total: 5.01 ms
Wall time: 3.99 ms
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([1., 3., 5.])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">);</span> 

<span class="c1"># @torch.jit.script</span>
<span class="k">def</span> <span class="nf">batch_gather_jit</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
<span class="c1">#     import pdb; pdb.set_trace()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]]]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># %%timeit</span>
<span class="c1"># %time</span>
<span class="o">%</span><span class="k">time</span> batch_gather_jit(t, idx)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 237 Âµs, sys: 462 Âµs, total: 699 Âµs
Wall time: 3.16 ms
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([1., 3., 5.])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">);</span> 

<span class="k">def</span> <span class="nf">batch_gather_vec</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">flat_first</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">tensor</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">flat_first</span><span class="p">[</span><span class="n">indices</span> <span class="o">+</span> <span class="n">offset</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="o">%</span><span class="k">time</span> batch_gather_vec(t, idx)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 866 Âµs, sys: 2.32 ms, total: 3.19 ms
Wall time: 8.97 ms
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([1., 3., 5.])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># broadcasting: the good and the ugly</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="phucnsp/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>This blog contains my personal view about everything either in work and life.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/phucnsp" title="phucnsp"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Phuc_Nguyen_Su" title="Phuc_Nguyen_Su"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
