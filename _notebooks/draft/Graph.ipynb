{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph\n",
    "> in progress\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [self-taught]\n",
    "- image: images/bone.jpeg\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/using-graph-convolutional-neural-networks-on-structured-documents-for-information-extraction-c1088dcd2b8f\n",
    "\n",
    "CNNs effectively capture patterns in data in Euclidean space\n",
    "\n",
    "data is represented in the form of a Graph and lack a grid-like regularity. \n",
    "As Graphs can be irregular, they may have a variable size of un-ordered nodes and each node may have a different number of neighbors, resulting in mathematical operations such as convolutions difficult to apply to the Graph domain.\n",
    "\n",
    "Some examples of such non-Euclidean data include:\n",
    "- Protein-Protein Interaction Data where interactions between molecules are modeled as graphs\n",
    "- Citation Networks where scientific papers are nodes and citations are uni- or bi-directional edges\n",
    "- Social Networks where people on the network are nodes and their relationships are edges\n",
    "\n",
    "This article particularly discusses the use of Graph Convolutional Neural Networks (GCNs) on structured documents such as Invoices and Bills to automate the extraction of meaningful information by learning positional relationships between text entities.\n",
    "\n",
    "What is a Graph?\n",
    "\n",
    "\n",
    "\n",
    "**How to convert Structured Documents to Graphs?**\n",
    "Such recurring structural information along with text attributes can help a Graph Neural Network learn neighborhood representations and perform node classification as a result\n",
    "\n",
    "\n",
    "Geometric Algorithm: Connecting objects based on visibility\n",
    "\n",
    "\n",
    "**Convolution on Document Graphs for Information Extraction**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/overview-of-deep-learning-on-graph-embeddings-4305c10ad4a4\n",
    "\n",
    "Graph embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/graph-convolutional-networks-for-geometric-deep-learning-1faf17dee008m\n",
    "\n",
    "Graph Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1611.08097.pdf  \n",
    "https://arxiv.org/pdf/1901.00596.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/graph-theory-and-deep-learning-know-hows-6556b0e9891b\n",
    "\n",
    "**Everything you need to know about Graph Theory for Deep Learning**\n",
    "\n",
    "Graph Theory — crash course\n",
    "\n",
    "1. What is a graph?\n",
    "\n",
    "A graph, in the context of graph theory, is a structured datatype that has nodes (entities that hold information) and edges (connections between nodes that can also hold information). A graph is a way of structuring data, but can be a datapoint itself. Graphs are a type of Non-Euclidean data, which means they exist in 3D, unlike other datatypes like images, text, and audio.\n",
    "\n",
    "\n",
    "- Graphs can have labels on their edges and/or nodes\n",
    "- Labels can also be considered weights, but that’s up to the graph’s designer.\n",
    "- Labels don’t have to be numerical, they can be textual.\n",
    "- Labels don’t have to be unique;\n",
    "- Graphs can have features (a.k.a attributes).\n",
    "\n",
    "Take care not to mix up features and labels. \n",
    "> Note: a node is a person, a node’s label is a person’s name, and the node’s features are the person’s characteristics.\n",
    "\n",
    "- Graphs can be directed or undirected\n",
    "- A node in the graph can even have an edge that points/connects to itself. This is known as a self-loop.\n",
    "\n",
    "Graphs can be either:\n",
    "- Heterogeneous — composed of different types of nodes\n",
    "- Homogeneous — composed of the same type of nodes\n",
    "\n",
    "and are either:\n",
    "- Static — nodes and edges do not change, nothing is added or taken away\n",
    "- Dynamic — nodes and edges change, added, deleted, moved, etc.\n",
    "\n",
    "graphs can be vaguely described as either\n",
    "- Dense — composed of many nodes and edges\n",
    "- Sparse — composed of fewer nodes and edges\n",
    "\n",
    "Graphs can be made to look neater by turning them into their planar form, which basically means rearranging nodes such that edges don’t intersect\n",
    "\n",
    "2. Graph Analysis\n",
    "3. E-graphs — graphs on computers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@flawnsontong1/what-is-geometric-deep-learning-b2adb662d91d\n",
    "\n",
    "**What is Geometric Deep Learning?**\n",
    "\n",
    "The vast majority of deep learning is performed on Euclidean data. This includes datatypes in the 1-dimensional and 2-dimensional domain. \n",
    "Images, text, audio, and many others are all euclidean data.\n",
    "\n",
    "`Non-euclidean data` can represent more complex items and concepts with more accuracy than 1D or 2D representation:\n",
    "\n",
    "When we represent things in a non-euclidean way, we are giving it an inductive bias. \n",
    "An inductive bias allows a learning algorithm to prioritize one solution (or interpretation) over another, independent of the observed data. Inductive biases can express assumptions about either the data-generating process or the space of solutions.\n",
    "In the majority of current research pursuits and literature, the inductive bias that is used is relational.\n",
    "\n",
    "Building on this intuition, `Geometric Deep Learning (GDL)` is the niche field under the umbrella of deep learning that aims to build neural networks that can learn from non-euclidean data.\n",
    "\n",
    "The prime example of a non-euclidean datatype is a graph. `Graphs` are a type of data structure that consists of `nodes` (entities) that are connected with `edges` (relationships). This abstract data structure can be used to model almost anything.\n",
    "\n",
    "\n",
    "We want to be able to learn from graphs because:\n",
    "\n",
    "`\n",
    "Graphs allow us to represent individual features, while also providing information regarding relationships and structure.\n",
    "`\n",
    "`Graph theory` is the study of graphs and what we can learn from them. There are various types of graphs, each with a set of rules, properties, and possible actions. \n",
    "\n",
    "Examples of Geometric Deep Learning\n",
    "- Molecular Modeling and learning: \n",
    "One of the bottlenecks in computational chemistry, biology, and physics is the representation concepts, entities, and interactions. Our current methods of representing these concepts computationally can be considered “lossy”, since we lose a lot of valuable information. By treating atoms as nodes, and bonds as edges, we can save structural information that can be used downstream in prediction or classification.\n",
    "\n",
    "- 3D Modeling and Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 types of bias\n",
    "https://twitter.com/math_rachel/status/1113203073051033600\n",
    "https://arxiv.org/pdf/1806.01261.pdf\n",
    "https://stackoverflow.com/questions/35655267/what-is-inductive-bias-in-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ocr]",
   "language": "python",
   "name": "conda-env-ocr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
