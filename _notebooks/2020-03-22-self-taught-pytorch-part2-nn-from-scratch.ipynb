{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch part 2 - neural net from scratch \n",
    "> This notebook will create and train model from scratch and then gradually refactor it by using built-in pytorch modules\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [self-taught, tutorial]\n",
    "- image: images/pytorch_ava.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [part 1](https://phucnsp.github.io/blog/self-taught/2020/03/22/self-taught-pytorch-part1-tensor.html) of this serie, we have gone through the basic elements of neural network. In this part we will start writing a program. \n",
    "\n",
    "Computer programs in general consist of two primary components, `code` and `data`. With traditional programming, the programmer’s job is to explicitly write the software or code to perform computations. But with deep learning and neural networks, this job explicitly belongs to the optimization algorithm. It will compile our data into code which is actually neural net's weights. The programmer’s job is to oversee and guide the learning process though training. We can think of this as an indirect way of writing software or code. \n",
    "\n",
    "In order to have an overview of `where we are`, we will briefly talk about fundamental stages of an machine learning/deep learning project. \n",
    "1. Project planning and project setup\n",
    "Gather team, define requirements, goals and allocate resources\n",
    "2. Data collection and labelling\n",
    "Define which data to collect and label them\n",
    "3. **Training and debugging: we are here**\n",
    "Start implementing, debugging and improving model. This serie will focus on this stage using Pytorch framework. \n",
    "4. Deploying and testing\n",
    "Write tests to prevent regresison, roll out in production.\n",
    "\n",
    "So now, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch provides the elegantly designed modules and classes to help you create and train neural networks.  \n",
    "Following are the most fundamental modules which we will repeatly work with along the way.\n",
    "\n",
    "| Package                | Description                                                                                                      |\n",
    "|------------------------|---------------------------------------------------------------------------------------|\n",
    "| torch                  | The top-level PyTorch package and tensor library.|\n",
    "| torch.nn               | A subpackage that contains modules and extensible classes for building neural networks.|\n",
    "| torch.nn.functional    | A functional interface that contains typical operations used for building neural networks like loss functions and convolutions. |\n",
    "| torch.autograd    | handle the automatic differentiation of arbitrary scalar valued functions.\n",
    "| torch.optim            | A subpackage that contains standard optimization operations like SGD and Adam.|\n",
    "| torchvision            | A package that provides access to popular datasets, model architectures, and image transformations for computer vision.|\n",
    "| torchvision.transforms | An interface that contains common transforms for image processing.|\n",
    "\n",
    "In order to fully understand exactly what ther are doing, we will create and train a very basic neural network from scratch which initially only use the most basic Pytorch tensor functionality and gradually refactor it with those Pytorch built-in modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T03:26:25.693227Z",
     "start_time": "2020-04-19T03:26:25.599155Z"
    }
   },
   "source": [
    "Data is the primary ingredient of deep learning. Before feeding data into our network, we need to consider many aspects such as:\n",
    "- Who created the dataset?\n",
    "- How was the dataset created?\n",
    "- What transformations were used?\n",
    "- What intent does the dataset have?\n",
    "- Possible unintentional consequences?\n",
    "- Is the dataset biased?\n",
    "- Are there ethical issues with the dataset?\n",
    "\n",
    "In this tutorial, we will use the well-prepared `Fashion-MNIST` dataset which was created by research lab of Zalando - a German based multi-national fashion commerce company. The dataset was designed to mirror the original MNIST dataset as closely as possible while introducing higher difficulty in training due to simply having more complex data than hand written images. The abstract from its [paper](https://arxiv.org/abs/1708.07747):  \n",
    "\n",
    "`We present Fashion-MNIST, a new dataset comprising of 28 × 28 grayscale images of 70, 000 fashion products from 10 categories, with 7, 000 images per category. The training set has 60, 000 images and the test set has 10, 000 images. Fashion-MNIST is intended to serve as a direct dropin replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist.`\n",
    "\n",
    "The Fashion-MNIST was built, unlike the hand-drawn MNIST dataset, from actual images on Zalando’s website. However, they have been transformed to more closely correspond to the MNIST specifications. This is the general conversion process that each image from the site went through:\n",
    "- Converted to PNG\n",
    "- Trimmed\n",
    "- Resized\n",
    "- Sharpened\n",
    "- Extended\n",
    "- Negated\n",
    "- Gray-scaled\n",
    "\n",
    "The dataset has the following ten classes of fashion items:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:00.262600Z",
     "start_time": "2020-04-20T09:21:00.258313Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2clas = {0 : \"T-shirt/top\",\n",
    "            1 : \"Trouser\",\n",
    "            2 : \"Pullover\",\n",
    "            3 : \"Dress\",\n",
    "            4 : \"Coat\",\n",
    "            5 : \"Sandal\",\n",
    "            6 : \"Shirt\",\n",
    "            7 : \"Sneaker\",\n",
    "            8 : \"Bag\",\n",
    "            9 : \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T03:26:25.693227Z",
     "start_time": "2020-04-19T03:26:25.599155Z"
    }
   },
   "source": [
    "A sample of the items look like this:  \n",
    "\n",
    "![sample_fashition_mnist](data/sample_fashion_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T06:55:01.425727Z",
     "start_time": "2020-04-19T06:55:01.421312Z"
    }
   },
   "source": [
    "That's enough background information about the dataset. Now we will prepare data for our network.   \n",
    "\n",
    "The general idea of this step is to transform our dataset into tensor format so we can take advantages of GPU's parallel computing for later steps such as data augmentation, training model, etc.    \n",
    "\n",
    "We'll follow the ETL process to prepare data:  \n",
    "- Extract: Get the Fashion-MNIST image data from the source.  \n",
    "- Transform: Put our data into tensor form.  \n",
    "- Load: Put our data into an object to make it easily accessible.  \n",
    "\n",
    "The Fashion-MNIST source code can be accessed [here](https://github.com/zalandoresearch/fashion-mnist). We will use `pathlib` for dealing with paths and will download 4 parts - training set images, training set labels, test set images and test set labels - using `requests` library. Since this dataset has been stored using pickle, a python-specific format for serializing data, we need to unzip and deserialize it in order to read the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:03.981414Z",
     "start_time": "2020-04-20T09:21:02.685813Z"
    }
   },
   "outputs": [],
   "source": [
    "# a. extract data from source\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "PATH_ROOT = Path(\"data/fashion_mnist\")\n",
    "PATH_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URLs = [\n",
    "\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\",\n",
    "\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\",\n",
    "\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\",\n",
    "\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\"\n",
    "]\n",
    "\n",
    "def download_data(path_root, url):\n",
    "    filename = Path(url).name\n",
    "    if not (path_root / filename).exists():\n",
    "        content = requests.get(url).content\n",
    "        (path_root / filename).open(\"wb\").write(content)\n",
    "        \n",
    "for url in URLs: download_data(PATH_ROOT, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:05.839705Z",
     "start_time": "2020-04-20T09:21:03.983081Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "x_train, y_train = load_data(PATH_ROOT, kind='train')\n",
    "x_valid, y_valid = load_data(PATH_ROOT, kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: I am using the work `valid` and `test` interchangeble but in reality they are different and will be covered in later part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is in numpy array format. Each image is `28*28` and is being stored as a flattened row of length 784.   \n",
    "Let's reshape and take a look at one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:22.103831Z",
     "start_time": "2020-04-20T09:21:22.092761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:22.518395Z",
     "start_time": "2020-04-20T09:21:22.513632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:23.131955Z",
     "start_time": "2020-04-20T09:21:23.127250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:23.752329Z",
     "start_time": "2020-04-20T09:21:23.748114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.max(), y_valid.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:21:26.261109Z",
     "start_time": "2020-04-20T09:21:24.509004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_train[0].reshape(28,28), cmap=\"gray\")\n",
    "idx2clas[y_train[0].item()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will transform data into tensor format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:27.443241Z",
     "start_time": "2020-04-20T09:22:25.248650Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# transform 1. convert to tensor\n",
    "x_train, x_valid = map(lambda p: torch.tensor(p, dtype=torch.float32), (x_train, x_valid))\n",
    "y_train, y_valid = map(lambda p: torch.tensor(p, dtype=torch.int64), (y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And normalize the image tensor. This is standard step in image processing which helps faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:30.230184Z",
     "start_time": "2020-04-20T09:22:29.722700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 72.9342041015625, std: 90.02118682861328\n"
     ]
    }
   ],
   "source": [
    "# transform 2. normalize images\n",
    "mean = x_train.mean()\n",
    "std = x_train.std()\n",
    "print(f\"mean: {mean}, std: {std}\")\n",
    "x_train, x_valid = map(lambda p: (p - mean)/std, (x_train, x_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:30.946109Z",
     "start_time": "2020-04-20T09:22:30.780456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-4.0474e-07), tensor(1.0000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:31.466481Z",
     "start_time": "2020-04-20T09:22:31.435199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0023), tensor(0.9984))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: we need to set dtype=torch.float32 in order to be able to make matrix multiplication later on with  linear layer's weight matrix. Two tensor have to have the same datatype and device so as to do operations.\n",
    "\n",
    "And finally, load data into an object to make it easily accessible. This task normally is handled by Pytorch `DataLoader` object but since we are building everything from scratch, let's use the traditional `for loop` to access batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T09:18:53.933299Z",
     "start_time": "2020-04-19T09:18:53.930626Z"
    }
   },
   "outputs": [],
   "source": [
    "# c. load batches of data\n",
    "batch_size = 64\n",
    "nr_iters = len(x_train) // batch_size\n",
    "\n",
    "for i in range((nr_iters + 1)):\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    xs = x_train[start_index:end_index]\n",
    "    ys = y_train[start_index:end_index]\n",
    "    print(xs.shape)\n",
    "    print(ys.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create and training simple neural net from scratch\n",
    "\n",
    "For our 10-class classification problem, we will create a simple network which contains only a linear layer and a non-linear layer - softmax. \n",
    "\n",
    "In general, a layer contains 2 parts: \n",
    "- `data`: represents the state of that layer. In particular, they are weight and bias - learnable parameters which are updated/learned during training process. \n",
    "- `transformation`: the operation which transform layer's input to output using learnable parameters.\n",
    "\n",
    "`Linear layers`'s data is `weight matrix tensor` and `bias tensor` while its transformation is the `matrix multiplication`. The weight matrix defines a linear function that maps a 1-dimentional tensor with 784 elements to a 1-dimensional tensor with 10 elements. \n",
    "\n",
    "Briefly remind the mathematical function of linear layer.   \n",
    "Given $A$, $x$, $b$, $y$ are `Weight matrix tensor`, `Input tensor`, `Bias tensor` and `Output tensor`, respectively. Mathematical notation of the linear transformation is:\n",
    "\\begin{equation}\n",
    "y=A x+b\n",
    "\\end{equation}\n",
    "\n",
    "We will initialize the weight matrix tensor following the recommendation from [Xavier initialisation paper](https://arxiv.org/abs/1502.01852). This paper tackled the problem with randomly initialized weight drawn from Gaussian distribution which caused hard convergence of deep network.\n",
    "> Tip: \n",
    "    - we set `requires_grad` after initialization, since we don't want that step included in the gradident. \n",
    "    - The trailing `_` in Pytorch signifies that the operation is performed in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:37.381690Z",
     "start_time": "2020-04-20T09:22:37.377526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias    = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Thanks to Pytorch's ability to calculate gradients automatically, we can use any standard Python function (or callable object) as a model.   \n",
    "The log_softmax function is implemented using `log-sum-exp trick` for numerically stable. We will not go to detail this trick but you can go [here](https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/) or [here](https://www.tensorflow.org/api_docs/python/tf/nn/log_softmax) for details explanation. The formular for this trick is: \n",
    "$$ log\\_softmax(x) = x - logsumexp(x) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:39.352194Z",
     "start_time": "2020-04-20T09:22:39.348435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "def simplenet(x): return log_softmax(x @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Tip: `@` stand for dot product operation.\n",
    "\n",
    "Now we have had a simple network and data setup. Let's try to predict a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:41.474947Z",
     "start_time": "2020-04-20T09:22:41.461353Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "xs, ys = x_train[:bs], y_train[:bs]\n",
    "preds = simplenet(xs)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:42.126517Z",
     "start_time": "2020-04-20T09:22:42.120071Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4405, -3.5105, -2.7565, -1.4291, -2.4875, -2.0924, -4.0225, -4.0119,\n",
       "         -2.5381, -2.2188],\n",
       "        [-4.8259, -3.7734, -2.0315, -2.3298, -0.9287, -2.6093, -3.6926, -2.2518,\n",
       "         -1.9918, -5.2320],\n",
       "        [-2.6215, -2.3225, -1.9596, -1.8593, -2.6342, -2.3268, -1.6219, -2.6988,\n",
       "         -2.7874, -3.3023],\n",
       "        [-3.2222, -3.1183, -1.6531, -1.5975, -2.2923, -2.7484, -1.7113, -2.3899,\n",
       "         -2.6972, -4.0560],\n",
       "        [-4.0472, -4.3383, -2.3563, -1.5838, -0.7511, -2.6288, -3.0189, -3.5576,\n",
       "         -3.2544, -4.6537],\n",
       "        [-2.2369, -3.2984, -0.9843, -2.8722, -2.3741, -1.8116, -4.1416, -5.1253,\n",
       "         -2.9522, -2.3493],\n",
       "        [-1.8748, -4.8596, -2.7152, -1.2111, -3.2741, -2.0744, -2.4669, -2.8398,\n",
       "         -2.7450, -2.2655],\n",
       "        [-2.7887, -4.9238, -1.3429, -3.5693, -2.6362, -1.4553, -5.4066, -6.6005,\n",
       "         -3.2211, -1.2336],\n",
       "        [-3.9236, -2.5255, -2.9410, -0.6889, -4.0574, -3.9685, -2.6249, -1.6157,\n",
       "         -4.2080, -3.7726],\n",
       "        [-1.7502, -1.8132, -1.7902, -1.9453, -3.3830, -3.7103, -2.6871, -3.1987,\n",
       "         -2.2021, -2.5852],\n",
       "        [-3.7683, -3.3224, -2.6373, -2.0115, -0.7844, -2.8311, -2.6774, -2.6067,\n",
       "         -2.6543, -4.9239],\n",
       "        [-3.2636, -3.2367, -1.4613, -2.2395, -2.4437, -2.0885, -2.9661, -3.5086,\n",
       "         -1.3777, -3.2262],\n",
       "        [-1.4874, -4.1664, -2.1750, -1.5891, -3.1738, -2.5524, -2.2160, -3.7046,\n",
       "         -2.8008, -2.0662],\n",
       "        [-2.6747, -3.6151, -2.5766, -1.4708, -3.7484, -3.1546, -1.2979, -3.1983,\n",
       "         -2.5499, -1.9650],\n",
       "        [-2.2535, -4.0095, -3.1679, -0.7156, -3.5641, -2.4768, -2.4170, -3.0718,\n",
       "         -3.2315, -2.8394],\n",
       "        [-1.1524, -4.3791, -3.3212, -1.0543, -3.4922, -2.1228, -4.1253, -3.9749,\n",
       "         -2.9178, -3.0380]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What we did above is one `forward pass`, we load a batch of image add feed it through the network.   \n",
    "The result will not be better than a random prediction at this stage because we start with random weights.\n",
    "\n",
    "As we see in the `preds` tensor, it contains not only the tensor values but also a gradient function. As mentioned in part 1, pytorch use dynamic computational graph to track function operations that occur on tensors. These graph are then used to compute the derivatives. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:47.739822Z",
     "start_time": "2020-04-20T09:22:47.735999Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SubBackward0 at 0x12bde0310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we need to define the loss function which is the model's objective. Our weights and bias will be updated in the direction which make this loss decreased. One of the most common loss function is `negative log-likelihood`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:49.999501Z",
     "start_time": "2020-04-20T09:22:49.993158Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9355, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(input.shape[0]), target.tolist()].mean()\n",
    "\n",
    "loss_function = nll\n",
    "\n",
    "loss_function(preds, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, We will define a `metric`. During the training, reducing the `loss` is what our model tries to do but it is hard for us, as human, can intuitively understand how good the weights set are along the way. So we need a human-interpretable value which help us understand the training progress and it is the `metric`.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:22:52.143089Z",
     "start_time": "2020-04-20T09:22:52.137762Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(input, target): \n",
    "    return (torch.argmax(input, dim=1) == target).float().mean()\n",
    "\n",
    "accuracy(preds, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are now ready to begin the training process. The training process is an iterative process which including following steps:\n",
    "1. **Get batch from the training set**.  \n",
    "    - Since we have 60,000 samples in our training set, we will have 60,000 / 100 = 600 iterations. Something to notice, batch_size will directly impact to the number of times the weights updated. In our case, the weights will be updated 600 times by the end of each loop. So far, there is no rule-of-thump for selecting the value of batch size so we still need to do trial and error to figure out the best value.\n",
    "> Important: to be simple, I am not shuffling the training set at this stage. In reality, the training set should be shuffled to prevent correlation between batches and overfitting. If we keep feeding the network batch-by-batch in order, the network might remember this order and causes overfitting with this order. On the other hand, the validation loss will be identical whether we shuffle the validation set or not. Since shuffling takes extra time, it makes no sense to shuffle the validation data. \n",
    "    \n",
    "2. **Pass batch to network.**\n",
    "\n",
    "3. **Calculate the loss (difference between the predicted values and the true values).**\n",
    "\n",
    "4. **Calculate the gradient of the loss function w.r.t the network's weights.**\n",
    "   - Calculating the gradients is very easy using PyTorch. Since PyTorch has created a computation graph under the hood. As our tensor flowed forward through our network, all of the computations where added to the graph. The computation graph is then used by PyTorch to calculate the gradients of the loss function with respect to the network's weights.\n",
    "   \n",
    "5. **Update the weights using the gradients to reduce the loss.**\n",
    "    - The gradients calculated from step 4 are used by the optimizer to update the respective weights. \n",
    "    - We have disabled PyTorch gradient tracking at this step because we don't want these actions to be recorded for our next calculation of the gradient. There are many ways to disable this functionality, please check `Random topics` at the end of notebook for more information.\n",
    "    - After updating the weight, we need to zero out the gradients because the gradients will be calculated and added to the grad attributes of our network's parameters after calling loss.backward() at the next iteration.\n",
    "\n",
    "6. **Repeat steps 1-5 until one epoch is completed.**\n",
    "\n",
    "7. **Calculate mean loss of validation set**\n",
    "> Note: We can use a batch size for the validation set that is twice as large as that for the training set. This is because the validation set does not need backpropagation and thus takes less memory (it doesn’t need to store the gradients). We take advantage of this to use a larger batch size and compute the loss more quickly.\n",
    "\n",
    "8. **Repeat steps 1-6 for as many epochs required to reach the minimum loss.**\n",
    "\n",
    "We will use `Stochastic Gradient Descent (SGD)` optimizer to update our learnable parameters during training. `lr` tells the optimizer how far to step in the direction of minimizing loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:23:06.463860Z",
     "start_time": "2020-04-20T09:22:59.488994Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, valid_loss 0.5325431520462036, accuracy 0.8139\n",
      "epoch 1, valid_loss 0.49808417506217956, accuracy 0.8252\n",
      "epoch 2, valid_loss 0.48265715327262876, accuracy 0.8305\n",
      "epoch 3, valid_loss 0.4735100971221924, accuracy 0.8335\n",
      "epoch 4, valid_loss 0.46733067717552185, accuracy 0.8356\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01    \n",
    "epochs = 5  \n",
    "batch_size = 64     \n",
    "\n",
    "nr_iters = len(x_train) // bs\n",
    "for epoch in range(epochs):\n",
    "    for i in range((nr_iters + 1)):\n",
    "        # step 1. get batch of training set\n",
    "        start_index = i * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        xs = x_train[start_index:end_index]\n",
    "        ys = y_train[start_index:end_index]\n",
    "        # step 2. pass batch to network\n",
    "        preds = simplenet(xs)\n",
    "        # step 3. calculate the loss\n",
    "        loss = loss_function(preds, ys)\n",
    "        # step 4. calculate the gradient of the loss w.r.t the network's parameters\n",
    "        loss.backward()\n",
    "        with torch.no_grad(): \n",
    "            # step 5. update the weights using SGD algorithm\n",
    "            weights -= lr * weights.grad\n",
    "            bias    -= lr * bias.grad\n",
    "            weights.grad.zero_()          \n",
    "            bias.grad.zero_()\n",
    "    # step 6. calculate mean of valid loss after each epoch to see the improvement\n",
    "    batch_size_valid = batch_size * 2\n",
    "    nr_iters_valid = len(x_valid) // batch_size_valid\n",
    "    total_loss = 0\n",
    "    total_acc  = 0    \n",
    "    with torch.no_grad():\n",
    "        for i in range((nr_iters_valid + 1)):\n",
    "            start_index = i * batch_size_valid\n",
    "            end_index = start_index + batch_size_valid\n",
    "            xs = x_valid[start_index:end_index]\n",
    "            ys = y_valid[start_index:end_index]\n",
    "            preds = simplenet(xs)\n",
    "            loss = loss_function(preds, ys) \n",
    "            total_loss += loss.item() * xs.shape[0] \n",
    "            \n",
    "            acc = accuracy(preds, ys)\n",
    "            total_acc += acc.item() * xs.shape[0]\n",
    "    print(f\"epoch {epoch}, valid_loss {total_loss / len(x_valid)}, accuracy {total_acc / len(x_valid)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "During the first training epoches, the valid loss should decrease and the accuracy should increase. Otherwise, you did something wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Refactor neural network with Pytorch modules\n",
    "\n",
    "We will gradually refactor our simple net with Pytorch built-in modules, so that it does the same thing as before but start taking advantage of Pytorch's modules to make it more concise, more understandable and/or flexible.  \n",
    "To make things more gradual and more understandable, the refactoring will be divided into 3 stages.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Refactor stage 1 \n",
    " - Refactor loss fuction with `torch.nn.functional.cross_entropy` function.\n",
    " - Refactor model with `nn.Module`, `nn.Parameter` class.\n",
    " - Refactor optimization algorithm with `model.parameters` and `model.zero_grad` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We first will refactor the `log_softmax` and `nll` method with Pytorch built-in function `torch.nn.functional.cross_entropy` that combines the two. So we can even remove the activation function from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:23:15.367748Z",
     "start_time": "2020-04-20T09:23:15.364526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# old functions\n",
    "# def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "# def simplenet(x): return log_softmax(x @ weights + bias)\n",
    "\n",
    "# new functions\n",
    "loss_function = F.cross_entropy\n",
    "def simplenet(x): return x @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next we will refactor our `simplenet` using `torch.nn` module.\n",
    "\n",
    "`torch.nn` is PyTorch’s neural network (nn) library which contains the primary components to construct network's layers. Within the `torch.nn` package, there is a class called `Module`, and it is the base class for all of neural network modules, including layers. All of the layers in PyTorch need to extend this base class in order to inherit all of PyTorch’s built-in functionality within the `nn.Module` class.  \n",
    "> Note: `nn.Module` (uppercase M) is a Pytorch specific concept, and is a class we'll be using a lot. Do not confuse with the Python concept of a (lowercase m) `module`, which is a file of Python code that can be imported.\n",
    "\n",
    "In order to create model using `nn.Module`, we have 3 essential steps:\n",
    "1. Create a neural network class that extends the `nn.Module` base class.\n",
    "2. Define the network's layers as class attributes in `__init__` method.\n",
    "    - The layers's learnable parameters are initialized in this step. But they need to be wrapped in `nn.Parameters` class in order to help `nn.Module` know those are learnable parameter. The weight tensor inside every layer is an instance of this `Parameter` class. PyTorch’s `nn.Module` class is basically looking for any attributes whose values are instances of the `Parameter` class, and when it finds an instance of the parameter class, it keeps track of it. Take a look at `Random topics` section for more detail information about network parameters.\n",
    "3. Define the network's transformation (operation) in `forward` method.\n",
    "    - Every Pytorch `nn.Module` has a `forward()` method and so when we are building layers and networks, we must provide an implementation of the `forward()` method. The forward method is the actual transformation.\n",
    "    - The tensor input is passed forward though each layer transformation until the tensor reaches the output layer. The composition of all the individual layer forward passes defines the overall forward pass transformation for the network. The goal of the overall transformation is to transform or map the input to the correct prediction output class, and during the training process, the layer weights (data) are updated in such a way that cause the mapping to adjust to make the output closer to the correct prediction.\n",
    "    - When we implement the forward() method of our nn.Module subclass, we will typically use layers'attributes and functions from the `nn.functional` package. This package provides us with many neural network operations that we can use for building layers. In fact, many of the nn.Module layer classes use nn.functional functions to perform their operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:23:18.250184Z",
     "start_time": "2020-04-20T09:23:18.245079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "# old codes\n",
    "# weights = torch.randn(784,10) / math.sqrt(784)\n",
    "# weights.requires_grad_()\n",
    "# bias    = torch.zeros(10, requires_grad=True)\n",
    "# def simplenet(x): return log_softmax(x @ weights + bias)\n",
    "\n",
    "# new code\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784,10) / math.sqrt(784))\n",
    "        self.bias    = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x @ self.weights + self.bias\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One thing to point out that Pytorch neural network modules are `callable Python objects`. It means we can call the `simplenet` as it was a function.   \n",
    "What makes this possible is that PyTorch module classes implement a special Python function called `__call__()`. which will be invoked anytime the object instance is called. After the object instance is called, the `__call__()` method is invoked under the hood, and the `__call__()` in turn invokes the `forward()` method. Instead of calling the `forward()` method directly, we call the object instance. This applies to all PyTorch neural network modules, namely, networks and layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In order to access the model parameters, we can use `parameters()` or `named_parameters()` method. Next we will refactor optimization algorithm using `nn.Module.parameters` and `nn.Module.zero_grad` method. In addition, we also bring training loop inside a function for easier reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:24:24.330888Z",
     "start_time": "2020-04-20T09:24:19.311419Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, valid_loss 0.5341379848957062, accuracy 0.8131\n",
      "epoch 1, valid_loss 0.49990872111320495, accuracy 0.8275\n",
      "epoch 2, valid_loss 0.48446780610084533, accuracy 0.8317\n",
      "epoch 3, valid_loss 0.47528300595283507, accuracy 0.8343\n",
      "epoch 4, valid_loss 0.4690569020748138, accuracy 0.8355\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01    \n",
    "epochs = 5  \n",
    "batch_size = 64     \n",
    "\n",
    "nr_iters = len(x_train) // bs\n",
    "for epoch in range(epochs):\n",
    "    for i in range((nr_iters + 1)):\n",
    "        # step 1. get batch of training set\n",
    "        start_index = i * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        xs = x_train[start_index:end_index]\n",
    "        ys = y_train[start_index:end_index]\n",
    "        # step 2. pass batch to network\n",
    "        preds = simplenet(xs)\n",
    "        # step 3. calculate the loss\n",
    "        loss = loss_function(preds, ys)\n",
    "        # step 4. calculate the gradient of the loss w.r.t the network's parameters\n",
    "        loss.backward()\n",
    "        with torch.no_grad(): \n",
    "            # step 5. update the weights using SGD algorithm\n",
    "            # old code\n",
    "            # weights -= lr * weights.grad\n",
    "            # bias    -= lr * bias.grad\n",
    "            # weights.grad.zero_()          \n",
    "            # bias.grad.zero_()\n",
    "\n",
    "            # new code\n",
    "            for p in simplenet.parameters(): p -= lr * p.grad\n",
    "            simplenet.zero_grad()\n",
    "\n",
    "\n",
    "    # step 6. calculate mean of valid loss after each epoch to see the improvement\n",
    "    batch_size_valid = batch_size * 2\n",
    "    nr_iters_valid = len(x_valid) // batch_size_valid\n",
    "    total_loss = 0\n",
    "    total_acc  = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range((nr_iters_valid + 1)):\n",
    "            start_index = i * batch_size_valid\n",
    "            end_index = start_index + batch_size_valid\n",
    "            xs = x_valid[start_index:end_index]\n",
    "            ys = y_valid[start_index:end_index]\n",
    "            preds = simplenet(xs)\n",
    "            loss = loss_function(preds, ys) \n",
    "            total_loss += loss.item() * xs.shape[0] \n",
    "\n",
    "            acc = accuracy(preds, ys)\n",
    "            total_acc += acc.item() * xs.shape[0]\n",
    "    print(f\"epoch {epoch}, valid_loss {total_loss / len(x_valid)}, accuracy {total_acc / len(x_valid)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok so we have finished refactor stage 1. Let's move to refactor stage 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Refactor stage 2\n",
    " - Refactor model with `nn.Linear` class.\n",
    " - Refactor data setup with `torch.utils.data.TensorDataset`, `torch.utils.data.DataLoader`.\n",
    " - Refactor optimization algorithm with `torch.optim` module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pytorch `nn.Linear` class does all the things that we have done for linear layer, including intialize learnable parameters and define linear operation. \n",
    ">Note: We used the abbreviation `fc` below because linear layers are also called fully connected layers or dense layer.    \n",
    "So `linear` = `dense` = `fully connected.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:28:40.005007Z",
     "start_time": "2020-04-20T10:28:39.997977Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "simplenet = SimpleNet()    \n",
    "simplenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note: we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next is `Dataset` and `DataLoader`.  \n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class for representing a dataset. An abstract class is a Python class that has methods we must implement, in our case are `__getitem__` and `__len__`. In order to create a custom dataset, we need to subclass the `Dataset` class and override `__len__`, that provides the size of the dataset, and `__getitem__`, supporting integer indexing in range from 0 to len(self) exclusive. Upon doing this, our new subclass can then be passed to the a PyTorch DataLoader object.  \n",
    "\n",
    "PyTorch’s `TensorDataset` is a Dataset wrapping tensors. By defining a length and way of indexing, this also gives us a way to iterate, index, and slice `along the first dimension of a tensor`. This will make it easier to access both the independent and dependent variables in the same line as we train.  \n",
    "> Note: we can douple batch size of valid set because we do not need to calculate gradient for it and it can handle larger batch size comparing to training set.\n",
    "\n",
    "`torch.utils.data.DataLoader` is responsible for managing batches. It makes life easier to iterate over batches.\n",
    "We can create a `DataLoader` from any `Dataset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:25:23.451231Z",
     "start_time": "2020-04-20T09:25:23.446130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64     \n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:41:39.093218Z",
     "start_time": "2020-04-20T08:41:39.089249Z"
    },
    "hidden": true
   },
   "source": [
    "The code in training loop is now changed from\n",
    "\n",
    "```\n",
    "for i in range((nr_iters + 1)):\n",
    "    # step 1. get batch of training set\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    xs = x_train[start_index:end_index]\n",
    "    ys = y_train[start_index:end_index]\n",
    "    # step 2. pass batch to network\n",
    "    preds = simplenet(xs)\n",
    "```\n",
    "to\n",
    "\n",
    "```\n",
    "for xs,ys in train_dl:\n",
    "    preds = simplenet(xs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And `torch.optim` package.  \n",
    "This module provides various optimization algorithms. Its API provides `step` and `zero_grad` method for weight updating and zero out gradient which will help us refactor our code further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:27:10.323105Z",
     "start_time": "2020-04-20T09:27:04.302763Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, valid_loss 0.5226423740386963, accuracy 0.8163999915122986\n",
      "epoch 1, valid_loss 0.49401089549064636, accuracy 0.82669997215271\n",
      "epoch 2, valid_loss 0.48364755511283875, accuracy 0.8306000232696533\n",
      "epoch 3, valid_loss 0.4771580994129181, accuracy 0.8323000073432922\n",
      "epoch 4, valid_loss 0.4616956412792206, accuracy 0.8371000289916992\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.01    \n",
    "epochs = 5  \n",
    "\n",
    "simplenet = SimpleNet()\n",
    "opt = optim.SGD(simplenet.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    simplenet.train()\n",
    "    for xs,ys in train_dl:\n",
    "        preds = simplenet(xs)\n",
    "        loss = loss_function(preds, ys)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    simplenet.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = sum(loss_function(simplenet(xs),ys)*len(xs)  for xs, ys in valid_dl)\n",
    "        total_acc = sum(accuracy(simplenet(xs),ys)*len(xs) for xs, ys in valid_dl)\n",
    "        \n",
    "    print(f\"epoch {epoch}, valid_loss {total_loss / len(x_valid)}, accuracy {total_acc / len(x_valid)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Done!  \n",
    "We have finished the whole processes. Thanks to Pytorch built-in modules, our training loop is now dramatically smaller and easier to understand.   \n",
    "The refactor stage 3 does not introduce any new Pytorch modules. It is only an bonus step which help the code a bit cleaner and less code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Refactor stage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`get_data` returns dataloaders for the training and validation sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:18:03.973923Z",
     "start_time": "2020-04-20T10:18:03.970054Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs, shuffle=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`get_model` returns instance of our model and the optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:18:04.413400Z",
     "start_time": "2020-04-20T10:18:04.409453Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model(model, lr):\n",
    "    m = model()\n",
    "    opt = optim.SGD(m.parameters(), lr=lr)\n",
    "    return m, opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we go through a similar process twice of calculating the loss for both the training set and the validation set, let’s make that into its own function, `loss_batch`, which computes the loss for one batch.  \n",
    "We pass an optimizer in for the training set, and use it to perform backprop. For the validation set, we don’t pass an optimizer, so the method doesn’t perform backprop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:18:04.814860Z",
     "start_time": "2020-04-20T10:18:04.808775Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xs, ys, opt=None, metric=None):\n",
    "    loss = loss_func(model(xs), ys)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    if metric is not None:\n",
    "        acc = metric(model(xs), ys)\n",
    "        return loss.item(), acc.item(), len(xs)\n",
    "    else:\n",
    "        return loss.item(), len(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`fit` runs the necessary operations to train our model and compute the training and validation losses for each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:19:12.148694Z",
     "start_time": "2020-04-20T10:19:12.141929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, metric, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xs, ys in train_dl:\n",
    "            loss_batch(model, loss_func, xs, ys, opt)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, accs, nums =  zip(*[loss_batch(model, loss_func, xs, ys, metric=metric) for xs,ys in valid_dl])\n",
    "            \n",
    "        total_loss = np.sum(np.multiply(losses, nums))\n",
    "        total_acc  = np.sum(np.multiply(accs, nums))\n",
    "        print(f\"epoch {epoch}, valid_loss {total_loss / np.sum(nums)}, accuracy {total_acc / np.sum(nums)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:19:37.877279Z",
     "start_time": "2020-04-20T10:19:32.228194Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, valid_loss 0.5245783556461334, accuracy 0.8162\n",
      "epoch 1, valid_loss 0.49596426906585694, accuracy 0.8261\n",
      "epoch 2, valid_loss 0.4808829068660736, accuracy 0.8334\n",
      "epoch 3, valid_loss 0.47098530049324033, accuracy 0.8347\n",
      "epoch 4, valid_loss 0.4786785946369171, accuracy 0.831\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "lr = 0.01\n",
    "epochs = 5\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model(model=SimpleNet, lr=lr)\n",
    "fit(epochs, model, loss_function, accuracy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Done!   \n",
    "Now we can use refactored functions to train a wide variety of models.   \n",
    "In part 3, we will use it to train a CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Disabling PyTorch Gradient Tracking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get predictions for the entire training set\n",
    "Note at the top, we have annotated the function using the @torch.no_grad() PyTorch decoration. \n",
    "This is because we want this functions execution to omit gradient tracking. This is because gradient \n",
    "tracking uses memory, and during inference (getting predictions while not training) there is no need to \n",
    "keep track of the computational graph. The decoration is one way of locally turning off the gradient tracking\n",
    "feature while executing specific functions. We specifically need the gradient calculation feature anytime we \n",
    "are going to calculate gradients using the backward() function. Otherwise, it is a good idea to turn it off\n",
    "because having it off will reduce memory consumption for computations, e.g. when we are using networks for \n",
    "predicting (inference).\n",
    "\n",
    "As another example, we can use Python's with context manger keyword to specify that a specify block of code\n",
    "should exclude gradient computations.\n",
    "Both of these options are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        imgs, lbs = batch\n",
    "        \n",
    "        preds = model(imgs)\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "    return all_preds\n",
    "\n",
    "# Locally Disabling PyTorch Gradient Tracking\n",
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
    "    train_preds = get_all_preds(model, prediction_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For more information, please check [here](https://pytorch.org/docs/stable/notes/autograd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log-sum-exp trick\n",
    "https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/  \n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/log_softmax  \n",
    "https://stackoverflow.com/questions/44081007/logsoftmax-stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "come back later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some good sources:\n",
    "- [pytorch zero to all](https://github.com/hunkim/PyTorchZeroToAll)\n",
    "- [deeplizard](https://deeplizard.com/learn/video/v5cngxo4mIg)\n",
    "- [effective pytorch](https://github.com/vahidk/EffectivePyTorch?fbclid=IwAR1MhsjnjccWy6dIVtibFOCZbWhLtAj5pSTobnkUDxw_gHgfEswnVzqrKQ0#torchscript)\n",
    "- [what is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "- [recommend walk with pytorch](https://forums.fast.ai/t/getting-comfortable-with-pytorch-projects/28371)\n",
    "- [official tutorial](https://pytorch.org/tutorials/)\n",
    "- [DL(with Pytorch)](https://github.com/Atcold/pytorch-Deep-Learning)\n",
    "- [Pytorch project template](https://github.com/moemen95/PyTorch-Project-Template)\n",
    "- [nlp turorial with pytorch](https://github.com/graykode/nlp-tutorial)\n",
    "- [UDACITY course](https://www.udacity.com/course/deep-learning-pytorch--ud188)\n",
    "- [awesome pytorch list](https://github.com/bharathgs/Awesome-pytorch-list)\n",
    "- [deep learning with pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\n",
    "- others:\n",
    "    - https://medium.com/pytorch/get-started-with-pytorch-cloud-tpus-and-colab-a24757b8f7fc\n",
    "    - Grokking Algorithms: An illustrated guide for programmers and other curious people 1st Edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai2] *",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
